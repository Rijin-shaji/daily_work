[
  {
    "vector_id": 0,
    "job_id": "3M",
    "chunk_id": 1,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "Company : 3M  \nJob role     :  AI Engineer \nLocation  : Bengaluru East, Karnataka, India  \n \nAbout the job 3M has a long -standing reputation as a company committed to innovation. We provide \nthe freedom to explore and encourage curiosity and creativity. We gain new insight from \ndiverse thinking, and take risks on new ideas. Here, you can apply your talent in bol d \nways that matter. Job Description  \n The Impact You’ll Make in this Role  \n As an AI/UI Engineer, you will be instrumental in designing, developing, and deploying AI-driven applications that enhance our product offerings. This role emphasizes the \npractical application of AI technologies to solve complex business challenges, focusi ng \non integrating AI capabilities into scalable and reliable systems.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 1,
    "job_id": "3M",
    "chunk_id": 2,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "Job Description  \n The Impact You’ll Make in this Role  \n As an AI/UI Engineer, you will be instrumental in designing, developing, and deploying AI-driven applications that enhance our product offerings. This role emphasizes the \npractical application of AI technologies to solve complex business challenges, focusi ng \non integrating AI capabilities into scalable and reliable systems. You will collaborate \nclosely with cross -functional teams to ensure seamless integration of AI solutions into \nour products. Key Responsibilities  \n \nUI/UX Development:  \n  \n \n• Build responsive, accessible, and high-performance interfaces using React.js / \nNext.js, TypeScript, TailwindCSS, and Material UI. • Implement AI -driven user experiences (chatbots/agents, dashboards, dynamic \nrecommendations ). • Optimize front- end performance for large -scale enterprise use cases.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 2,
    "job_id": "3M",
    "chunk_id": 3,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "• Implement AI -driven user experiences (chatbots/agents, dashboards, dynamic \nrecommendations ). • Optimize front- end performance for large -scale enterprise use cases. • Figma design to MVP building   \n \n \n \nFull -Stack Development  \n \n \n \n• Develop secure and scalable backends using Node.js and/or Python (FastAPI, \nFlask). • Design RESTful & GraphQL APIs for AI and data services. • Work with databases: PostgreSQL, MongoDB, Redis, and vector databases \n(Pinecone, Weaviate, FAISS). AI & GenAI Integration  \n  \n \n• Integrate LLM APIs (Azure OpenAI, Anthropic Claude etc) with the app.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 3,
    "job_id": "3M",
    "chunk_id": 4,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "• Work with databases: PostgreSQL, MongoDB, Redis, and vector databases \n(Pinecone, Weaviate, FAISS). AI & GenAI Integration  \n  \n \n• Integrate LLM APIs (Azure OpenAI, Anthropic Claude etc) with the app. • Build RAG pipelines using Azure Cognitive Search, AWS Kendra, or LangChain. • Implement real -time streaming responses from AI models (WebSockets, SSE). Cloud & DevOps (Azure + AWS):  \n \n \n \n• Deploy applications on Azure App Services, AWS ECS/EKS, and serverless \narchitectures (Azure Functions, AWS Lambda). • Implement CI/CD pipelines with Azure DevOps and AWS CodePipeline.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 4,
    "job_id": "3M",
    "chunk_id": 5,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "Cloud & DevOps (Azure + AWS):  \n \n \n \n• Deploy applications on Azure App Services, AWS ECS/EKS, and serverless \narchitectures (Azure Functions, AWS Lambda). • Implement CI/CD pipelines with Azure DevOps and AWS CodePipeline. • Ensure high availability, scalability, and security across multi -cloud \nenvironments. Collaboration  \n \n \n \n• Partner with AI/ML engineers for model deployment and inference optimization. • Work with designers and product teams to deliver world- class user experiences. To set you up for success in this role from day one, 3M requires (at a minimum) the \nfollowing qualiﬁcations:  \n \n \n \n• Bachelor’s degree in computer science, Artiﬁcial Intelligence, Data Science, or a \nrelated ﬁeld.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 5,
    "job_id": "3M",
    "chunk_id": 6,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "• Work with designers and product teams to deliver world- class user experiences. To set you up for success in this role from day one, 3M requires (at a minimum) the \nfollowing qualiﬁcations:  \n \n \n \n• Bachelor’s degree in computer science, Artiﬁcial Intelligence, Data Science, or a \nrelated ﬁeld. • 5+ years of experience building full -stack AI applications, including at least 1 \nyear speciﬁcally in Generative AI. • Proven expertise in AI applications, including RAG solutions, AI agentic systems, and UI/UX design. • Experience evaluating, ﬁne -tuning, and deploying large language models (LLMs) \nsuch as GPT, Claude, or similar LLMs. • Strong skills in prompt engineering, ﬁne tuning to optimize AI model accuracy \nand relevance, perform benchmarking evaluations, and conduct model \ncomparisons.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 6,
    "job_id": "3M",
    "chunk_id": 7,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "• Experience evaluating, ﬁne -tuning, and deploying large language models (LLMs) \nsuch as GPT, Claude, or similar LLMs. • Strong skills in prompt engineering, ﬁne tuning to optimize AI model accuracy \nand relevance, perform benchmarking evaluations, and conduct model \ncomparisons. • Demonstrated ability to optimize AI models for cost`, scalability, and low -\nlatency performance. Additional qualiﬁcations that could help you succeed even further in this role include:  \n \n \n \n• Excellent communication and collaboration skills with product managers, data \nscientists, engineers, and stakeholders. • Familiarity with MLOps practices, including model lifecycle management and \nCI/CD. • Experience deploying AI applications on cloud platforms (AWS, Azure, GCP).",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 7,
    "job_id": "3M",
    "chunk_id": 8,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "• Familiarity with MLOps practices, including model lifecycle management and \nCI/CD. • Experience deploying AI applications on cloud platforms (AWS, Azure, GCP). Learn more about 3M’s creative solutions to the world’s problems at www.3M.com or on \nInstagram, Facebook, and LinkedIn @3M. Safety is a core value at 3M. All employees are expected to contribute to a strong Environmental Health and Safety (EHS) culture by following safety policies, identifying \nhazards, and engaging in continuous improvement. Please note: your application may not be considered if you do not provide your \neducation and work history, either by: 1) uploading a resume, or 2) entering the information into the application ﬁelds directly.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 8,
    "job_id": "3M",
    "chunk_id": 9,
    "source_file": "3M.pdf",
    "folder": "D:/Project_2",
    "text": "All employees are expected to contribute to a strong Environmental Health and Safety (EHS) culture by following safety policies, identifying \nhazards, and engaging in continuous improvement. Please note: your application may not be considered if you do not provide your \neducation and work history, either by: 1) uploading a resume, or 2) entering the information into the application ﬁelds directly.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "3M",
      "location": "Bengaluru East, Karnataka, India"
    }
  },
  {
    "vector_id": 9,
    "job_id": "Accenture",
    "chunk_id": 1,
    "source_file": "Accenture.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Accenture in India  \nJob role     :  AI/ML Computational Science Specialist  \nLocation  : Bengaluru , Karnataka, India  \nAbout the job \nSkill required:  Tech for Operations - Artiﬁcial Intelligence (AI)  \n \nDesignation:  AI/ML Computational Science Specialist  \n \nQualiﬁcations: Any Graduation  \n Years of Experience: 5 – 7 years  \n \nLanguage - Ability:English(International) - Intermediate  \n \nAbout Accenture  \n Accenture is a global professional services company with leading capabilities in digital, cloud and security.Combining unmatched experience and specialized skills \nacross more than 40 industries, we offer Strategy and Consulting, Technology and \nOperatio ns services, and Accenture Song — all powered by the world’s largest \nnetwork of Advanced Technology and Intelligent Operations centers. Our 784,000 \npeople deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 c ountries. We embrace the power of change to \ncreate value and shared success for our clients, people, shareholders, partners and communities.Visit us at www.accenture.com \n \nWhat would you do? As a part of the Knowledge -AI team, you will lead the \ndevelopment and deployment of AI -based assets using the latest technologies and \nadvanced AI techniques. You will be responsible for building scalable, production -\nready AI solutions using Machine Learning, Deep Learning, NLP, and Generative AI \n(GenAI) approaches. You w ill apply your expertise to understand complex business \nprocesses and design AI -driven solutions that reduce turnaround time and improve \nefficiency.",
    "metadata": {
      "job_title": "AI/ML Computational Science Specialist",
      "company": "Accenture in India",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 10,
    "job_id": "Accenture",
    "chunk_id": 2,
    "source_file": "Accenture.pdf",
    "folder": "D:/Project_2",
    "text": "You will be responsible for building scalable, production -\nready AI solutions using Machine Learning, Deep Learning, NLP, and Generative AI \n(GenAI) approaches. You w ill apply your expertise to understand complex business \nprocesses and design AI -driven solutions that reduce turnaround time and improve \nefficiency. You will collaborate with business experts, researchers, and platform engineers to deliver enterprise-grade  AI solutions that align with Accenture’s core \nprinciples and deliver measurable outcomes. You will also contribute to innovation through patents, reusable assets, and enhancements to existing solutions. ________________________________________  \nWhat are we looking for? •  Strong programming skills in Python and familiarity with libraries such as \nNumPy, pandas, scikit -learn, Matplotlib, and Seaborn  \n•  Experience with Machine Learning and Deep Learning frameworks (e.g., \nTensorFlow, PyTorch, Keras)  \n•  Hands -on experience with Natural Language Processing (NLP) and Large \nLanguage Models (LLMs)  \n•  Exposure to Generative AI, Prompt Engineering, and orchestration \nframeworks (e.g., LangChain, LlamaIndex)  \n•  Experience with deploying AI models using FastAPI, Flask, or gRPC  \n•  Familiarity with containerization and orchestration tools (e.g., Docker, \nKubernetes)  \n•  Experience with cloud platforms (AWS, Azure, GCP) and services like \nSageMaker, Vertex AI, Azure ML  \n•  Understanding of MLOps tools and practices (e.g., MLﬂow, DVC, Kubeﬂow, \nCI/CD pipelines)  \n•  Ability to perform under pressure and manage multiple stakeholders  \n•  Strong business acumen and ability to translate business challenges into AI \nsolutions  \n•  Excellent collaboration and communication skills across cross -functional \nteams ________________________________________ \n•  Designing scalable and modular AI architectures  \n•  Implementing CI/CD pipelines for ML workﬂows using tools like GitHub \nActions, Jenkins, or Azure DevOps  \n•  Working with vector databases (e.g., Pinecone, FAISS) for semantic search \nand RAG pipelines  \n•  Applying model optimization techniques (e.g., ONNX, TensorRT, \nquantization, distillation)  \n•  Implementing observability and monitoring using Prometheus, Grafana, \nArize AI, or WhyLabs  \n•  Understanding of responsible AI practices (e.g., fairness, explainability, bias \ndetection)  \n•  Agile methodologies and sprint planning  \n•  Good understanding of SQL and NoSQL databases Roles and \nResponsibilities:  \n•  Design, develop, and deploy AI -based solutions across multiple domains \n•  Provide technical leadership and mentorship to junior team members  \n•  Industrialize and commercialize AI products and solutions \n•  Analyze complex business processes and propose AI -based optimizations \n•  Manage cross -functional stakeholders and ensure alignment with business \ngoals  \n•  Drive innovation and contribute to patents and reusable assets  \n•  Lead product/solution development and collaborate with clients to deliver \nvalue  \n•  Operate in an Agile development environment and proactively manage risks \nand blockers  \n•  Ensure adherence to quality control best practices including unit, \nintegration, UAT, and performance testing  \n•  Maintain comprehensive documentation and deliver compelling storytelling \nand presentations to stakeholders",
    "metadata": {
      "job_title": "AI/ML Computational Science Specialist",
      "company": "Accenture in India",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 11,
    "job_id": "Accenture",
    "chunk_id": 3,
    "source_file": "Accenture.pdf",
    "folder": "D:/Project_2",
    "text": "________________________________________  \nWhat are we looking for? •  Strong programming skills in Python and familiarity with libraries such as \nNumPy, pandas, scikit -learn, Matplotlib, and Seaborn  \n•  Experience with Machine Learning and Deep Learning frameworks (e.g., \nTensorFlow, PyTorch, Keras)  \n•  Hands -on experience with Natural Language Processing (NLP) and Large \nLanguage Models (LLMs)  \n•  Exposure to Generative AI, Prompt Engineering, and orchestration \nframeworks (e.g., LangChain, LlamaIndex)  \n•  Experience with deploying AI models using FastAPI, Flask, or gRPC  \n•  Familiarity with containerization and orchestration tools (e.g., Docker, \nKubernetes)  \n•  Experience with cloud platforms (AWS, Azure, GCP) and services like \nSageMaker, Vertex AI, Azure ML  \n•  Understanding of MLOps tools and practices (e.g., MLﬂow, DVC, Kubeﬂow, \nCI/CD pipelines)  \n•  Ability to perform under pressure and manage multiple stakeholders  \n•  Strong business acumen and ability to translate business challenges into AI \nsolutions  \n•  Excellent collaboration and communication skills across cross -functional \nteams ________________________________________ \n•  Designing scalable and modular AI architectures  \n•  Implementing CI/CD pipelines for ML workﬂows using tools like GitHub \nActions, Jenkins, or Azure DevOps  \n•  Working with vector databases (e.g., Pinecone, FAISS) for semantic search \nand RAG pipelines  \n•  Applying model optimization techniques (e.g., ONNX, TensorRT, \nquantization, distillation)  \n•  Implementing observability and monitoring using Prometheus, Grafana, \nArize AI, or WhyLabs  \n•  Understanding of responsible AI practices (e.g., fairness, explainability, bias \ndetection)  \n•  Agile methodologies and sprint planning  \n•  Good understanding of SQL and NoSQL databases Roles and \nResponsibilities:  \n•  Design, develop, and deploy AI -based solutions across multiple domains \n•  Provide technical leadership and mentorship to junior team members  \n•  Industrialize and commercialize AI products and solutions \n•  Analyze complex business processes and propose AI -based optimizations \n•  Manage cross -functional stakeholders and ensure alignment with business \ngoals  \n•  Drive innovation and contribute to patents and reusable assets  \n•  Lead product/solution development and collaborate with clients to deliver \nvalue  \n•  Operate in an Agile development environment and proactively manage risks \nand blockers  \n•  Ensure adherence to quality control best practices including unit, \nintegration, UAT, and performance testing  \n•  Maintain comprehensive documentation and deliver compelling storytelling \nand presentations to stakeholders",
    "metadata": {
      "job_title": "AI/ML Computational Science Specialist",
      "company": "Accenture in India",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 12,
    "job_id": "Blend",
    "chunk_id": 1,
    "source_file": "Blend.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Blend \nJob role     :  AI Engineer \nLocation  : Hyderabad, Telangana, India  \nAbout the job Job Description  \nWe are looking for an  AI Enginee r with hands -on experience designing and \ndeploying scalable AI solutions. In this role, you will be part of a cross-functional \nteam working on cutting -edge projects involving Retrieval -Augmented Generation \n(RAG), agentic frameworks, and end -to-end MLOps wo rkﬂows. You’ll play a key role in developing AI applications using tools like LangChain, \nCrewAI, and Google ADK, while applying advanced prompt engineering techniques \nand ensuring robust monitoring and performance tracing. Your collaboration with \nother engineering  will help align innovative AI systems with broader development \ngoals. What is this position about? • Design, develop, and deploy AI solutions.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Blend",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 13,
    "job_id": "Blend",
    "chunk_id": 2,
    "source_file": "Blend.pdf",
    "folder": "D:/Project_2",
    "text": "What is this position about? • Design, develop, and deploy AI solutions. • Implement Retrieval -Augmented Generation (RAG) and ﬁne -tuning \ntechniques. • Utilize and integrate AI frameworks like LangChain. • Use advanced prompt engineering techniques to solve complex problems \nwith LLMs. • Build and manage agentic frameworks such as CrewAI and Google ADK.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Blend",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 14,
    "job_id": "Blend",
    "chunk_id": 3,
    "source_file": "Blend.pdf",
    "folder": "D:/Project_2",
    "text": "• Use advanced prompt engineering techniques to solve complex problems \nwith LLMs. • Build and manage agentic frameworks such as CrewAI and Google ADK. • Apply MLOps best practices to streamline AI development workﬂows. • Monitor and trace AI applications performance. • Collaborate across teams to ensure alignment with traditional ML and AI \nmethodologies. • Work on end -to-end software engineering for scalable solutions.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Blend",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 15,
    "job_id": "Blend",
    "chunk_id": 4,
    "source_file": "Blend.pdf",
    "folder": "D:/Project_2",
    "text": "• Collaborate across teams to ensure alignment with traditional ML and AI \nmethodologies. • Work on end -to-end software engineering for scalable solutions. Qualiﬁcations  \n• 3+ years of experience in designing, developing, and deploying AI/ML \nsolutions  \n• Strong hands -on experience with Azure AI & ML services, including:  \n• Azure Machine Learning  \n• Azure OpenAI Service  \n• Azure AI Search / Cognitive Search  \n• Azure Data & Compute services  \n• Strong understanding of machine learning fundamentals and traditional AI \nconcepts  \n• Experience with MLOps tools and practices (model training, deployment, \nmonitoring, CI/CD on Azure)  \n• Solid programming skills in Python (or other relevant languages)  \n• Excellent problem -solving skills and ability to work in a collaborative, cross-\nfunctional environment.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Blend",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 16,
    "job_id": "BMI",
    "chunk_id": 1,
    "source_file": "BMI.pdf",
    "folder": "D:/Project_2",
    "text": "Company : BMI  \nJob role     :  Data Scientist -Artiﬁcial Intelligence  \nLocation  : Kochi , Kerala, India  \nAbout the job \nIntroduction  \n \nIn this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a \nwide range of public and private sector clients around the world. Our delivery \ncenters offer ou r clients locally based skills and technical expertise to drive \ninnovation and adoption of new technology. Your Role And Responsibilities  \n \n \n• Work with broader team to build, analyze and improve the AI solutions. • You will also work with our software developers in consuming different \nenterprise applications \n \n \nRequired Technical And Professional Expertise  \n \n \n• Resource should have 5 -7 years of experience. Sound knowledge of Python \nand should know how to use the ML related services. • Proﬁcient in Python with focus on Data Analytics Packages.",
    "metadata": {
      "job_title": "Data Scientist -Artiﬁcial Intelligence",
      "company": "BMI",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 17,
    "job_id": "BMI",
    "chunk_id": 2,
    "source_file": "BMI.pdf",
    "folder": "D:/Project_2",
    "text": "Sound knowledge of Python \nand should know how to use the ML related services. • Proﬁcient in Python with focus on Data Analytics Packages. • Strategy Analyse large, complex data sets and provide actionable insights to inform business decisions. • Strategy Design and implementing data models that help in identifying \npatterns and trends. Collaboration Work with data engineers to optimize and \nmaintain data pipelines. • Perform quantitative analyses that translate data into actionable insights \nand provide analytical, data -driven decision -making.",
    "metadata": {
      "job_title": "Data Scientist -Artiﬁcial Intelligence",
      "company": "BMI",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 18,
    "job_id": "BMI",
    "chunk_id": 3,
    "source_file": "BMI.pdf",
    "folder": "D:/Project_2",
    "text": "Collaboration Work with data engineers to optimize and \nmaintain data pipelines. • Perform quantitative analyses that translate data into actionable insights \nand provide analytical, data -driven decision -making. Identify and \nrecommend process improvements to enhance the efficiency of the data platform. Develop and maintain data models, al gorithms, and statistical \nmodels  \n \n \nPreferred Technical And Professional Experience  \n  \n• Experience with conversation analytics. Experience with cloud technologies  \n• Experience with data exploration tools such as Tableu",
    "metadata": {
      "job_title": "Data Scientist -Artiﬁcial Intelligence",
      "company": "BMI",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 19,
    "job_id": "BMI",
    "chunk_id": 4,
    "source_file": "BMI.pdf",
    "folder": "D:/Project_2",
    "text": "Experience with cloud technologies  \n• Experience with data exploration tools such as Tableu",
    "metadata": {
      "job_title": "Data Scientist -Artiﬁcial Intelligence",
      "company": "BMI",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 20,
    "job_id": "Cisco",
    "chunk_id": 1,
    "source_file": "Cisco.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Cisco  \nJob role     :  Applied AI Scientist  \nLocation  :  Bengaluru, Karnataka, India  \nAbout the job \n• Meet the Team  \n \nSplunk, a Cisco company, is building a safer, more resilient digital world with an end -to-end, full -stack platform designed for hybrid, multi -cloud \nenvironments. Join the Foundational Modeling team at Splunk, where we advance the state of AI for high-volum e, real -time, multi -modal \nmachine -generated data — including logs, time series, traces, and events. We combine deep AI research expertise with the scale and operational excellence of Splunk and Cisco’s global engineering capabilities. Our wo rk \nspans networking, security, observability, and customer experience — designing and deploying foundation models that enhance reliability, \nstrengthen security, prevent downtime, and deliver predictive insights \nacross Splunk Observability, Security, and Pl atform at enterprise scale. You’ll be part of a culture that values technical excellence, impact -driven \ninnovation, and cross -functional collaboration — all within a ﬂexible, \ngrowth -oriented environment. Your Impact  \n \n \n• Own and develop speciﬁc components of foundation -model pipelines for \nmachine -generated data —primarily logs, with supporting work across time \nseries, traces, and events.",
    "metadata": {
      "job_title": "Applied AI Scientist",
      "company": "Cisco",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 21,
    "job_id": "Cisco",
    "chunk_id": 2,
    "source_file": "Cisco.pdf",
    "folder": "D:/Project_2",
    "text": "You’ll be part of a culture that values technical excellence, impact -driven \ninnovation, and cross -functional collaboration — all within a ﬂexible, \ngrowth -oriented environment. Your Impact  \n \n \n• Own and develop speciﬁc components of foundation -model pipelines for \nmachine -generated data —primarily logs, with supporting work across time \nseries, traces, and events. • Implement and optimize parts of distributed training and inference \nworkﬂows, including proﬁling, scaling, and efficiency improvements. • Collaborate with engineering, product, and data science teams to translate \nrequirements into workable prototypes and support production integration. • Participate in team knowledge -sharing, documentation, and internal \ntechnical discussions to help strengthen collective expertise. • Stay current with emerging AI/ML advances and bring relevant ideas, papers, and techniques into ongoing research and development.",
    "metadata": {
      "job_title": "Applied AI Scientist",
      "company": "Cisco",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 22,
    "job_id": "Cisco",
    "chunk_id": 3,
    "source_file": "Cisco.pdf",
    "folder": "D:/Project_2",
    "text": "• Participate in team knowledge -sharing, documentation, and internal \ntechnical discussions to help strengthen collective expertise. • Stay current with emerging AI/ML advances and bring relevant ideas, papers, and techniques into ongoing research and development. • Minimum Qualiﬁcations  \n \n \n• PhD in Computer Science or related quantitative ﬁeld, or Master plus 2+ \nyears of industry research experience. • Proven track record in at least one of the following areas: large language \nmodeling for both structure and unstructured data, deep learning -based \ntime series modeling, advanced anomaly detection, and multi -modality \nmodeling. • Solid proﬁciency in Python and deep learning frameworks (e.g., PyTorch, \nTensorFlow)   \n• Experience translating research ideas into production systems. • Preferred Qualiﬁcations  \n  \n• Deep NLP & Domain -Adapted LLMs: Background in building and adapting \nlarge -scale language models (e.g., T5, BERT, LLaMA) for specialized domains \nincluding structured/unstructured logs, text, and event sequences.",
    "metadata": {
      "job_title": "Applied AI Scientist",
      "company": "Cisco",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 23,
    "job_id": "Cisco",
    "chunk_id": 4,
    "source_file": "Cisco.pdf",
    "folder": "D:/Project_2",
    "text": "• Solid proﬁciency in Python and deep learning frameworks (e.g., PyTorch, \nTensorFlow)   \n• Experience translating research ideas into production systems. • Preferred Qualiﬁcations  \n  \n• Deep NLP & Domain -Adapted LLMs: Background in building and adapting \nlarge -scale language models (e.g., T5, BERT, LLaMA) for specialized domains \nincluding structured/unstructured logs, text, and event sequences. • Log Analytics Expertise – In-depth knowledge of structured/unstructured \nsystem logs, event sequence analysis, anomaly detection, and root cause \nidentiﬁcation. • Advanced Anomaly Detection – Experience creating robust, scalable \napproaches (statistical, deep learning, or hybrid) for high -volume, real -time \nlogs data. • Multi -Modal AI Modeling – Strong track record fusing logs, time series, \ntraces, tabular data, and graphs for foundation models tackling complex operational insights. • Large -Scale Training & Optimization – Experience optimizing model \narchitectures, distributed training pipelines, and inference efficiency to minimize cost and latency while preserving accuracy.",
    "metadata": {
      "job_title": "Applied AI Scientist",
      "company": "Cisco",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 24,
    "job_id": "Cisco",
    "chunk_id": 5,
    "source_file": "Cisco.pdf",
    "folder": "D:/Project_2",
    "text": "• Multi -Modal AI Modeling – Strong track record fusing logs, time series, \ntraces, tabular data, and graphs for foundation models tackling complex operational insights. • Large -Scale Training & Optimization – Experience optimizing model \narchitectures, distributed training pipelines, and inference efficiency to minimize cost and latency while preserving accuracy. • MLOps & Continuous Learning – Fluency in automated retraining, drift \ndetection, incremental updates, and production monitoring of ML models. • Strong Research Track Record – Publications in top AI/ML conferences or \njournals (e.g., NeurIPS, ICML, ICLR, AAAI, CVPR, ACL, KDD) demonstrating \ncontributions to state -of-the -art methods and real -world applications.",
    "metadata": {
      "job_title": "Applied AI Scientist",
      "company": "Cisco",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 25,
    "job_id": "ebay",
    "chunk_id": 1,
    "source_file": "ebay.pdf",
    "folder": "D:/Project_2",
    "text": "Company : eBay  \nJob role     :  Machine Learning Engineer (T25)  \nLocation  :  Bengaluru, Karnataka, India  \nAbout the job \n• At eBay, we're more than a global ecommerce leader — we’re changing the \nway the world shops and sells. Our platform empowers millions of buyers \nand sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of \necommerce for enthusiasts. Our customers are our compass, authenticity thrives, bold ideas are \nwelcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our cus tomers, our company, \nand our planet. Join a team of passionate thinkers, innovators, and dreamers — and help us \nconnect people and build communities to create economic opportunity for \nall.",
    "metadata": {
      "job_title": "Machine Learning Engineer (T25)",
      "company": "eBay",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 26,
    "job_id": "ebay",
    "chunk_id": 2,
    "source_file": "ebay.pdf",
    "folder": "D:/Project_2",
    "text": "We're in this together, sustaining the future of our cus tomers, our company, \nand our planet. Join a team of passionate thinkers, innovators, and dreamers — and help us \nconnect people and build communities to create economic opportunity for \nall. Machine Learning Engineer (T25), Product Knowledge  \n Do you love Big Data? Deploying Machine Learning models? Challenging optimization problems? Knowledgeable, collaborative co -workers?",
    "metadata": {
      "job_title": "Machine Learning Engineer (T25)",
      "company": "eBay",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 27,
    "job_id": "ebay",
    "chunk_id": 3,
    "source_file": "ebay.pdf",
    "folder": "D:/Project_2",
    "text": "Challenging optimization problems? Knowledgeable, collaborative co -workers? Come \nwork at eBay and help us redeﬁne global, online commerce! Who Are We? The Product Knowledge team is at the epicenter of eBay’s Tech -driven, \nCustomer -centric overhaul. Our team is entrusted with creating and using \neBay’s Product Knowledge - a vast Big Data system which is built up of \nlistings, transactions, products, knowledge graphs, and more.",
    "metadata": {
      "job_title": "Machine Learning Engineer (T25)",
      "company": "eBay",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 28,
    "job_id": "ebay",
    "chunk_id": 4,
    "source_file": "ebay.pdf",
    "folder": "D:/Project_2",
    "text": "The Product Knowledge team is at the epicenter of eBay’s Tech -driven, \nCustomer -centric overhaul. Our team is entrusted with creating and using \neBay’s Product Knowledge - a vast Big Data system which is built up of \nlistings, transactions, products, knowledge graphs, and more. Our team has a mix of highly proﬁcie nt people from multiple ﬁelds such as Machine \nLearning, Data Science, Software Engineering, Operations, and Big Data \nAnalytics. We have a strong culture of collaboration, and plenty of \nopportunity to learn, make an impact, and grow! What Will You Do  \n \nWe are looking for exceptional Engineers, who take pride in creating simple \nsolutions to apparently -complex problems. Our Engineering tasks typically \ninvolve at least one of the following:  \n \n \n• Building a pipeline that processes up to billions of items, frequently \nemploying ML models on these datasets  \n• Creating services that provide Search or other Information Retrieval \ncapabilities at low latency on datasets of hundreds of millions of items  \n• Crafting sound API design and driving integration between our Data layers \nand Customer -facing applications and components  \n• Designing and running A/B tests in Production experiences in order to vet \nand measure the impact of any new or improved functionality  \n \n \n \n•  If you love a good challenge, and are good at handling complexity - we’d love \nto hear from you!",
    "metadata": {
      "job_title": "Machine Learning Engineer (T25)",
      "company": "eBay",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 29,
    "job_id": "ebay",
    "chunk_id": 5,
    "source_file": "ebay.pdf",
    "folder": "D:/Project_2",
    "text": "What Will You Do  \n \nWe are looking for exceptional Engineers, who take pride in creating simple \nsolutions to apparently -complex problems. Our Engineering tasks typically \ninvolve at least one of the following:  \n \n \n• Building a pipeline that processes up to billions of items, frequently \nemploying ML models on these datasets  \n• Creating services that provide Search or other Information Retrieval \ncapabilities at low latency on datasets of hundreds of millions of items  \n• Crafting sound API design and driving integration between our Data layers \nand Customer -facing applications and components  \n• Designing and running A/B tests in Production experiences in order to vet \nand measure the impact of any new or improved functionality  \n \n \n \n•  If you love a good challenge, and are good at handling complexity - we’d love \nto hear from you! eBay is an amazing company to work for. Being on the team, you can expect \nto beneﬁt from:  \n  \n• A competitive salary - including stock grants and a yearly bonus  \n• A healthy work culture that promotes business impact and at the same time \nhighly values your personal well -being  \n• Being part of a force for good in this world - eBay truly cares about its \nemployees, its customers, and the world’s population, and takes every opportunity to make this clearly apparent  \n \n \n \n• Job Responsibilities  \n  \n• Design, deliver, and maintain signiﬁcant features in data pipelines, ML \nprocessing, and / or service infrastructure  \n• Optimize software performance to achieve the required throughput and / or \nlatency  \n• Work with your manager, peers, and Product Managers to scope projects and \nfeatures  \n• Come up with a sound technical strategy, taking into consideration the \nproject goals, timelines, and expected impact  \n• Take point on some cross -team efforts, taking ownership of a business \nproblem and ensuring the different teams are in sync and working towards a coherent technical solution \n• Take active part in knowledge sharing across the organization - both teaching \nand learning from others  \n  \n \n• Minimum Qualiﬁcations  \n  \n• Passion and commitment for technical excellence   \n• B.Sc. or M.Sc. in Computer Science or an equivalent professional \nexperience  \n•  2+ years of software design and development experience, tackling non -\ntrivial problems in backend services and / or data pipelines  \n• A solid foundation in Data Structures, Algorithms, Object -Oriented \nProgramming, Software Design, and core Statistics knowledge  \n• Experience in production -grade coding in Java, and Python/Scala   \n• Experience in the close examination of data and computation of statistics  \n•  Experience in using and operating Big Data processing pipelines, such as: \nHadoop and Spark  \n• Good verbal and written communication and collaboration skills",
    "metadata": {
      "job_title": "Machine Learning Engineer (T25)",
      "company": "eBay",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 30,
    "job_id": "ebay",
    "chunk_id": 6,
    "source_file": "ebay.pdf",
    "folder": "D:/Project_2",
    "text": "or M.Sc. in Computer Science or an equivalent professional \nexperience  \n•  2+ years of software design and development experience, tackling non -\ntrivial problems in backend services and / or data pipelines  \n• A solid foundation in Data Structures, Algorithms, Object -Oriented \nProgramming, Software Design, and core Statistics knowledge  \n• Experience in production -grade coding in Java, and Python/Scala   \n• Experience in the close examination of data and computation of statistics  \n•  Experience in using and operating Big Data processing pipelines, such as: \nHadoop and Spark  \n• Good verbal and written communication and collaboration skills",
    "metadata": {
      "job_title": "Machine Learning Engineer (T25)",
      "company": "eBay",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 31,
    "job_id": "GE",
    "chunk_id": 1,
    "source_file": "GE.pdf",
    "folder": "D:/Project_2",
    "text": "Company : GE Aerospace \nJob role     :  Research Engineer - Computer Vision  \nLocation  : Bengaluru, Karnataka, India  \nAbout the job Job Description Summary  \n \nWe are looking for top notch researchers to be part of our growing Software Controls and Optimization team at GE Aerospace Research. As a group, we \ninnovate and execute on the R&D strategy for GE Aerospace on a range of problems \nfrom building predictive/pr escriptive analytics for a variety of applications that \nimprove process efficiencies in the business, engine faults to designing inspections solutions for aircraft engines. Job Description  \n \nSite Overview  \n \nEstablished in 2000, the John F. Welch Technology Center (JFWTC) in Bengaluru is \nour multidisciplinary research and engineering center. Engineers and scientists at \nJFWTC have contributed to hundreds of aviation patents, pioneering breakthroughs in engine technologies, advanced mat erials, and additive manufacturing. Roles And Responsibilities  \n  \n• Work independently as well as with a diverse team to develop and apply \nadvanced technology solutions to GE Aerospace products and services \nusing modeling, optimization, estimation, or detection technologies, leveraging AI/ML to augment a physics-based unde rstanding of systems. • Validate performance of developed solution through simulations and application on target product to mature technology to be transferred to the GE Aerospace business.",
    "metadata": {
      "job_title": "Research Engineer - Computer Vision",
      "company": "GE Aerospace",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 32,
    "job_id": "GE",
    "chunk_id": 2,
    "source_file": "GE.pdf",
    "folder": "D:/Project_2",
    "text": "Roles And Responsibilities  \n  \n• Work independently as well as with a diverse team to develop and apply \nadvanced technology solutions to GE Aerospace products and services \nusing modeling, optimization, estimation, or detection technologies, leveraging AI/ML to augment a physics-based unde rstanding of systems. • Validate performance of developed solution through simulations and application on target product to mature technology to be transferred to the GE Aerospace business. • Document technology and results through patent applications, technical \nreports, and  publications. • Stay current with advances in system technologies to seek out new ideas \nand applications. • Work in a team environment with colleagues across GE Aerospace \nResearch, and business units. Ideal Candidate  \n Should have experience in data analytics, optimization, estimation, or detection  algorithms.",
    "metadata": {
      "job_title": "Research Engineer - Computer Vision",
      "company": "GE Aerospace",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 33,
    "job_id": "GE",
    "chunk_id": 3,
    "source_file": "GE.pdf",
    "folder": "D:/Project_2",
    "text": "• Work in a team environment with colleagues across GE Aerospace \nResearch, and business units. Ideal Candidate  \n Should have experience in data analytics, optimization, estimation, or detection  algorithms. Qualiﬁcations/Requirements  \n \n \n• Doctorate degree in an Engineering ﬁeld with experience in design of \nestimation, controls, AI/ML, or fault detection algorithms. • Or a Master’s degree in an Engineering ﬁeld with a minimum of 3 years of \nexperience in AI/ML, physics-based modeling, estimation, or fault detection algorithms. • Knowledge and application of data analytics, optimization, estimation, or \ndetection  algorithms. • Proﬁciency in Python or Matlab and familiarity with C & C++.",
    "metadata": {
      "job_title": "Research Engineer - Computer Vision",
      "company": "GE Aerospace",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 34,
    "job_id": "GE",
    "chunk_id": 4,
    "source_file": "GE.pdf",
    "folder": "D:/Project_2",
    "text": "• Knowledge and application of data analytics, optimization, estimation, or \ndetection  algorithms. • Proﬁciency in Python or Matlab and familiarity with C & C++. Desired Qualiﬁcation  \n  \n• Experience with end-to -end development of digital products with exposure \nto problems in the aero/thermal domain. • Strong analytical skills, familiarity with robust modeling/analysis \ntechniques. • Proﬁciency with use of NPSS for aerospace applications. • Strong interpersonal skills.",
    "metadata": {
      "job_title": "Research Engineer - Computer Vision",
      "company": "GE Aerospace",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 35,
    "job_id": "GE",
    "chunk_id": 5,
    "source_file": "GE.pdf",
    "folder": "D:/Project_2",
    "text": "• Proﬁciency with use of NPSS for aerospace applications. • Strong interpersonal skills. • Self -motivated and ability to work independently and as part of a team. • Experience leading teams which includes setting up schedules, milestones, technical reviews, tracking funding etc. • Ability to communicate effectively with senior leadership. • Demonstrated ability to take an innovative idea from a concept to a product.",
    "metadata": {
      "job_title": "Research Engineer - Computer Vision",
      "company": "GE Aerospace",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 36,
    "job_id": "GE",
    "chunk_id": 6,
    "source_file": "GE.pdf",
    "folder": "D:/Project_2",
    "text": "• Ability to communicate effectively with senior leadership. • Demonstrated ability to take an innovative idea from a concept to a product. • Humble: respectful, receptive, agile, eager to learn  \n• Transparent: shares critical information, speaks with candor, contributes \nconstructively  \n• Focused: quick learner, strategically prioritizes work, committed  \n• Leadership ability: strong communicator, decision -maker, collaborative  \n• Problem solver: analytical -minded, challenges existing processes, critical \nthinker. At GE Aerospace, we have a relentless dedication to the future of safe and more sustainable ﬂight and believe in our talented people to make it happen. Here, you \nwill have the opportunity to work on really cool things with really smart and \ncollaborative p eople. Together, we will mobilize a new era of growth in aerospace \nand defense.",
    "metadata": {
      "job_title": "Research Engineer - Computer Vision",
      "company": "GE Aerospace",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 37,
    "job_id": "GE",
    "chunk_id": 7,
    "source_file": "GE.pdf",
    "folder": "D:/Project_2",
    "text": "Here, you \nwill have the opportunity to work on really cool things with really smart and \ncollaborative p eople. Together, we will mobilize a new era of growth in aerospace \nand defense. Where others stop, we accelerate. Additional Information \n \nRelocation Assistance Provided:  Yes",
    "metadata": {
      "job_title": "Research Engineer - Computer Vision",
      "company": "GE Aerospace",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 38,
    "job_id": "IBM",
    "chunk_id": 1,
    "source_file": "IBM.pdf",
    "folder": "D:/Project_2",
    "text": "Company : IBM  \nJob role     :  Senior / Lead AI Engineer – Agentic & Generative AI Systems  \nLocation  : Kochi, Kerala, India  \nAbout the job \nIntroduction  \n \nAt IBM Software, we transform client challenges into solutions. Building the world’s leading AI -powered, cloud-native products that shape the future of business and \nsociety. Our legacy of innovation creates endless opportunities for IBMers to learn, grow, and make an impact on a global scale. Working in Software means joining a \nteam fueled by curiosity and collaboration. You’ll work with diverse technologies, partners, and industries to design, develop, and deliver solutions that power digital \ntransformatio n. With a culture that values innovation, growth, and continuous \nlearning, IBM Software places you at the heart of IBM’s product and technology \nlandscape. Here, you’ll have the tools and opportunities to advance your career \nwhile creating software that cha nges the world.",
    "metadata": {
      "job_title": "Senior / Lead AI Engineer – Agentic & Generative AI Systems",
      "company": "IBM",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 39,
    "job_id": "IBM",
    "chunk_id": 2,
    "source_file": "IBM.pdf",
    "folder": "D:/Project_2",
    "text": "You’ll work with diverse technologies, partners, and industries to design, develop, and deliver solutions that power digital \ntransformatio n. With a culture that values innovation, growth, and continuous \nlearning, IBM Software places you at the heart of IBM’s product and technology \nlandscape. Here, you’ll have the tools and opportunities to advance your career \nwhile creating software that cha nges the world. Role Overview  \n \nYour role and responsibilities  \n We are seeking a highly skilled AI Engineer to architect, build, and scale intelligent, agentic AI platforms that solve complex infrastructure and operational challenges. This role requires de ep expertise in Generative AI, multi -agent orchestration, and \nproduction -grade ML systems, with strong emphasis on reliability, performance, \nand operational excellence. Key Responsibilities  \n  \n• Develop Intelligent AI Solutions - Design and deliver advanced NLP and \nGenerative AI solutions, including Retrieval -Augmented Generation (RAG) \npipelines, prompt -driven systems, and agentic workﬂows to solve real -world \ninfrastructure and operational problems. • Own Critical AI Features End-to -End - Lead the complete lifecycle of LLM -\npowered applications —such as chatbots, optimization engines, and \nautonomous assistants —from prompt design and model integration to \ndeployment, monitoring, and iteration.",
    "metadata": {
      "job_title": "Senior / Lead AI Engineer – Agentic & Generative AI Systems",
      "company": "IBM",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 40,
    "job_id": "IBM",
    "chunk_id": 3,
    "source_file": "IBM.pdf",
    "folder": "D:/Project_2",
    "text": "Key Responsibilities  \n  \n• Develop Intelligent AI Solutions - Design and deliver advanced NLP and \nGenerative AI solutions, including Retrieval -Augmented Generation (RAG) \npipelines, prompt -driven systems, and agentic workﬂows to solve real -world \ninfrastructure and operational problems. • Own Critical AI Features End-to -End - Lead the complete lifecycle of LLM -\npowered applications —such as chatbots, optimization engines, and \nautonomous assistants —from prompt design and model integration to \ndeployment, monitoring, and iteration. • Build Agentic & Multi -Agent AI Platforms - Architect and deploy scalable \nmulti -agent systems capable of autonomous reasoning, tool usage, task \ndecomposition, and orchestration across multiple operational domains. • Multi -Operational Tool Integration - Design and integrate AI agents with \nmultiple operational tools and APIs (monitoring, CI/CD, ticketing, \ninfrastructure, and platform services) to enable autonomous execution, \nremediation, and decision -making. • AI-Powered Observability & Autoscaling - Develop AI -driven observability, \nanomaly detection, root -cause analysis, and autoscaling frameworks for \nlarge -scale distributed systems and microservices platforms. • CI/CD & Platform Integration - Embed AI/ML solutions into CI/CD pipelines, \nmonitoring systems, and platform APIs to support continuous delivery, \nexperimentation, and operational intelligence.",
    "metadata": {
      "job_title": "Senior / Lead AI Engineer – Agentic & Generative AI Systems",
      "company": "IBM",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 41,
    "job_id": "IBM",
    "chunk_id": 4,
    "source_file": "IBM.pdf",
    "folder": "D:/Project_2",
    "text": "• AI-Powered Observability & Autoscaling - Develop AI -driven observability, \nanomaly detection, root -cause analysis, and autoscaling frameworks for \nlarge -scale distributed systems and microservices platforms. • CI/CD & Platform Integration - Embed AI/ML solutions into CI/CD pipelines, \nmonitoring systems, and platform APIs to support continuous delivery, \nexperimentation, and operational intelligence. • Cross -Functional Collaboration - Collaborate closely with platform, \ninfrastructure, SRE, and product engineering teams to deliver high -impact, \nAI-enabled operational experiences. • Technical Leadership & SME Role - Serve as a subject matter expert across \nGenerative AI, agentic architectures, ML optimization techniques, and large -\nscale system design. • Mentorship & Best Practices - Mentor engineers on ML system design, \nprompt engineering strategies, Python best practices, code quality, testing, \nand experimentation methodologies. Required Technical And Professional Expertise  \n  \n• Agentic AI & Multi -Agent Systems - Strong hands -on experience building \nagentic and multi -agent systems using frameworks such as LangChain, \nLangGraph, or equivalent, with deep understanding of multi -step reasoning, \nplanning, and tool invocation.",
    "metadata": {
      "job_title": "Senior / Lead AI Engineer – Agentic & Generative AI Systems",
      "company": "IBM",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 42,
    "job_id": "IBM",
    "chunk_id": 5,
    "source_file": "IBM.pdf",
    "folder": "D:/Project_2",
    "text": "• Mentorship & Best Practices - Mentor engineers on ML system design, \nprompt engineering strategies, Python best practices, code quality, testing, \nand experimentation methodologies. Required Technical And Professional Expertise  \n  \n• Agentic AI & Multi -Agent Systems - Strong hands -on experience building \nagentic and multi -agent systems using frameworks such as LangChain, \nLangGraph, or equivalent, with deep understanding of multi -step reasoning, \nplanning, and tool invocation. • Prompt Engineering & LLM Control - Expertise in prompt engineering, prompt \ntemplating, structured outputs, evaluation, and guardrails to ensure reliable, controllable, and secure LLM behavior in production. • Python & Production Engineering Excellence - Advanced Python skills with \nstrong adherence to best practices, including modular design, async \nprogramming, type hints, testing frameworks, performance optimization, \nand secure coding standards. • LLM Inference & Performance Optimization - Proven experience optimizing \nLLM inference at scale using techniques such as KV caching, quantization, batching, and efficient model serving. • End -to-End ML Systems Ownership - Demonstrated ownership of ML \nsystems across the full lifecycle—from data ingestion and feature pipelines to deployment, monitoring, and continuous improvement.",
    "metadata": {
      "job_title": "Senior / Lead AI Engineer – Agentic & Generative AI Systems",
      "company": "IBM",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 43,
    "job_id": "IBM",
    "chunk_id": 6,
    "source_file": "IBM.pdf",
    "folder": "D:/Project_2",
    "text": "• LLM Inference & Performance Optimization - Proven experience optimizing \nLLM inference at scale using techniques such as KV caching, quantization, batching, and efficient model serving. • End -to-End ML Systems Ownership - Demonstrated ownership of ML \nsystems across the full lifecycle—from data ingestion and feature pipelines to deployment, monitoring, and continuous improvement. • Large -Scale Distributed Systems - Experience designing and operating AI \nsystems for large -scale distributed platforms, including multi -agent \noperations across infrastructure and cloud environments (e.g., MSCP servers and complex operational ecosystems). Preferred Technical And Professional Experience  \n  \n• Experience with AIOps, autonomous remediation, and self -healing systems  \n• Familiarity with Kubernetes and cloud-native observability stacks \n• Prior experience delivering production -grade Generative AI or AI platform \nservices",
    "metadata": {
      "job_title": "Senior / Lead AI Engineer – Agentic & Generative AI Systems",
      "company": "IBM",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 44,
    "job_id": "Infineon",
    "chunk_id": 1,
    "source_file": "Infineon.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Inﬁneon Technologies  \nJob role     :  Senior Engineer AI/ML  \nLocation  : Bengaluru  East , Karnataka, India  \nAbout the job  \n• #WeAreIn to program innovative solutions for tomorrow’s challenges. Are \nyou in? As a Senior Enginer AI you will be responsible for designing, \ndeveloping, and deploying artiﬁcial intelligence (AI) models and ecosystem that can generate human -like content, such as text, images, and \nvideos.Additionally you will be developing innovative solutions that leverage the power of generative AI to drive business value and improve customer \nexperiences. Your Role  \n Key responsibilities in your new role \n \n \n• Design and develop algorithms for generative models using deep learning techniques for VP work products. • Collaborate with cross -functional teams to integrate generative AI solutions \ninto existing VP workﬂow systems. • Research and stay up to date on the latest advancements in generative AI technologies and methodologies.",
    "metadata": {
      "job_title": "Senior Engineer AI/ML",
      "company": "Inﬁneon Technologies",
      "location": "Bengaluru  East , Karnataka, India"
    }
  },
  {
    "vector_id": 45,
    "job_id": "Infineon",
    "chunk_id": 2,
    "source_file": "Infineon.pdf",
    "folder": "D:/Project_2",
    "text": "• Collaborate with cross -functional teams to integrate generative AI solutions \ninto existing VP workﬂow systems. • Research and stay up to date on the latest advancements in generative AI technologies and methodologies. • Optimize and ﬁne -tune generative models for performance and efficiency. • Troubleshoot and resolve issues related to generative AI models and implementations. • Create and maintain documentation for generative AI models and their applications. • Communicate complex technical concepts and ﬁndings to non-technical \nStakeholders  \n  \n• Your Proﬁle  \n Qualiﬁcations And Skills To Help You Succeed  \n \n \n• Strong background in C++/System -C/ TLM 2.0 on various development \nplatform (Windows/Linux etc)  \n• Graduate or Post graduate in Engineering with Minimum of 3+ years of relevant experience  \n• Development of functional/cycle approximate models using SystemC and \ntools such as Synopsys Virtualizer, ASTC,VLAB etc.",
    "metadata": {
      "job_title": "Senior Engineer AI/ML",
      "company": "Inﬁneon Technologies",
      "location": "Bengaluru  East , Karnataka, India"
    }
  },
  {
    "vector_id": 46,
    "job_id": "Infineon",
    "chunk_id": 3,
    "source_file": "Infineon.pdf",
    "folder": "D:/Project_2",
    "text": "• Create and maintain documentation for generative AI models and their applications. • Communicate complex technical concepts and ﬁndings to non-technical \nStakeholders  \n  \n• Your Proﬁle  \n Qualiﬁcations And Skills To Help You Succeed  \n \n \n• Strong background in C++/System -C/ TLM 2.0 on various development \nplatform (Windows/Linux etc)  \n• Graduate or Post graduate in Engineering with Minimum of 3+ years of relevant experience  \n• Development of functional/cycle approximate models using SystemC and \ntools such as Synopsys Virtualizer, ASTC,VLAB etc. based on Visual Studio, \ng++ (for Linux)  \n• Proﬁcient knowledge of computer architecture, embedded CPU (ARM/RISC -\nV), real -time systems, OS, Automotive communication platforms (Ethernet, \nCAN, FlexRay etc.) • Veriﬁcation of models using various methods, such as standalone SystemC \nbased unit veriﬁcation, co -simulation with RTL (System Verilog) and SW \nbased system testing etc. • Embedded system test development using C/C++ and automated \nexecution/debugging. • Hands -on experience on embedded compilers such as GNU, Tasking etc.",
    "metadata": {
      "job_title": "Senior Engineer AI/ML",
      "company": "Inﬁneon Technologies",
      "location": "Bengaluru  East , Karnataka, India"
    }
  },
  {
    "vector_id": 47,
    "job_id": "Infineon",
    "chunk_id": 4,
    "source_file": "Infineon.pdf",
    "folder": "D:/Project_2",
    "text": "• Embedded system test development using C/C++ and automated \nexecution/debugging. • Hands -on experience on embedded compilers such as GNU, Tasking etc. and debuggers such as PLS, Lauterbach T32 etc…  \n• Strong background in machine learning and deep learning algorithms. • Ability to design and implement scalable and efficient AI system  \n• Advanced knowledge of natural language processing for text generation task  \n• Ability to stay updated with the latest advancements in generative AI research and incorporate them into work  \n• Proﬁciency in Python, TensorFlow, and PyTorch for developing AI models  \n• Hand -on experience in Version Control Systems, Change Management \nSystems ,familiar with Atlassian tools including JIRA, Conﬂuence and Bitbucket  \n• Highly motivated and willing to take responsibility & ownership and adhere \nto the deadlines.Able to work well independently and in a team. • Excellent interpersonal & communication skills, ability to work with cross -\nfunctional teams and leadership capabilities  \n• Excellent problem solving and analytical skills Good team player in a multi -\nsite/multi -cultural work environment  \n \n \n•",
    "metadata": {
      "job_title": "Senior Engineer AI/ML",
      "company": "Inﬁneon Technologies",
      "location": "Bengaluru  East , Karnataka, India"
    }
  },
  {
    "vector_id": 48,
    "job_id": "Infineon",
    "chunk_id": 5,
    "source_file": "Infineon.pdf",
    "folder": "D:/Project_2",
    "text": "• Excellent interpersonal & communication skills, ability to work with cross -\nfunctional teams and leadership capabilities  \n• Excellent problem solving and analytical skills Good team player in a multi -\nsite/multi -cultural work environment  \n \n \n•",
    "metadata": {
      "job_title": "Senior Engineer AI/ML",
      "company": "Inﬁneon Technologies",
      "location": "Bengaluru  East , Karnataka, India"
    }
  },
  {
    "vector_id": 49,
    "job_id": "Infosys",
    "chunk_id": 1,
    "source_file": "Infosys.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Infosys  \nJob role     :  Computer Vision  \nLocation  : Bengaluru East, Karnataka, India About the job  \nJob Description  \n• Primary skills:Technology ->Artiﬁcial Intelligence ->Computer Vision  \n \n \nA day in the life of an Infoscion \n \n \n•  As part of the Infosys delivery team, your primary role would be to interface \nwith the client for quality assurance, issue resolution and ensuring high \ncustomer satisfaction. •  You will understand requirements, create and review designs, validate the \narchitecture and ensure high levels of service offerings to clients in the technology domain. •  You will participate in project estimation, provide inputs for solution \ndelivery, conduct technical risk planning, perform code reviews and unit test \nplan reviews. •  You will lead and guide your teams towards developing optimized high \nquality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes. •  You would be a key contributor to building efficient programs/ systems and \nif you think you ﬁt right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you ﬁt \nright in to help our c lients navigate their next in their digital transformation \njourney, this is the place for you!",
    "metadata": {
      "job_title": "Computer Vision",
      "company": "Infosys",
      "location": "Bengaluru East, Karnataka, India About the job"
    }
  },
  {
    "vector_id": 50,
    "job_id": "Infosys",
    "chunk_id": 2,
    "source_file": "Infosys.pdf",
    "folder": "D:/Project_2",
    "text": "•  You would be a key contributor to building efficient programs/ systems and \nif you think you ﬁt right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you ﬁt \nright in to help our c lients navigate their next in their digital transformation \njourney, this is the place for you! •  Knowledge of more than one technology  \n•  Basics of Architecture and Design fundamentals  \n•  Knowledge of Testing tools \n•  Knowledge of agile methodologies  \n•  Understanding of Project life cycle activities on development and \nmaintenance projects  \n•  Understanding of one or more Estimation methodologies, Knowledge of \nQuality processes  \n•  Basics of business domain to understand the business requirements \n•  Analytical abilities, Strong Technical Skills, Good communication skills  \n•  Good understanding of the technology and domain \n•  Ability to demonstrate a sound understanding of software quality assurance \nprinciples, SOLID design principles and modelling methods  \n•  Awareness of latest technologies and trends  \n•  Excellent problem solving, analytical and debugging skills",
    "metadata": {
      "job_title": "Computer Vision",
      "company": "Infosys",
      "location": "Bengaluru East, Karnataka, India About the job"
    }
  },
  {
    "vector_id": 51,
    "job_id": "Intel",
    "chunk_id": 1,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Intel  \nJob role     :  TCAD Machine Learning Engineer  \nLocation  : Bengaluru, Karnataka, India  \nAbout the job \nJob Details  \n \nJob Description:  \n \nJoin Intel and build a better tomorrow. Intel is during an exciting transformation, \nwith a vision to create and extend computing technology to connect and enrich the \nlives of every person on Earth. So, join us and help us create the next generation of \ntech nologies that will shape the future for decades to come. Are you an engineer/physicist who loves programming? Do you enjoy creating \nmachine learning models so that you can run them through a computer to answer \nquestions that  cannot be answered otherwise? Do you take pride in optimizing \ncodes to reduce runtime?",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 52,
    "job_id": "Intel",
    "chunk_id": 2,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "Do you enjoy creating \nmachine learning models so that you can run them through a computer to answer \nquestions that  cannot be answered otherwise? Do you take pride in optimizing \ncodes to reduce runtime? If your answer is yes, come join our team - we are looking \nfor you. We are a team of software developers with strong engineering and physics background responsible for creating physics -based simulation and machine \nlearning tools that are essential for developing next generation, angstrom -era Intel \ntransistors. Responsibilities Include, But Are Not Limited To  \n  \n•  Developing and training new machine learning models and improving \nexisting ones. •  Developing new capabilities to existing ML based software solutions, \ndebugging and ﬁxing bugs, and writing testcases.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 53,
    "job_id": "Intel",
    "chunk_id": 3,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "Responsibilities Include, But Are Not Limited To  \n  \n•  Developing and training new machine learning models and improving \nexisting ones. •  Developing new capabilities to existing ML based software solutions, \ndebugging and ﬁxing bugs, and writing testcases. •  Collaborating directly with the applications engineers in the US and other \ngeographies to provide support and address feature requests. •  Converting projects from proof -of-concept stage to production ready. •  Maintain and develop software infrastructure. Creating software simulation \nﬂows, developing physical models, and analyzing the fundamental device \nand process issues encountered in cutting -edge technology development.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 54,
    "job_id": "Intel",
    "chunk_id": 4,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "•  Maintain and develop software infrastructure. Creating software simulation \nﬂows, developing physical models, and analyzing the fundamental device \nand process issues encountered in cutting -edge technology development. •  Collaborating directly with the experimental research, process, and design \nteams to deﬁne experiments and present recommendations that achieve \nthe scaling path for the logic, memory, and analog devices in advanced -\nnode, industry -leading products. What We Offer  \n \n \n•  We give you opportunities to transform technology and create a better \nfuture, by delivering products that touch the lives of every person on earth. •  As a global leader in innovation and new technology, we foster a \ncollaborative, supportive, and exciting environment where the brightest \nminds in the world come together to achieve exceptional results. •  We provide beneﬁts that promote a healthy, enjoyable life: excellent \nmedical plans, wellness programs, and amenities, time off, recreational activities, discounts on various products and services, and much more creative perks that make Intel a Great Place to Work  \n•  We're constantly working on making a more connected and intelligent \nfuture, and we need your help.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 55,
    "job_id": "Intel",
    "chunk_id": 5,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "•  As a global leader in innovation and new technology, we foster a \ncollaborative, supportive, and exciting environment where the brightest \nminds in the world come together to achieve exceptional results. •  We provide beneﬁts that promote a healthy, enjoyable life: excellent \nmedical plans, wellness programs, and amenities, time off, recreational activities, discounts on various products and services, and much more creative perks that make Intel a Great Place to Work  \n•  We're constantly working on making a more connected and intelligent \nfuture, and we need your help. Change tomorrow. Start today. Qualiﬁcations  \n You must possess the minimum qualiﬁcations below to be initially considered for \nthis position. Preferred qualiﬁcations are in addition to the minimum requirements and are considered a plus factor in identifying top candidates.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 56,
    "job_id": "Intel",
    "chunk_id": 6,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "Qualiﬁcations  \n You must possess the minimum qualiﬁcations below to be initially considered for \nthis position. Preferred qualiﬁcations are in addition to the minimum requirements and are considered a plus factor in identifying top candidates. The experience \nlisted below  may be obtained through schoolwork, classes and project work, \ninternships, military training, and/or work experience. Minimum Qualiﬁcations  \n \n \n•  Candidate must be pursuing or recently completed an PhD in Electrical \nEngineering, Physics, Mechanical Engineering, Chemical Engineering, Mathematics, Computer Science and Engineering, Physics, Mathematics, or \nother relevant related degrees with a software focus. •  A minimum of 1 years of research/thesis experience in building machine \nlearning / deep learning models. •  A minimum of 1 years of experience in software development through \nacademic projects and/or research.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 57,
    "job_id": "Intel",
    "chunk_id": 7,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "•  A minimum of 1 years of research/thesis experience in building machine \nlearning / deep learning models. •  A minimum of 1 years of experience in software development through \nacademic projects and/or research. •  Proﬁcient in Python, C/C++, or any other similar programming languages. Familiar with backend and front -end web application development. Preferred Qualiﬁcations  \n  \n•  A strong background in data structure and algorithms, and software \ndevelopment. •  A strong background in statistics, linear algebra and solid-state device \nphysics.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 58,
    "job_id": "Intel",
    "chunk_id": 8,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "Preferred Qualiﬁcations  \n  \n•  A strong background in data structure and algorithms, and software \ndevelopment. •  A strong background in statistics, linear algebra and solid-state device \nphysics. •  2+ years of experience in developing full -stack web applications using \nframeworks like Flask, Django, Angular, and React. •  2+ years of experience in software development in high performance \ncomputing, computation modeling and numerical methods. •  Publications and/or open -source projects that demonstrate expertise in \nareas such as machine learning, device physics or process ﬂow physics. Job Type \n \nCollege Grad  \n \nShift  \n Shift 1 (India)  \n \nPrimary Location:  \n India, Bangalore  \n Additional Locations:  \n \nBusiness Group  \n \nIntel Foundry strives to make every facet of semiconductor manufacturing state -of-\nthe-art while delighting our customers -- from delivering cutting -edge silicon \nprocess and packaging technology leadership for the AI era, enabling our \ncustomers to design leadership products, global manufacturing scale and supply chain, through the continuous yield improvements to advanced packaging all the \nway to ﬁnal test and assembly.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 59,
    "job_id": "Intel",
    "chunk_id": 9,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "•  Publications and/or open -source projects that demonstrate expertise in \nareas such as machine learning, device physics or process ﬂow physics. Job Type \n \nCollege Grad  \n \nShift  \n Shift 1 (India)  \n \nPrimary Location:  \n India, Bangalore  \n Additional Locations:  \n \nBusiness Group  \n \nIntel Foundry strives to make every facet of semiconductor manufacturing state -of-\nthe-art while delighting our customers -- from delivering cutting -edge silicon \nprocess and packaging technology leadership for the AI era, enabling our \ncustomers to design leadership products, global manufacturing scale and supply chain, through the continuous yield improvements to advanced packaging all the \nway to ﬁnal test and assembly. We ensure our foundry customers' products receive \nour utmost focus in te rms of service, technology enablement and capacity \ncommitments. Employees in the Foundry Technology Manufacturing are part of a worldwide factory network that designs, develops, manufactures, and assembly/test packages the compute devices to improve the li ves of every person \non Earth. Posting Statement  \n \nAll qualiﬁed applicants will receive consideration for employment without regard \nto race, color, religion, religious creed, sex, national origin, ancestry, age, physical \nor mental disability, medical condi tion, genetic information, military and veteran \nstatus, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or \nordinance. Position of Trust  \n N/A  \n \nWork Model for this Role  \n This role will be eligible for our hybrid work model which allows employees to split \ntheir time between working on-site at their assigned Intel site and off -site.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 60,
    "job_id": "Intel",
    "chunk_id": 10,
    "source_file": "Intel.pdf",
    "folder": "D:/Project_2",
    "text": "Posting Statement  \n \nAll qualiﬁed applicants will receive consideration for employment without regard \nto race, color, religion, religious creed, sex, national origin, ancestry, age, physical \nor mental disability, medical condi tion, genetic information, military and veteran \nstatus, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or \nordinance. Position of Trust  \n N/A  \n \nWork Model for this Role  \n This role will be eligible for our hybrid work model which allows employees to split \ntheir time between working on-site at their assigned Intel site and off -site. * Job \nposting details (such as work model, location or time type) are sub ject to change.",
    "metadata": {
      "job_title": "TCAD Machine Learning Engineer",
      "company": "Intel",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 61,
    "job_id": "intelo",
    "chunk_id": 1,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Intelo.ai  \nJob role     :  Staff Engineer  \nLocation  : Kochi, Kerala, India  \nAbout the job  \n• About Intelo.ai  \n• We are building the  Operating System for Collaborative Intelligence in Retail. • While others are trying to replace humans with \"Black Box\" AI, Intelo is \nbuilding a  \"Glass Box\" —a collaborative merchandising platform where 18 \nspecialized AI Agents work alongside retail teams to solve complex planning, pricing, and inventory problems. We don’t just automate tasks; we \nenable Agentic Workﬂows  that allow planners to move from data operators \nto strategic directors. • We are a fast -growing, venture -backed company moving at breakneck \nspeed. We are looking for engineers who are \"Customer Love Obsessed\" and ready to \"Dare to Fail\" as we redeﬁne how billion -dollar retailers operate. •  \n \n• The Role:   \n• We are looking for two Staff Engineers  to serve as the technical anchors in \nour engineer team.",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 62,
    "job_id": "intelo",
    "chunk_id": 2,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "We are looking for engineers who are \"Customer Love Obsessed\" and ready to \"Dare to Fail\" as we redeﬁne how billion -dollar retailers operate. •  \n \n• The Role:   \n• We are looking for two Staff Engineers  to serve as the technical anchors in \nour engineer team. •   \n• This is not a people management role. You will not be approving vacation \ndays or managing HR issues. You will be a  Player -Coach: a high -level \nindividual contributor who sets the technical standard, writes the most \ncomplex code, and mentors a group of talented engineers. • You will own the  \"How\": How we architect multi -agent systems, how we \nautomate our own coding workﬂows, and how we scale our platform to \nhandle enterprise-grade complexity.",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 63,
    "job_id": "intelo",
    "chunk_id": 3,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "You will be a  Player -Coach: a high -level \nindividual contributor who sets the technical standard, writes the most \ncomplex code, and mentors a group of talented engineers. • You will own the  \"How\": How we architect multi -agent systems, how we \nautomate our own coding workﬂows, and how we scale our platform to \nhandle enterprise-grade complexity. •  \n \n• What You Will Do \n• 1. Build the Agentic Future  \n• Design and build sophisticated  Multi -Agent Systems using frameworks and \ncustom orchestrators. • Implement  Agent -to-Agent (A2A) communication protocols and  Model \nContext Protocols (MCP) that allow our AI to securely access client data \n(Azure Data Lake, SAP, Oracle) and \"think\" before it acts. • User machine learning to build sophisticated model for demand prediction, \nclustering etc  \n• Ensure our \"Human-in -the-Loop\" architecture remains transparent, \nexplainable, and trustworthy for enterprise users.",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 64,
    "job_id": "intelo",
    "chunk_id": 4,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "• Implement  Agent -to-Agent (A2A) communication protocols and  Model \nContext Protocols (MCP) that allow our AI to securely access client data \n(Azure Data Lake, SAP, Oracle) and \"think\" before it acts. • User machine learning to build sophisticated model for demand prediction, \nclustering etc  \n• Ensure our \"Human-in -the-Loop\" architecture remains transparent, \nexplainable, and trustworthy for enterprise users. •   \n• 2. Drive \"Code Automation\" & The Golden Path  \n• We believe in engineers who don't need to be managed because the  system \nmanages the quality. • You will build the  \"Golden Path\" : the internal tools, CI/CD pipelines, and AI -\nassisted coding workﬂows (Cursor/Copilot contexts) that allow your teams \nto ship safely and autonomously. • You will review the PRs and set the bar for code quality, ensuring we never ship \"spaghetti code\" to hit a deadline.",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 65,
    "job_id": "intelo",
    "chunk_id": 5,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "• You will build the  \"Golden Path\" : the internal tools, CI/CD pipelines, and AI -\nassisted coding workﬂows (Cursor/Copilot contexts) that allow your teams \nto ship safely and autonomously. • You will review the PRs and set the bar for code quality, ensuring we never ship \"spaghetti code\" to hit a deadline. •   \n• 3. Mentor & Elevate   \n• You will be the technical lead for key agents. • Your job is to unblock your team. When a Senior Engineer is stuck on a race \ncondition, you sit with them and solve it.",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 66,
    "job_id": "intelo",
    "chunk_id": 6,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "• Your job is to unblock your team. When a Senior Engineer is stuck on a race \ncondition, you sit with them and solve it. • You will partner with the  Principal Engineer to ensure technical feasibility \nmeets business velocity. •  \n \n• What We Are Looking For  \n• You are a Builder ﬁrst:  You still love writing code. You are uncomfortable if \nyou go a week without committing to the repo. • System Design Expert:  You have experience designing distributed systems, \nevent -driven architectures, or high-scale data pipelines.",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 67,
    "job_id": "intelo",
    "chunk_id": 7,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "You are uncomfortable if \nyou go a week without committing to the repo. • System Design Expert:  You have experience designing distributed systems, \nevent -driven architectures, or high-scale data pipelines. • AI/LLM Pragmatism:  You have hands -on experience (or deep curiosity) with \nLLM orchestration, RAG pipelines, or Agentic frameworks. You know the \ndifference between a cool demo and a production -grade agent. • Force Multiplier:  You have a track record of making the engineers around you \nbetter through code reviews, design docs, and mentorship. • \"Keep It Simple\" Mindset:  You ﬁght against over -engineering.",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 68,
    "job_id": "intelo",
    "chunk_id": 8,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "• Force Multiplier:  You have a track record of making the engineers around you \nbetter through code reviews, design docs, and mentorship. • \"Keep It Simple\" Mindset:  You ﬁght against over -engineering. You know that \nthe best code is the code you don't have to write. •  \n \n• Our Tech Stack  \n• Core: Python (Heavy usage for Agents/Data), TypeScript/React (Frontend), \nNode.js/Go (Services). • AI/Data: Azure OpenAI, LangChain/Semantic Kernel, Vector Databases \n(Pinecone/Weaviate), Azure Data Lake. • Infrastructure:  Kubernetes, Terraform, GitHub Actions (Heavy automation).",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 69,
    "job_id": "intelo",
    "chunk_id": 9,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "• AI/Data: Azure OpenAI, LangChain/Semantic Kernel, Vector Databases \n(Pinecone/Weaviate), Azure Data Lake. • Infrastructure:  Kubernetes, Terraform, GitHub Actions (Heavy automation). •  \n \n• Why Join Now? • Impact: You will be one of the top two technical leaders in the company, \nreporting directly to the executive leadership. • Autonomy:  We don't believe in micromanagement. We deﬁne the Goal, and \nyou deﬁne the  Solution .",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 70,
    "job_id": "intelo",
    "chunk_id": 10,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "• Autonomy:  We don't believe in micromanagement. We deﬁne the Goal, and \nyou deﬁne the  Solution . • Culture: We live by  \"Live Intelo\" —transparency, open communication, and \nno ego. You will work with a leadership team that values technical excellence as much as sales revenue. • How to Apply  \n• Send.your.GitHub― Portfolio.and.a.brief.note.on.the.hardest.ƒAgenticƒ.or. ƒAutomationƒ.problem.you\"ve.solved.recently¡  \n•",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 71,
    "job_id": "intelo",
    "chunk_id": 11,
    "source_file": "intelo.pdf",
    "folder": "D:/Project_2",
    "text": "• How to Apply  \n• Send.your.GitHub― Portfolio.and.a.brief.note.on.the.hardest.ƒAgenticƒ.or. ƒAutomationƒ.problem.you\"ve.solved.recently¡  \n•",
    "metadata": {
      "job_title": "Staff Engineer",
      "company": "Intelo.ai",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 72,
    "job_id": "job profile_1",
    "chunk_id": 1,
    "source_file": "job profile_1.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  EPAM Systems  \nJob role   : Senior Software Engineer - C++, Linux, Any \nDatabases \nLocation  : Coimbatore, Tamil Nadu \nAbout t he job \nWe ar e see king a dedicate d Seni or Softwar e Engineer wit h expertis e in C+ +, Linux , and \ndatabases to contribut e to the design , developmen t, and deployme nt of database-centri c back-\nend solutions i n an Agile environment. Join a tea m focus ed on deli vering impactf ul commerci al solutio ns while engagi ng global \ncustomer s and adopti ng new technologies. Responsibilities \nD\nesign, develop, and deploy software projects\nSupport technical queries and impact analysis\nParticipate in technical peer reviews and design discussions\nCollaborate in requirement sessions and deliver solutions within iterations\nTranslate stories into actionable tasks during sprint planning and retrospectives\nDocument knowledge and share insights across the team\nApply principles and patterns in software architecture and design\nEnsure adherence to financial security standards where required\nManage multiple tasks while working with distributed teams\nUse Agile methodologies such as Scrum or SAFe\nHave a deep understandi ng of software patterns and technical solutions\nRequirements  \n5 to 8 years of experience in software development\nBackground in C, C++, and shell scripting\nProficiency in Oracle database, SQL, and Linux commands\nKnowledge of OOA/OOD principles, test-driven development, and Agile processes\nExpertise in software architecture, design principles, and patterns\nExperience with global customer collaboration and diverse project teams\nFlexibility to work in database-centric back-end environments and file-based 3rd party\nc\nommunication\nStrong communication skills with the ability to present technical solutions effectively\nFamiliarity with PCI, PII, and financial security requirements preferred",
    "metadata": {
      "job_title": "Senior Software Engineer - C++, Linux, Any",
      "company": "EPAM Systems",
      "location": "Coimbatore, Tamil Nadu"
    }
  },
  {
    "vector_id": 73,
    "job_id": "job profile_10",
    "chunk_id": 1,
    "source_file": "job profile_10.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  Empnéo ICT  \n \n \nJob role     Senior Java Develope r \n \n Location  Kochi, Kerala, Indi a \nAbout the job  \nKnowledge  and Skill Requirem ents:  \n Strong  Analytical  and Problem -Solving  skills.  Strong  understanding  and working  knowledge  of basic  Algorithms  and Data  Structures.  Strong  analytical  and problem -solving  skills  to diagnose  and resolve  complex  technical  \nissues.  Discipline  in Test Driven  Development.  Very good  understanding  and experience  with Authentication  based  systems  like OAuth2,  \nSSO, Azure  AD and basic  Cryptography.  Exceptional  experience  and working  knowledge  of Java technologies  and Spring  \nframework.",
    "metadata": {
      "job_title": "Senior Java Develope r",
      "company": "Empnéo ICT",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 74,
    "job_id": "job profile_10",
    "chunk_id": 2,
    "source_file": "job profile_10.pdf",
    "folder": "D:/Project_2",
    "text": " Very good  understanding  and experience  with Authentication  based  systems  like OAuth2,  \nSSO, Azure  AD and basic  Cryptography.  Exceptional  experience  and working  knowledge  of Java technologies  and Spring  \nframework.  Good  understanding  of Micro -Services  Design,  Object  Oriented  Programming  and \nService  Oriented  Architecture.  Experience  in implementing  Microservices  using  Kubernetes,  Dockers,  Java Spring  \nframework,  JPA, PL/SQL  and DB like MySQL,  Oracle,  MS-SQL over MS Azure  or AWS  \nClouds.  Experience  with Java frameworks  and libraries  commonly  used  in backend  development,  \nsuch as Spring,  JPA, Hibernate,  Apache  Kafka,  or JAX-RS.  Experience  in developing,  maintaining,  troubleshooting  and deploying  backend  \napplications  over Cloud  solutions  like Microsoft  Azure  and AWS.",
    "metadata": {
      "job_title": "Senior Java Develope r",
      "company": "Empnéo ICT",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 75,
    "job_id": "job profile_10",
    "chunk_id": 3,
    "source_file": "job profile_10.pdf",
    "folder": "D:/Project_2",
    "text": " Experience  with Java frameworks  and libraries  commonly  used  in backend  development,  \nsuch as Spring,  JPA, Hibernate,  Apache  Kafka,  or JAX-RS.  Experience  in developing,  maintaining,  troubleshooting  and deploying  backend  \napplications  over Cloud  solutions  like Microsoft  Azure  and AWS.  Well-versed  with cloud  solutions  for computing,  storage,  DB, identity,  security,  \nnetworking,  access/permission,  app hosting,  app monitoring,  logging,  scaling  and \navailability  needs.  Experience  in writing  complex  SQL queries,  procedures  and functions.  Experience  in Docker  Containers,  build  and deployment  in a container  environment.  Experience  with SQL, NoSQL,  database  systems.",
    "metadata": {
      "job_title": "Senior Java Develope r",
      "company": "Empnéo ICT",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 76,
    "job_id": "job profile_10",
    "chunk_id": 4,
    "source_file": "job profile_10.pdf",
    "folder": "D:/Project_2",
    "text": " Experience  in Docker  Containers,  build  and deployment  in a container  environment.  Experience  with SQL, NoSQL,  database  systems.  Detailed  knowledge  of the JVM Platform.  Comfortable  with Linux  command -line interface.  Experi ence  working  with Git in a CI/CD  environment.  Experience  with JIRA/Confluence  or similar  tools  \n Strong  knowledge  of continuous  integration  practices.",
    "metadata": {
      "job_title": "Senior Java Develope r",
      "company": "Empnéo ICT",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 77,
    "job_id": "job profile_10",
    "chunk_id": 5,
    "source_file": "job profile_10.pdf",
    "folder": "D:/Project_2",
    "text": " Experi ence  working  with Git in a CI/CD  environment.  Experience  with JIRA/Confluence  or similar  tools  \n Strong  knowledge  of continuous  integration  practices.  Experience  and thorough  understanding  of Agile  Software  Development  \n Strong  communication  and soft skills,  able to motivate,  mentor  and help fellow  \ndevelopers  as well as communicate  complex  ideas  effectively.  Detail -oriented  and exceptional  organizational  skills  \n Excellent  verbal  and written  communication  skills \n Exercises  independence  and self-motivation  while  still being  able to work  with others  \ncollaboratively  with ability  to thrive  in a fast-paced,  high-energy  environment. Self-\nmotivated  with positive  energy",
    "metadata": {
      "job_title": "Senior Java Develope r",
      "company": "Empnéo ICT",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 78,
    "job_id": "job profile_10",
    "chunk_id": 6,
    "source_file": "job profile_10.pdf",
    "folder": "D:/Project_2",
    "text": "Self-\nmotivated  with positive  energy",
    "metadata": {
      "job_title": "Senior Java Develope r",
      "company": "Empnéo ICT",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 79,
    "job_id": "job profile_2",
    "chunk_id": 1,
    "source_file": "job profile_2.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  CrowdStrik e \nJob role     :  Sr. Software Engine er - Rust (Remote, \nIND) \n Location  : Greater  Coimbatore  Area  \n \nAbout the job  \nAs a global leader in cybersecurity, CrowdStrike protects the people, processes and technologies \nthat drive modern organizations. Since 2011, our mission hasn’t changed — we’re here to stop \nbreaches, and we’ve redefined modern security with the world’s most advanced AI -native \nplatform. Our customers span all industries, and they count on CrowdStrike to keep their \nbusinesses running, their communities safe and their lives moving forward. We’re a lso a mission -\ndriven company. We cultivate a culture that gives every CrowdStriker both the flexibility and \nautonomy to own their careers. We’re always looking to add talented CrowdStrikers to the team \nwho have limitless passion, a relentless focus on inno vation and a fanatical commitment to our \ncustomers, our community and each other.",
    "metadata": {
      "job_title": "Sr. Software Engine er - Rust (Remote,",
      "company": "CrowdStrik e",
      "location": "Greater  Coimbatore  Area"
    }
  },
  {
    "vector_id": 80,
    "job_id": "job profile_2",
    "chunk_id": 2,
    "source_file": "job profile_2.pdf",
    "folder": "D:/Project_2",
    "text": "We cultivate a culture that gives every CrowdStriker both the flexibility and \nautonomy to own their careers. We’re always looking to add talented CrowdStrikers to the team \nwho have limitless passion, a relentless focus on inno vation and a fanatical commitment to our \ncustomers, our community and each other. Ready to join a mission that matters? The future of \ncybersecurity starts with you . The Product : \n \nYou will be part of the Data Science Software Development team. You’ll have the opportunity to \nimplement technologies as libraries and software development kits for internal/external \ncustomers and to jointly work with Machine Learning experts on creating predictive models on a \ndiverse and multidisciplinary tea m \n \nAbout  The Role: \n \nWe are looking to hir e Sr. Software  Engineer  - Rust/  C++ ( Remote ) focused on developing, \nunit testing, integration testing, feature development, significant reverse engineering, malware \nanalysis and file format experience to our growing team You will be pa rt of CrowdStrike’s Data \nScience team who is expanding - we are at the exciting intersection of Machine Learning, Big \nData, and Security and are looking to add a senior software engineer with .",
    "metadata": {
      "job_title": "Sr. Software Engine er - Rust (Remote,",
      "company": "CrowdStrik e",
      "location": "Greater  Coimbatore  Area"
    }
  },
  {
    "vector_id": 81,
    "job_id": "job profile_2",
    "chunk_id": 3,
    "source_file": "job profile_2.pdf",
    "folder": "D:/Project_2",
    "text": "The Product : \n \nYou will be part of the Data Science Software Development team. You’ll have the opportunity to \nimplement technologies as libraries and software development kits for internal/external \ncustomers and to jointly work with Machine Learning experts on creating predictive models on a \ndiverse and multidisciplinary tea m \n \nAbout  The Role: \n \nWe are looking to hir e Sr. Software  Engineer  - Rust/  C++ ( Remote ) focused on developing, \nunit testing, integration testing, feature development, significant reverse engineering, malware \nanalysis and file format experience to our growing team You will be pa rt of CrowdStrike’s Data \nScience team who is expanding - we are at the exciting intersection of Machine Learning, Big \nData, and Security and are looking to add a senior software engineer with . You’ll have the chance to broaden your horizons by working joi ntly with a team of Big Data, \nMachine Learning, and Security domain experts on hard and impactful problems . What  You’ll  Do:  \n \n \n Develop  file format  parsing  and feature  extraction  engines  \n Engineer  new machine  learning  features  in collaboration  with data scientists  \n Design,  implement,  test, optimize  and maintain  features  for internal/external  customers  in \nthe form  of robust  libraries  and software  development  kits \n Document  design  of complex  software  systems  and conduct  thorough  and constructively  \ncritical  software  reviews  \n Expose  simple  APIs to bundle  a variety  of robust  service s \n \n \nWhat  You’ll  Need : \n \n \n An independent  self-starter  who likes to take ownership  and independently  seeks  out \nnew challen ges \n Always  ready  to learn  and step outside  of your comfort  zone  to blaze  the trail for new \ntechnology  \n Proficient  in file formats  like PE, ELF, Mach -O, MS Office,  Zip, Packers  etc.  Reverse  engineering  experience  with C, C++ or Python  \n Python  with 12+ years  of experience  working  with Rust/C/C++  and familiarity  with \nPython  \n Comfortable  with Windows,  macOS  and Linux  platforms  \n Knowledge  of appropriate  algorithms  to solve  complex  technical  problem.  Working  knowledge  of Git, Bitbucket,  Jenkins  and Jira \n Familiar  with different  levels  of software  testing  and know  your way around  Continuous  \nIntegration/Continuous  Delivery  system s \n \n \nBonus  Points : \n \n \n Familiar  with Fuzzing  (e.g.",
    "metadata": {
      "job_title": "Sr. Software Engine er - Rust (Remote,",
      "company": "CrowdStrik e",
      "location": "Greater  Coimbatore  Area"
    }
  },
  {
    "vector_id": 82,
    "job_id": "job profile_2",
    "chunk_id": 4,
    "source_file": "job profile_2.pdf",
    "folder": "D:/Project_2",
    "text": " Reverse  engineering  experience  with C, C++ or Python  \n Python  with 12+ years  of experience  working  with Rust/C/C++  and familiarity  with \nPython  \n Comfortable  with Windows,  macOS  and Linux  platforms  \n Knowledge  of appropriate  algorithms  to solve  complex  technical  problem.  Working  knowledge  of Git, Bitbucket,  Jenkins  and Jira \n Familiar  with different  levels  of software  testing  and know  your way around  Continuous  \nIntegration/Continuous  Delivery  system s \n \n \nBonus  Points : \n \n \n Familiar  with Fuzzing  (e.g. Jazzer/AFL/Peach)  techniques.  Familiar  with software  vulnerabilities  and secure  programming  \n Familiar  with cloud  computing  platform(s)  AWS/GCP/Azure  \n Interested  in Machine  Learnin g \n \n \nBenefits  Of Working  At CrowdStrike :  \n \n \n Remote -friendly  and flexible  work  culture  \n Market  leader  in compensation  and equity  awards  \n Comprehensive  physi cal and mental  wellness  programs  \n Competitive  vacation  and holidays  for recharge  \n Paid parental  and adoption  leaves  \n Professional  development  opportunities  for all employees  regardless  of level or role \n Employee  Networks,  geographic  neighborhood  groups,  and volunteer  opportunities  to \nbuild  connections  \n Vibrant  office  culture  with world  class  amenities  \n Great  Place  to Work  Certified™  across  the globe  \n \n \nCrowdStrike  is proud  to be an equal  opportunity  employer. We are committed  to fostering  a \nculture  of belonging  where  everyone  is valued  for who they are and empowered  to succeed. We \nsupport  veterans  and individuals  with disabilities  through  our affirmative  action  program .",
    "metadata": {
      "job_title": "Sr. Software Engine er - Rust (Remote,",
      "company": "CrowdStrik e",
      "location": "Greater  Coimbatore  Area"
    }
  },
  {
    "vector_id": 83,
    "job_id": "job profile_2",
    "chunk_id": 5,
    "source_file": "job profile_2.pdf",
    "folder": "D:/Project_2",
    "text": "We are committed  to fostering  a \nculture  of belonging  where  everyone  is valued  for who they are and empowered  to succeed. We \nsupport  veterans  and individuals  with disabilities  through  our affirmative  action  program . CrowdStrike  is committed  to providing  equal  employment  opportunity  for all employees  and \napplicants  for employment. The Company  does  not discriminate  in employment  opportunities  or \npractices  on the basis  of race,  color,  creed,  ethnicity,  religion,  sex (including  pregnancy  or \npregnancy -related  medical  conditions),  sexual  orientation,  gender  identity,  marital  or family  \nstatus,  veteran  status,  age, national  origin,  ancestry,  physical  disability  (including  HIV and AIDS),  \nmental  disability,  medical condition,  genetic  information,  membership  or activity  in a local human  \nrights  commission,  status  with regard  to public  assistance,  or any other  characteristic  protected  \nby law. We base all employment  decisions --including  recruitment,  selection,  training, \ncompensation,  benefits,  discipline,  promotions,  transfers,  lay-offs, return  from  lay-off, \nterminations  and social/recreational  programs --on valid job requirements . If you need  assistance  accessing  or reviewing  the information  on this website  or need  help \nsubmitting  an application  for employment  or requesting  an accommodation,  please  contact  us at \nrecruiting@crowdstrike.com  for further  assistance .",
    "metadata": {
      "job_title": "Sr. Software Engine er - Rust (Remote,",
      "company": "CrowdStrik e",
      "location": "Greater  Coimbatore  Area"
    }
  },
  {
    "vector_id": 84,
    "job_id": "job profile_2",
    "chunk_id": 6,
    "source_file": "job profile_2.pdf",
    "folder": "D:/Project_2",
    "text": "We base all employment  decisions --including  recruitment,  selection,  training, \ncompensation,  benefits,  discipline,  promotions,  transfers,  lay-offs, return  from  lay-off, \nterminations  and social/recreational  programs --on valid job requirements . If you need  assistance  accessing  or reviewing  the information  on this website  or need  help \nsubmitting  an application  for employment  or requesting  an accommodation,  please  contact  us at \nrecruiting@crowdstrike.com  for further  assistance . , \n \nBonus  Points : \n \n \n Familiar  with Fuzzing  (e.g. Jazzer/AFL/Peach)  techniques.  Familiar  with software  vulne rabilities  and secure  programming  \n Familiar  with cloud  computing  platform(s)  AWS/GCP/Azure  \n Interested  in Machine  Learnin g",
    "metadata": {
      "job_title": "Sr. Software Engine er - Rust (Remote,",
      "company": "CrowdStrik e",
      "location": "Greater  Coimbatore  Area"
    }
  },
  {
    "vector_id": 85,
    "job_id": "job profile_2",
    "chunk_id": 7,
    "source_file": "job profile_2.pdf",
    "folder": "D:/Project_2",
    "text": " Familiar  with software  vulne rabilities  and secure  programming  \n Familiar  with cloud  computing  platform(s)  AWS/GCP/Azure  \n Interested  in Machine  Learnin g",
    "metadata": {
      "job_title": "Sr. Software Engine er - Rust (Remote,",
      "company": "CrowdStrik e",
      "location": "Greater  Coimbatore  Area"
    }
  },
  {
    "vector_id": 86,
    "job_id": "job profile_3",
    "chunk_id": 1,
    "source_file": "job profile_3.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  Accenture in Indi a  \nJob role     :  Custom Software Enginee r \n Location  : Coimbatore,  Tamil  Nadu,  India \n \nAbout the job  \nProject  Role : Custom Software Enginee r \n \nProject  Role Description  : Develop custom software solutions to design, code, and enhance \ncomponents across systems or applications. Use modern frameworks and agile practices to \ndeliver scalable, high -performing solutions tailored to specific business need s. \n \nMust  have  skills  : SAP ABAP Development for HAN A \n \nGood  to have  skills  : NA \n \nMinimum  3 Year(s)  Of Experience  Is Require d \n \nEducational  Qualification  : 15 years full time educatio n \n \nSummary: As an Application Developer, you will design, build, and configu re applications to meet \nbusiness process and application requirements. A typical day involves collaborating with team \nmembers to understand project needs, developing application features, and ensuring that the \nsolutions align with business objectives. You will also engage in testing and troubleshooting to \nenhance application performance and user experience, while continuously seeking opportunities \nfor improvement and innovation in application development processes. Roles & Responsibilities: \n- Expected to pe rform independently and become an SME. - Required active \nparticipation/contribution in team discussions.",
    "metadata": {
      "job_title": "Custom Software Enginee r",
      "company": "Accenture in Indi a",
      "location": "Coimbatore,  Tamil  Nadu,  India"
    }
  },
  {
    "vector_id": 87,
    "job_id": "job profile_3",
    "chunk_id": 2,
    "source_file": "job profile_3.pdf",
    "folder": "D:/Project_2",
    "text": "Roles & Responsibilities: \n- Expected to pe rform independently and become an SME. - Required active \nparticipation/contribution in team discussions. - Contribute in providing solutions to work related \nproblems. - Assist in the documentation of application specifications and user guides. - Engage in \ncode reviews to ensure quality and adherence to best practices. Professional & Technical Skills: - \nMust To Have Skills: Proficiency in SAP ABAP Development.",
    "metadata": {
      "job_title": "Custom Software Enginee r",
      "company": "Accenture in Indi a",
      "location": "Coimbatore,  Tamil  Nadu,  India"
    }
  },
  {
    "vector_id": 88,
    "job_id": "job profile_3",
    "chunk_id": 3,
    "source_file": "job profile_3.pdf",
    "folder": "D:/Project_2",
    "text": "- Engage in \ncode reviews to ensure quality and adherence to best practices. Professional & Technical Skills: - \nMust To Have Skills: Proficiency in SAP ABAP Development. - Good To Have Skills: Experience with \nSAP Fiori and SAP HANA. - Strong understanding of object -oriented programming principles. - \nExperience with debugging and performance tuning of ABAP programs. - Familiarity with SAP \nmodules such as SD, MM, and FI.",
    "metadata": {
      "job_title": "Custom Software Enginee r",
      "company": "Accenture in Indi a",
      "location": "Coimbatore,  Tamil  Nadu,  India"
    }
  },
  {
    "vector_id": 89,
    "job_id": "job profile_3",
    "chunk_id": 4,
    "source_file": "job profile_3.pdf",
    "folder": "D:/Project_2",
    "text": "- \nExperience with debugging and performance tuning of ABAP programs. - Familiarity with SAP \nmodules such as SD, MM, and FI. Additional Information: - The candidate should have minimum \n3 years of experience in SAP ABAP Developm ent. - This position is based at our Coimbatore \noffice. - A 15 years full time education is required., 15 years full time educatio n",
    "metadata": {
      "job_title": "Custom Software Enginee r",
      "company": "Accenture in Indi a",
      "location": "Coimbatore,  Tamil  Nadu,  India"
    }
  },
  {
    "vector_id": 90,
    "job_id": "job profile_3",
    "chunk_id": 5,
    "source_file": "job profile_3.pdf",
    "folder": "D:/Project_2",
    "text": "- A 15 years full time education is required., 15 years full time educatio n",
    "metadata": {
      "job_title": "Custom Software Enginee r",
      "company": "Accenture in Indi a",
      "location": "Coimbatore,  Tamil  Nadu,  India"
    }
  },
  {
    "vector_id": 91,
    "job_id": "job profile_4",
    "chunk_id": 1,
    "source_file": "job profile_4.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  AES Technologies India Pvt Limite d  \nJob role     :  Software Engineer (Application/Data \nMigration & Integrations) [Remote ] \n Location  : Coimbatore,  Tamil Nadu,  India \nAbout the job  \nSoftware  Engineer  (Application/Data  Migration  & Integrations)  \n \nPurpose  of the role \n \nRefactor and containerise PHP/Java services, execute PostgreSQL migrations, and deliver secure \nintegrations via API Management and third -party systems, ens uring functional parity and \nrepeatable deployments across multiple programme instances. Key Responsibilities  \n \n \n Refactor  and containerise  application  workloads  (PHP/Apache,  Java services,  Node  where  \napplicable)  for deployment  to App Service  for Containers,  Azure  Container  Apps  and or \nAKS, build  and maintain  secure  container  images  and manage  releases  with ACR.  Plan and execute  database  migrations  to Azure  PostgreSQL  Flexible  Server,  including  \nschema  conversion,  performance  tuning,  and migration  validation  \n Implement  and maintain  database  change  management  using  tools  such as \nFlyway/Liquibase;  manage  schema  drift and ensure  repeatable  migrations  across  \nenvironments.  Build  and consume  secure  APIs and integrations  via API Management,  including  \nauthentication,  certificate  handling,  request/response  validation,  and resilience  patterns  \n(timeouts/retries/idempotency)  \n Implement  application  observability  (structured  logs, health  checks,  metrics)  integrated  \nwith Azure  Monitor/Log  Analytics;  ensure  secrets  are managed  securely  via Key Vault  and \nmanaged  identity  where  possible  \n Collaborate  with platform,  infra,  and vendor  technical  teams  on cutover  planning,  defect  \ntriage,  and troubleshooting  during  POC/pilot/waves  to ensure  safe clinical  releases. Experience  & Skills  \n \n \n Senior  software  engineering  experience  delivering  and operating  production  web services  \n(PHP  and/or  Java),  including  refactoring  of legacy  systems  \n Hands -on experience  containerising  applications  with Docker  and deploying  to cloud  \nPaaS/container  platforms  (Azure  Container  Apps  and/or  App Service  for Containers;  AKS \nexposure  beneficial)  \n Strong  PostgreSQL  experience  including  schema  design,  migration  execution,  \nperformance  tuning,  and validation  at cutover  \n Proven  experience  designing  and integrating  secure  REST  APIs,  including  authentication  \nflows,  certificates,  and API gateway  patterns  (API Management  beneficial)  \n Strong  engineering  discipline:  automated  testing,  CI build  pipelines,  safe release  \npractices,  troubleshooting,  and post-release  defect  management  \n Comfortable  working  in regulated  environments  where  change  control,  auditability,  and \nclinical  risk are key considerations  \n \n \nTechnology  & Tooling  \n \n \n Languages/Runtime:  PHP, Java (Spring  Boot/Dropwizard),  JavaScript/Node  (if applicable)  \n Containers:  Docker,  ACR,  App Service  for Containers  / Azure  Container  Apps  (AKS  \nbeneficial)  \n Data:  PostgreSQL,  pg_dump/pg_restore,  DMS  (beneficial),  Flyway/Liquibase  (preferred)  \n Integrations:  REST,  OpenAPI,  Azure  API Management,  vendor  API integrations  \n Security:  Key Vault,  Managed  Identity,  TLS/certificates,  OWASP  principles  \n Observability:  Azure  Monitor  / Log Analytics  (application  logging/health  checks)  \n Delivery:  Git, Azure DevOps/GitHub  Actions  (as a consumer  of CI pipelines;  platform  team  \nowns  landing  zone)  \n \n \nPreferred  Certifications  \n \nAZ204, CKAD",
    "metadata": {
      "job_title": "Software Engineer (Application/Data",
      "company": "AES Technologies India Pvt Limite d",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 92,
    "job_id": "job profile_4",
    "chunk_id": 2,
    "source_file": "job profile_4.pdf",
    "folder": "D:/Project_2",
    "text": "Experience  & Skills  \n \n \n Senior  software  engineering  experience  delivering  and operating  production  web services  \n(PHP  and/or  Java),  including  refactoring  of legacy  systems  \n Hands -on experience  containerising  applications  with Docker  and deploying  to cloud  \nPaaS/container  platforms  (Azure  Container  Apps  and/or  App Service  for Containers;  AKS \nexposure  beneficial)  \n Strong  PostgreSQL  experience  including  schema  design,  migration  execution,  \nperformance  tuning,  and validation  at cutover  \n Proven  experience  designing  and integrating  secure  REST  APIs,  including  authentication  \nflows,  certificates,  and API gateway  patterns  (API Management  beneficial)  \n Strong  engineering  discipline:  automated  testing,  CI build  pipelines,  safe release  \npractices,  troubleshooting,  and post-release  defect  management  \n Comfortable  working  in regulated  environments  where  change  control,  auditability,  and \nclinical  risk are key considerations  \n \n \nTechnology  & Tooling  \n \n \n Languages/Runtime:  PHP, Java (Spring  Boot/Dropwizard),  JavaScript/Node  (if applicable)  \n Containers:  Docker,  ACR,  App Service  for Containers  / Azure  Container  Apps  (AKS  \nbeneficial)  \n Data:  PostgreSQL,  pg_dump/pg_restore,  DMS  (beneficial),  Flyway/Liquibase  (preferred)  \n Integrations:  REST,  OpenAPI,  Azure  API Management,  vendor  API integrations  \n Security:  Key Vault,  Managed  Identity,  TLS/certificates,  OWASP  principles  \n Observability:  Azure  Monitor  / Log Analytics  (application  logging/health  checks)  \n Delivery:  Git, Azure DevOps/GitHub  Actions  (as a consumer  of CI pipelines;  platform  team  \nowns  landing  zone)  \n \n \nPreferred  Certifications  \n \nAZ204, CKAD",
    "metadata": {
      "job_title": "Software Engineer (Application/Data",
      "company": "AES Technologies India Pvt Limite d",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 93,
    "job_id": "job profile_5",
    "chunk_id": 1,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  Foxsense Innovations  \n \nJob role     :  Java Develope r \n Location  : Coimbatore,  Tamil Nadu,  India \nAbout the job  \nQuick  Facts  About  The Role  \n \nRole : Java Developer / Senior Java Developer  \n \nLocation : Coim batore  \n \nYOE: 3-8 Years  \n \nSkills : Java, Springboot, Angular, AWS  \n \nBenefits : Learn more about our perks below  \n \nCompensation : Competitive compensation as per industry standards. Who  We Are \n \nWe are Foxsense Innovations - a bunch of passionate developers that l ove solving complex \nbusiness problems through products and tools we build from scratch. Weʼve been at it for over 5 \nyears now, and weʼve serviced over 50 happy customers around the world, while also building \nseveral in -house micro -SaaS tools for the market  (all of this while being bootstrapped and \nprofitable). Our team is rapidly growing, and weʼre in an exciting phase of our 1 -10 journey. This \nis an opportunity for anyone who wants to experience this journey with us. About  The Role \n \nWe aspire to build a h igh-quality, innovative & robust software.",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 94,
    "job_id": "job profile_5",
    "chunk_id": 2,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": "This \nis an opportunity for anyone who wants to experience this journey with us. About  The Role \n \nWe aspire to build a h igh-quality, innovative & robust software. If you are a hands -on platform \nbuilder with significant experience in developing scalable data platforms, look no further. Click on \nApply and we will reach out to you soon. Responsibilities  \n \n \n Determines  operation al feasibility  by evaluating  analysis,  problem  definition,  \nrequirements,  solution  development,  and proposed  solutions.  Documents  and demonstrates  solutions  by developing  documentation,  flowcharts,  \nlayouts,  diagrams,  charts,  code  comments  and clear  code.",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 95,
    "job_id": "job profile_5",
    "chunk_id": 3,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": "Responsibilities  \n \n \n Determines  operation al feasibility  by evaluating  analysis,  problem  definition,  \nrequirements,  solution  development,  and proposed  solutions.  Documents  and demonstrates  solutions  by developing  documentation,  flowcharts,  \nlayouts,  diagrams,  charts,  code  comments  and clear  code.  Prepares  and installs  solutions  by determining  and designing  system  specifications,  \nstandards,  and programming.  Improves  operations  by conducting  systems  analysis;  recommending  changes  in policies  \nand procedures.  Obtains  and licenses  software  by obtaining  required  information  from  vendors;  \nrecommending  purchases;  testing  and approving  products.  Updates  job knowledge  by studying  state -of-the-art development  tools,  programming  \ntechniques,  and computing  equipment  \n Participate  in educational  opportunities  & read professional  publications;  \n Protects  operations  by keeping  information  confidential.",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 96,
    "job_id": "job profile_5",
    "chunk_id": 4,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": " Obtains  and licenses  software  by obtaining  required  information  from  vendors;  \nrecommending  purchases;  testing  and approving  products.  Updates  job knowledge  by studying  state -of-the-art development  tools,  programming  \ntechniques,  and computing  equipment  \n Participate  in educational  opportunities  & read professional  publications;  \n Protects  operations  by keeping  information  confidential.  Provides  information  by collecting,  analyzing,  and summarizing  development  and service  \nissues.  Accomplishes  engineering  and organization  mission  by completing  related  results  as \nneeded.  Develops  software  solutions  by studying  information  needs;  conferring  with users;  \nstudying  systems  flow,  data usage,  and work  processes;  investigating  problem  areas;  \nfollowing  the software  developme nt lifecycle. Requirements  \n \n \n Proven  work  experience  as a Software  Engineer  or Software  Developer  \n Experience  designing  interactive  applications  \n Ability  to develop  software  in Java \n Excellent  knowledge  of relational  databases,  SQL and ORM  technologies  (JPA2 , \nHibernate)  \n Experience  developing  web applications  using  at least one popular  web framework  (JSF, \nWicket,  GWT,  Spring  MVC)  \n Experience  with test-driven  development  \n Proficiency  in software  engineering  tools  \n Ability  to document  requirements  and specification s \n \n \nBonus  Skills  \n \n \n Experience  with cloud  platforms  such as AWS,  Azure,  or Google  Cloud.",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 97,
    "job_id": "job profile_5",
    "chunk_id": 5,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": " Develops  software  solutions  by studying  information  needs;  conferring  with users;  \nstudying  systems  flow,  data usage,  and work  processes;  investigating  problem  areas;  \nfollowing  the software  developme nt lifecycle. Requirements  \n \n \n Proven  work  experience  as a Software  Engineer  or Software  Developer  \n Experience  designing  interactive  applications  \n Ability  to develop  software  in Java \n Excellent  knowledge  of relational  databases,  SQL and ORM  technologies  (JPA2 , \nHibernate)  \n Experience  developing  web applications  using  at least one popular  web framework  (JSF, \nWicket,  GWT,  Spring  MVC)  \n Experience  with test-driven  development  \n Proficiency  in software  engineering  tools  \n Ability  to document  requirements  and specification s \n \n \nBonus  Skills  \n \n \n Experience  with cloud  platforms  such as AWS,  Azure,  or Google  Cloud.  Familiarity  with microservices  architecture  and API development.  Contributions  to open -source  projects  or a strong  technical  portfolio. What  Your  First 30-60-90 Days  Will Look  Like \n \nIn your first 30 days, you will:  \n \n \n Gain a deep  understanding  of the company’s  mission,  tech stack,  and product  landscape.  Meet  with cross -functional  teams  to familiarize  yourself  with workflows,  goals,  and \nchallenges.",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 98,
    "job_id": "job profile_5",
    "chunk_id": 6,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": "What  Your  First 30-60-90 Days  Will Look  Like \n \nIn your first 30 days, you will:  \n \n \n Gain a deep  understanding  of the company’s  mission,  tech stack,  and product  landscape.  Meet  with cross -functional  teams  to familiarize  yourself  with workflows,  goals,  and \nchallenges.  Dive into the codebase  to understand  existing  systems  and identify  areas  for \nimprovement.  Contribute  to minor  fixes or enhancements  to get hands -on experience  with the platform. In Your  Next  30 Days,  You Will \n \n \n Take  ownership  of a feature  or modu le, driving  its design,  development,  and delivery.  Propose  and implement  optimizations  or improvements  in the current  system.",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 99,
    "job_id": "job profile_5",
    "chunk_id": 7,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": "In Your  Next  30 Days,  You Will \n \n \n Take  ownership  of a feature  or modu le, driving  its design,  development,  and delivery.  Propose  and implement  optimizations  or improvements  in the current  system.  Actively  participate  in planning  sessions,  offering  insights  and recommendations.  Establish  yourself  as a go-to problem  solver  and collaborator  within  the team. Why  work  with us \n \nWhen you work with Foxsense Innovations, you donʼt just work a boring job. Our goal is to create \na work environment that makes you want to brag about your work to your friends!",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 100,
    "job_id": "job profile_5",
    "chunk_id": 8,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": "Why  work  with us \n \nWhen you work with Foxsense Innovations, you donʼt just work a boring job. Our goal is to create \na work environment that makes you want to brag about your work to your friends! Hereʼs  Why  Youʼll  Love  Working  With  Us \n \n \n Unlimited  sick leave  policy,  and a generous  paid leave  plan to ensure  you get time off \nwork  whenever  you need  it \n A competitive  and rewarding  start-up culture  that motivates  you from  day one, along  \nwith regular  team -building  activities  \n Delicious  lunch  along  with snacks  and refreshments  at office,  so that hunger  pangs  never  \naffect  your A-game  \n We have  a yearly  annual  retreat  for the team  to unwind  and enjoy  - we went  to Vagamon  \nlast year,  who knows  where  we go this year! If that's  not enough,  there's  always  more!  Need  a breather? Game  with Foxes  at the TT.",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 101,
    "job_id": "job profile_5",
    "chunk_id": 9,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": " Need  a breather? Game  with Foxes  at the TT. There's  a scoreboard!  Our wholesome  health  care plans  care for you - whenever,  wherever.  Embrace  growth! Learn  & grow  from  peers  - You'll  find budding  freshers,  seasoned  \nveterans  - you name  it.",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 102,
    "job_id": "job profile_5",
    "chunk_id": 10,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": " Embrace  growth! Learn  & grow  from  peers  - You'll  find budding  freshers,  seasoned  \nveterans  - you name  it.  We take unwinding  as seriously  as we do hustling  - game  nights  are our way of \ndowntime.  Collaboration  is vital for us - your value  isn’t limited  to your responsibilities! Feel free to \nlurk in other  departments  and share  your thoughts!",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 103,
    "job_id": "job profile_5",
    "chunk_id": 11,
    "source_file": "job profile_5.pdf",
    "folder": "D:/Project_2",
    "text": "Feel free to \nlurk in other  departments  and share  your thoughts!",
    "metadata": {
      "job_title": "Java Develope r",
      "company": "Foxsense Innovations",
      "location": "Coimbatore,  Tamil Nadu,  India"
    }
  },
  {
    "vector_id": 104,
    "job_id": "job profile_6",
    "chunk_id": 1,
    "source_file": "job profile_6.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  IBM \n \nJob role     :  Application Developer -Open Sourc e Location  : \nKochi, Kerala, Indi a \nAbout the job  \nIntroduction  \n \nA career in IBM Consulting is rooted by long -term relationships and close collaboration with \nclients across the globe. Y ou'll work with visionaries across multiple industries to improve the \nhybrid cloud and AI journey for the most innovative and valuable companies in the world. Your \nability to accelerate impact and make meaningful change for your clients is enabled by our \nstrategic partner ecosystem and our robust technology platforms across the IBM portfolio  \n \nYour  Role  And Responsibilities  \n \n \n Managing  and developing  C++ Applications.  Bringing  your expertise  to solve  the application  criticality.  C++ coding  experience  for prod uct application.  Experience  on design,  code  development,  unit test and maintain  code  quality  as defined  \nby project  \n \n \nPreferred  Education  \n \nMaster's Degree  \n \nRequired  Technical  And Professional  Expertise  \n \n \n 6-7 Years  of C++ programming  language  experience.",
    "metadata": {
      "job_title": "Application Developer -Open Sourc e Location  :",
      "company": "IBM",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 105,
    "job_id": "job profile_6",
    "chunk_id": 2,
    "source_file": "job profile_6.pdf",
    "folder": "D:/Project_2",
    "text": " C++ coding  experience  for prod uct application.  Experience  on design,  code  development,  unit test and maintain  code  quality  as defined  \nby project  \n \n \nPreferred  Education  \n \nMaster's Degree  \n \nRequired  Technical  And Professional  Expertise  \n \n \n 6-7 Years  of C++ programming  language  experience.  Good Knowledge  required  on QT.  Should  be able to design,  code  independently  \n \n \nPreferred  Technical  And Professional  Experience  \n \n \n Creative  problem  solving  skills and excellent  Communication  Skill",
    "metadata": {
      "job_title": "Application Developer -Open Sourc e Location  :",
      "company": "IBM",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 106,
    "job_id": "job profile_7",
    "chunk_id": 1,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  Blackhawk Network India  \n \nJob role     Sr. Software Engineer  \n Location  : Kozhikode, Kerala, Indi a \nAbout the job  \nAbout  Blackhawk  Network:   \n \nToday, through BHN’s single global platform, businesses of all kinds can tap into the world’s \nlargest network of branded payment solutions. BHN helps businesses grow revenue, increase \nloyalty, motivate and reward their teams, disburse funds and engage cons umers. Branded \npayment solutions include the issuance and distribution of gift cards, egifts, corporate payouts \nand rewards, along with the technology to deliver these products in seamless, integrated ways. BHN’s network spans the globe with more than 400, 000 consumer touchpoints. Learn more at \nBHN.com. Overview:   \n \nAs a Sr. Software Engineer, you will join the team responsible for delivering the next generation \nhigh- volume, fault -tolerant, and scalable transaction processing system for Blackhawk.",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 107,
    "job_id": "job profile_7",
    "chunk_id": 2,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": "Learn more at \nBHN.com. Overview:   \n \nAs a Sr. Software Engineer, you will join the team responsible for delivering the next generation \nhigh- volume, fault -tolerant, and scalable transaction processing system for Blackhawk. The \ncand idate will possess a demonstrated proficiency in a wide range of skills and experience \nutilizing  Java, React , Application service Interfaces, and database technologies. The desired \ncandidate will have an excellent understanding and hands -on experience desi gning and building \nsoftware components that can handle high volume traffic. Apply now for a chance to lead our \nproducts and platforms to new heights of functionality and adoption. Responsibilities:   \n \nFull Stack  Development:  \n \n \n Develop  and maintain  web applications  using  Java (Spring  Boot,  Spring  MVC)  for the \nback -end and React.js  for the front -end.",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 108,
    "job_id": "job profile_7",
    "chunk_id": 3,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": "Apply now for a chance to lead our \nproducts and platforms to new heights of functionality and adoption. Responsibilities:   \n \nFull Stack  Development:  \n \n \n Develop  and maintain  web applications  using  Java (Spring  Boot,  Spring  MVC)  for the \nback -end and React.js  for the front -end.  Collaborate  with front -end developers  to integrate  user-facing  elements  with server -side \nlogic.  Write  clean,  maintainable,  and efficient  Java code  to ensure  high performance  and \nscalability  of applications. System  Design  & Architecture:  \n \n \n Design  and implement  complex  systems  and RESTful  APIs,  including  integrations  with \nthird -party  services.  Architect  solutions  that are scalable,  secure,  and high-performing  using Spring  ecosystem  \nbest practices.",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 109,
    "job_id": "job profile_7",
    "chunk_id": 4,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": "System  Design  & Architecture:  \n \n \n Design  and implement  complex  systems  and RESTful  APIs,  including  integrations  with \nthird -party  services.  Architect  solutions  that are scalable,  secure,  and high-performing  using Spring  ecosystem  \nbest practices. Collaboration  & Communication:  \n \n \n Work  closely  with UI/UX  designers,  product  managers,  and other  stakeholders  to deliver  \nhigh-quality  solutions.  Participate  in code  reviews  to ensure  adherence  to best practices  and consi stency  across  \nthe team.  Mentor  junior  developers  and support  their technical  and professional  growth. Testing  & Debugging:  \n \n \n Write  unit tests (using  JUnit),  integration  tests (e.g.,  with Spring  Test),  and functional  tests \nto ensure  application  reliabilit y.",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 110,
    "job_id": "job profile_7",
    "chunk_id": 5,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": " Mentor  junior  developers  and support  their technical  and professional  growth. Testing  & Debugging:  \n \n \n Write  unit tests (using  JUnit),  integration  tests (e.g.,  with Spring  Test),  and functional  tests \nto ensure  application  reliabilit y.  Troubleshoot  and debug  applications  to resolve  performance  bottlenecks  and bugs. Continuous  Improvement:  \n \n \n Stay updated  with emerging  technologies  and industry  trends,  especially  within  the Java \nand Spring  ecosystems.  Propose  and implement  new features,  performance  optimizations,  and improvements  to \nexisting  systems. Qualifications:   \n \n \n Experience:  5+ years  of full-stack  development  experience,  including:  \n Strong  proficiency  in JAVA,  specifically  with Spring  Boot  and related  frameworks.",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 111,
    "job_id": "job profile_7",
    "chunk_id": 6,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": " Propose  and implement  new features,  performance  optimizations,  and improvements  to \nexisting  systems. Qualifications:   \n \n \n Experience:  5+ years  of full-stack  development  experience,  including:  \n Strong  proficiency  in JAVA,  specifically  with Spring  Boot  and related  frameworks.  Experience  with front -end technologies  like React.js  or Angular.  Understanding  of relational  databases  (MySQL,  PostgreSQL,  etc.) and RESTful  API \ndevelopment.  Technical  Skills:  \n Proficient  in JavaScript,  HTML5,  CSS3,  and responsive  design.",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 112,
    "job_id": "job profile_7",
    "chunk_id": 7,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": "and RESTful  API \ndevelopment.  Technical  Skills:  \n Proficient  in JavaScript,  HTML5,  CSS3,  and responsive  design.  Solid  understanding  of MVC  architecture  and web application  frameworks.  Familiarity  with version  control  systems  (Git) and deployment  tools.  Knowledge  of JavaScript  build  tools  (Webpack,  NPM)  and state  management  \nlibraries  (Redux  etc.).  Additional  Skills:  \n Familiarity  with cloud  platforms  (AWS)  and containerisation  technologies  \n(Docker).",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 113,
    "job_id": "job profile_7",
    "chunk_id": 8,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": " Knowledge  of JavaScript  build  tools  (Webpack,  NPM)  and state  management  \nlibraries  (Redux  etc.).  Additional  Skills:  \n Familiarity  with cloud  platforms  (AWS)  and containerisation  technologies  \n(Docker).  Experience  with Agile  methodologies  and version  control  using  Git.  Knowledge  of security  best practices  and techniques  for web applications. We seek candidates who not only  demonstrate curiosity and adaptability in emerging \ntechnologies but have also successfully implemented and utilized AI tools to enhance their work, \nimprove processes, or deliver measurable results. Our teams embrace continuous learning and \nthe thoughtful integration of AI to create meaningful impact – for our employees and the future \nof work.",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 114,
    "job_id": "job profile_7",
    "chunk_id": 9,
    "source_file": "job profile_7.pdf",
    "folder": "D:/Project_2",
    "text": "We seek candidates who not only  demonstrate curiosity and adaptability in emerging \ntechnologies but have also successfully implemented and utilized AI tools to enhance their work, \nimprove processes, or deliver measurable results. Our teams embrace continuous learning and \nthe thoughtful integration of AI to create meaningful impact – for our employees and the future \nof work.",
    "metadata": {
      "job_title": "Sr. Software Engineer",
      "company": "Blackhawk Network India",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 115,
    "job_id": "job profile_8",
    "chunk_id": 1,
    "source_file": "job profile_8.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  NeST Digital  \n \n \nJob role     Software Engineer - JAVA \n Location  : Kozhikode, Kerala, Indi a \nAbout the job  \nPrimary  Skills  \n \nJAVA 8+, Spring Boot, ReST, Micro Services, Docker, Angular, Javascript, RDBMS/ NoSQL, Junit  \n \nLocation  \n \nTrivandrum \\Kochi \\Bangalore  \n \nResponsibilities  \n \n \n Provide  technology  leadership  in  \n Working  in an agile  development  environment   \n Translating  business  requirements  into low-level application  design   \n Application  code  development  through  a collaborative  approach   \n Doing  Full-scale  unit testing   \n Applying  test-driven  and behaviour -driven  development  (TDD/BDD)  QA concepts   \n Applying  continuous  integration  and continuous  deployment  (CI/CD)  concepts   \n \n \nMandatory Skills  \n \n \n Java,  Spring  Boot,  and relational  / non-relationa l databases   \n Hands  on experience  in Lambda  and Functional  Interfaces   \n Experience  in Angular  framework.  Basic  knowledge  of AWS  cloud  services  in one or more  …(Amazon  EC2, Amazon  RDS, \nAmazon  MSK,  Amazon  ElastiCache,  AWS  Glue AWS  IAM, Istio,  AWS  AppMesh,  Amazon \nKeyspaces,  Amazon  API Gateway...)   \n Modern  SDLC  tooling  (Maven,  Git)  \n Java full stack -based  micro  services  design -oriented  application  development  and \ndeploying  the same  using  Container  orchestration  in the cloud  environment   \n Understanding  CI/CD  pipelin e & related  system  development  environment",
    "metadata": {
      "job_title": "Software Engineer - JAVA",
      "company": "NeST Digital",
      "location": "Kozhikode, Kerala, Indi a"
    }
  },
  {
    "vector_id": 116,
    "job_id": "job profile_9",
    "chunk_id": 1,
    "source_file": "job profile_9.pdf",
    "folder": "D:/Project_2",
    "text": "Company   :  Infocus Technologies Pvt ltd  \n \n \nJob role     Infocus Technologies - Backend \nLead/Developer  \n \n Location  Kochi, Kerala, Indi a \nAbout the job  \nDescription  \n \nAbout the Role :  \n \nInfocus Technologies Pvt. Ltd. is seeking skilled and passionate Backend API profes sionals to join \nour growing team. We are hiring for both Lead and Developer roles with strong expertise in Spring Boot and \nMicroservices Responsibilities :   \n \n \n Design,  develop,  and maintain  robust  and scalable  backend  APIs using  Spring  Boot  and \n \n \nMicroservices.  Lead  backend  development  projects,  ensuring  high code  quality  and performance  \nstandards.  Collaborate  with cross -functional  teams  including  front -end developers,  QA engineers,  \nand \n \n \nDevOps.  Participate  in code  reviews,  architecture  discussions,  and contribute  to best practices.",
    "metadata": {
      "job_title": "Infocus Technologies - Backend",
      "company": "Infocus Technologies Pvt ltd",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 117,
    "job_id": "job profile_9",
    "chunk_id": 2,
    "source_file": "job profile_9.pdf",
    "folder": "D:/Project_2",
    "text": " Collaborate  with cross -functional  teams  including  front -end developers,  QA engineers,  \nand \n \n \nDevOps.  Participate  in code  reviews,  architecture  discussions,  and contribute  to best practices.  Troubleshoot  and resolve  issues  in development,  testing,  and production  environments.  Mentor  junior  developers  and guide  them  through  technical  challenges  (for Lead  \nCandidate  Profile  :  \n For Lead  Role : 8 - 12+ years  of hands -on experience  in backend  development.  For Developer  Role : Minimum  4+ years  of relevant  experience.  Proficient  in Spring  Boot,  Microservices  architecture,  and RESTful  API development.",
    "metadata": {
      "job_title": "Infocus Technologies - Backend",
      "company": "Infocus Technologies Pvt ltd",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 118,
    "job_id": "job profile_9",
    "chunk_id": 3,
    "source_file": "job profile_9.pdf",
    "folder": "D:/Project_2",
    "text": " For Developer  Role : Minimum  4+ years  of relevant  experience.  Proficient  in Spring  Boot,  Microservices  architecture,  and RESTful  API development.  Strong  underst anding  of software  development  principles,  version  control  (e.g.,  Git), and \nCI/CD  pipelines.  Excellent  problem -solving  skills  and attention  to detail.  Strong  communication  and interpersonal  skills.  Ability  to work  in a collaborative,  fast-paced  Skills  :  \n Experience  with containerization  (Docker,  Kubernetes)  and cloud  platforms  (AWS  \npreferred).",
    "metadata": {
      "job_title": "Infocus Technologies - Backend",
      "company": "Infocus Technologies Pvt ltd",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 119,
    "job_id": "job profile_9",
    "chunk_id": 4,
    "source_file": "job profile_9.pdf",
    "folder": "D:/Project_2",
    "text": " Strong  communication  and interpersonal  skills.  Ability  to work  in a collaborative,  fast-paced  Skills  :  \n Experience  with containerization  (Docker,  Kubernetes)  and cloud  platforms  (AWS  \npreferred).  Knowledge  of database  technologies  like MySQL,  PostgreSQL,  or MongoDB.  Exposure  to Agile  methodologies",
    "metadata": {
      "job_title": "Infocus Technologies - Backend",
      "company": "Infocus Technologies Pvt ltd",
      "location": "Kochi, Kerala, Indi a"
    }
  },
  {
    "vector_id": 120,
    "job_id": "Nissan",
    "chunk_id": 1,
    "source_file": "Nissan.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Nissan Motor Corporation  \nJob role     :  ML Engineer II  \nLocation  :  Trivandrum, Kerala, India  \nAbout the job \n• Nissan is a pioneer in Innovation and Technology. With a focus on Mobility, \nOperational Excellence, Value to our Customers and Electriﬁcation of \nvehicles, you can expect to be part of a very exciting journey here at Nissan. Nissan is going after a massive Digital Transformation backed by leading \ntechnologies across the organization globally. We are committed to building \na diverse, entrepreneurial organization, and our current team is a strong \nevidence of that. Our people are what drive the business forwar d. At Nissan \nDigital, you will be part of a dynamic team with ample opportunities to grow \nand make a difference. Responsibilities:  \n \nAssist in developing, training, and optimizing machine learning models for \nvarious applications.",
    "metadata": {
      "job_title": "ML Engineer II",
      "company": "Nissan Motor Corporation",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 121,
    "job_id": "Nissan",
    "chunk_id": 2,
    "source_file": "Nissan.pdf",
    "folder": "D:/Project_2",
    "text": "Our people are what drive the business forwar d. At Nissan \nDigital, you will be part of a dynamic team with ample opportunities to grow \nand make a difference. Responsibilities:  \n \nAssist in developing, training, and optimizing machine learning models for \nvarious applications. Work with large datasets, performing data preprocessing, feature \nengineering, and model evaluation. Collaborate with data scientists and software engineers to integrate ML \nmodels into production environments. Conduct experiments to improve model accuracy and efficiency. Write clean, efficient, and well -documented code for ML model \ndevelopment.",
    "metadata": {
      "job_title": "ML Engineer II",
      "company": "Nissan Motor Corporation",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 122,
    "job_id": "Nissan",
    "chunk_id": 3,
    "source_file": "Nissan.pdf",
    "folder": "D:/Project_2",
    "text": "Conduct experiments to improve model accuracy and efficiency. Write clean, efficient, and well -documented code for ML model \ndevelopment. Stay updated with the latest advancements in ML algorithms and technologies. Key Competencies:  \n Strong analytical and problem -solving skills. Ability to understand and implement ML algorithms effectively. Good communication skills to collaborate with cross -functional teams.",
    "metadata": {
      "job_title": "ML Engineer II",
      "company": "Nissan Motor Corporation",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 123,
    "job_id": "Nissan",
    "chunk_id": 4,
    "source_file": "Nissan.pdf",
    "folder": "D:/Project_2",
    "text": "Ability to understand and implement ML algorithms effectively. Good communication skills to collaborate with cross -functional teams. Attention to detail and a structured approach to work. GenAI: Curiosity and experimentation with LLMs & GenAI tools (e.g., ChatGPT, Gemini) and prompt tuning  \n MLOps: Learning foundations of model deployment, version control, and \nexperiment tracking  \n \nRelevant Work Exp : 2 -5 years  \n \nTechnical Skills:  \n \nProﬁciency in Python, TensorFlow, PyTorch, or Scikit -learn. Experience with data manipulation using Pandas and NumPy. Familiarity with c loud platforms like AWS, Azure, or GCP for ML model \ndeployment.",
    "metadata": {
      "job_title": "ML Engineer II",
      "company": "Nissan Motor Corporation",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 124,
    "job_id": "Nissan",
    "chunk_id": 5,
    "source_file": "Nissan.pdf",
    "folder": "D:/Project_2",
    "text": "Experience with data manipulation using Pandas and NumPy. Familiarity with c loud platforms like AWS, Azure, or GCP for ML model \ndeployment. Knowledge of SQL and database management. Understanding of software development best practices (Git, Docker, CI/CD). Behavioral Competencies:  \n Adaptability: Open to learning and applying new ML techniques, tools, and \nframeworks. Learning Agility: Willingness to experiment, analyze failures, and \ncontinuously improve skills.",
    "metadata": {
      "job_title": "ML Engineer II",
      "company": "Nissan Motor Corporation",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 125,
    "job_id": "Nissan",
    "chunk_id": 6,
    "source_file": "Nissan.pdf",
    "folder": "D:/Project_2",
    "text": "Behavioral Competencies:  \n Adaptability: Open to learning and applying new ML techniques, tools, and \nframeworks. Learning Agility: Willingness to experiment, analyze failures, and \ncontinuously improve skills. Teamwork: Works collaboratively with peers, takes feedback constructively, \nand contributes to team success. Certiﬁca tions (Optional):  \n TensorFlow Developer Certiﬁcation  \n \nAWS Certiﬁed Machine Learning - Specialty  \n \nMicrosoft Certiﬁed: Azure AI Engineer Associate  \n Google Professional Machine Learning Engineer  \n \nTrivandrum Kerala India",
    "metadata": {
      "job_title": "ML Engineer II",
      "company": "Nissan Motor Corporation",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 126,
    "job_id": "NTT",
    "chunk_id": 1,
    "source_file": "NTT.pdf",
    "folder": "D:/Project_2",
    "text": "Company : NTT DATA North America  \nJob role     :  AI Engineer \nLocation  : Bengaluru  East , Karnataka, India  \nAbout the job \nJob Details  \n \nReq ID:  343646  \n \nNTT DATA strives to hire exceptional, innovative and passionate individuals who \nwant to grow with us. If you want to be part of an inclusive, adaptable, and forward -\nthinking organization, apply now. We are currently seeking a AI Engineer to join our team in Bangalore, Karnātaka (IN-\nKA), India (IN). \"Need 2 Agentic AI engineers for development and performance evaluation / model \ntesting  \n \n \n•  should be strong in python  \n•  have experience building orchestration layer for LLMs, connecting to APIs, \ne t c.\"",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "NTT DATA North America",
      "location": "Bengaluru  East , Karnataka, India"
    }
  },
  {
    "vector_id": 127,
    "job_id": "Oracle",
    "chunk_id": 1,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Oracle  \nJob role    :  Senior AI Applications Engineer  \nLocation :  Trivandrum, Kerala, India  \n \nAbout the job Essential Skills \n \n JOB DESCRIPTION   \n  \n• Proﬁciency in programming languages relevant to AI (e.g., Python, Java). • Familiarity with modern AI/ML frameworks and platforms (e.g., TensorFlow, PyTorch, Oracle Cloud AI services). • Practical experience with enterprise software development, including REST APIs, microservices, and cloud -native architectures. • Strong problem -solving skills, particularly in translating business needs into \nscalable AI solutions. • Excellent written and verbal communication skills. • Ability to work effectively in a collaborative, multi -disciplinary, and global \nteam environment.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 128,
    "job_id": "Oracle",
    "chunk_id": 2,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "• Excellent written and verbal communication skills. • Ability to work effectively in a collaborative, multi -disciplinary, and global \nteam environment. Qualiﬁcations  \n Required:  \n \n \n• Bachelor’s degree or equivalent experience in Computer Science, \nEngineering, Mathematics, or a related technical ﬁeld. • At least 1 year of experience in AI, software engineering, or closely related \nﬁelds (exceptional candidates with less experience will be considered). • Hands -on knowledge of common AI techniques, including machine learning \nmethods and statistical modeling. Preferred:  \n  \n• Masters degree or higher in Computer Science, Data Science, Artiﬁcial \nIntelligence, or related discipline.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 129,
    "job_id": "Oracle",
    "chunk_id": 3,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "• Hands -on knowledge of common AI techniques, including machine learning \nmethods and statistical modeling. Preferred:  \n  \n• Masters degree or higher in Computer Science, Data Science, Artiﬁcial \nIntelligence, or related discipline. • Experience with Large Language Models, Retrieval Augmented Generation, \nor other advanced modern AI tooling. • Prior work with cloud platforms (preferably Oracle Cloud Infrastructure) a \nmajor plus. • Experience in developing and deploying enterprise-grade AI solutions. • Familiarity with DevOps practices and tools for CI/CD.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 130,
    "job_id": "Oracle",
    "chunk_id": 4,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "• Experience in developing and deploying enterprise-grade AI solutions. • Familiarity with DevOps practices and tools for CI/CD. Responsibilities  \n Key Responsibilities  \n  \n• Design, develop, and support AI -based enterprise applications using \nmodern AI tools and technologies (e.g., AI Agents, Retrieval Augmented \nGeneration [RAG], Model context protocol [MCP], Large Language Models). • Apply classical AI techniques such as clustering, classiﬁcation, regression, \nMonte Carlo simulations, and Bayesian blending. • Participate in system planning, scheduling, and implementation for \nenterprise -scale AI applications. • Build new product features and/or enhance existing features to automate \ncomplex business ﬂows and operations.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 131,
    "job_id": "Oracle",
    "chunk_id": 5,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "• Participate in system planning, scheduling, and implementation for \nenterprise -scale AI applications. • Build new product features and/or enhance existing features to automate \ncomplex business ﬂows and operations. • Collaborate with cross -functional teams to understand requirements and \ndeliver innovative AI -driven solutions. • Ensure application scalability, reliability, and performance in a cloud environment. • Contribute to best practices for development, testing, and deployment of AI \napplications. Qualiﬁcations  \n \nCareer Level - IC3 \n \nAbout Us  \n \nAs a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle \ntoday’s challenges.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 132,
    "job_id": "Oracle",
    "chunk_id": 6,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "• Contribute to best practices for development, testing, and deployment of AI \napplications. Qualiﬁcations  \n \nCareer Level - IC3 \n \nAbout Us  \n \nAs a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle \ntoday’s challenges. We’ve partnered with industry -leaders in almost every sector —\nand continue to thrive after 40+ years of change by operating with integrity. We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportun ities where work -life balance \nﬂourishes.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 133,
    "job_id": "Oracle",
    "chunk_id": 7,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all. Oracle careers open the door to global opportun ities where work -life balance \nﬂourishes. We offer competitive beneﬁts based on parity and consistency and \nsupport our people with ﬂexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities thro ugh our \nvolunteer programs. We’re committed to including people with disabilities at all stages of the \nemployment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation -\nrequest_mb@oracle.com or by calling +1 888 404 2494 in the United States.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 134,
    "job_id": "Oracle",
    "chunk_id": 8,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "We’re committed to including people with disabilities at all stages of the \nemployment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation -\nrequest_mb@oracle.com or by calling +1 888 404 2494 in the United States. Oracle is an Equal Employment Opportunity Employer. All qualiﬁed applicants will \nreceive consideration for employment without regard to race, color, religion, sex, \nnational origin, sexual orientation, gender identity, disability and protected \nveterans’ st atus, or any other characteristic protected by law. Oracle will consider \nfor employment qualiﬁed applicants with arrest and conviction records pursuant to \napplicable law.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 135,
    "job_id": "Oracle",
    "chunk_id": 9,
    "source_file": "Oracle.pdf",
    "folder": "D:/Project_2",
    "text": "Oracle will consider \nfor employment qualiﬁed applicants with arrest and conviction records pursuant to \napplicable law.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 136,
    "job_id": "Oracle2",
    "chunk_id": 1,
    "source_file": "Oracle2.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Oracle  \nJob role     :  Senior AI Applications Engineer  \nLocation  : Trivandrum, Kerala, India  \nAbout the job \nEssential Skills \n \n JOB DESCRIPTION   \n \n \n• Proﬁciency in programming languages relevant to AI (e.g., Python, Java). • Familiarity with modern AI/ML frameworks and platforms (e.g., TensorFlow, \nPyTorch, Oracle Cloud AI services). • Practical experience with enterprise software development, including REST \nAPIs, microservices, and cloud -native architectures. • Strong problem -solving skills, particularly in translating business needs into \nscalable AI solutions. • Excellent written and verbal communication skills. • Ability to work effectively in a collaborative, multi -disciplinary, and global \nteam environment.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 137,
    "job_id": "Oracle2",
    "chunk_id": 2,
    "source_file": "Oracle2.pdf",
    "folder": "D:/Project_2",
    "text": "• Excellent written and verbal communication skills. • Ability to work effectively in a collaborative, multi -disciplinary, and global \nteam environment. Qualiﬁcations  \n \nRequired:  \n  \n• Bachelor’s degree or equivalent experience in Computer Science, \nEngineering, Mathematics, or a related technical ﬁeld. • At least 1 year of experience in AI, software engineering, or closely related \nﬁelds (exceptional candidates with less experience will be considered). • Hands -on knowledge of common AI techniques, including machine learning \nmethods and statistical modeling. Preferred:  \n  \n• Masters degree or higher in Computer Science, Data Science, Artiﬁcial \nIntelligence, or related discipline.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 138,
    "job_id": "Oracle2",
    "chunk_id": 3,
    "source_file": "Oracle2.pdf",
    "folder": "D:/Project_2",
    "text": "• Hands -on knowledge of common AI techniques, including machine learning \nmethods and statistical modeling. Preferred:  \n  \n• Masters degree or higher in Computer Science, Data Science, Artiﬁcial \nIntelligence, or related discipline. • Experience with Large Language Models, Retrieval Augmented Generation, \nor other advanced modern AI tooling. • Prior work with cloud platforms (preferably Oracle Cloud Infrastructure) a \nmajor plus. • Experience in developing and deploying enterprise-grade AI solutions. • Familiarity with DevOps practices and tools for CI/CD.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 139,
    "job_id": "Oracle2",
    "chunk_id": 4,
    "source_file": "Oracle2.pdf",
    "folder": "D:/Project_2",
    "text": "• Experience in developing and deploying enterprise-grade AI solutions. • Familiarity with DevOps practices and tools for CI/CD. Responsibilities  \n \nKey Responsibilities  \n  \n• Design, develop, and support AI -based enterprise applications using \nmodern AI tools and technologies (e.g., AI Agents, Retrieval Augmented \nGeneration [RAG], Model context protocol [MCP], Large Language Models). • Apply classical AI techniques such as clustering, classiﬁcation, regression, Monte Carlo simulations, and Bayesian blending. • Participate in system planning, scheduling, and implementation for enterprise -scale AI applications. • Build new product features and/or enhance existing features to automate \ncomplex business ﬂows and operations.",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 140,
    "job_id": "Oracle2",
    "chunk_id": 5,
    "source_file": "Oracle2.pdf",
    "folder": "D:/Project_2",
    "text": "• Participate in system planning, scheduling, and implementation for enterprise -scale AI applications. • Build new product features and/or enhance existing features to automate \ncomplex business ﬂows and operations. • Collaborate with cross -functional teams to understand requirements and \ndeliver innovative AI -driven solutions. • Ensure application scalability, reliability, and performance in a cloud environment. • Contribute to best practices for development, testing, and deployment of AI \napplications. Qualiﬁcations  \n \nCareer Level - IC3",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 141,
    "job_id": "Oracle2",
    "chunk_id": 6,
    "source_file": "Oracle2.pdf",
    "folder": "D:/Project_2",
    "text": "• Contribute to best practices for development, testing, and deployment of AI \napplications. Qualiﬁcations  \n \nCareer Level - IC3",
    "metadata": {
      "job_title": "Senior AI Applications Engineer",
      "company": "Oracle",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 142,
    "job_id": "questhiring",
    "chunk_id": 1,
    "source_file": "questhiring.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Questhiring  \nJob role    : AI Backend Engineer  \nLocation : Bengaluru, Karnataka, India  \n \nAbout the job What You’ll Build  \n● Stateless backend services operating over durable workﬂow state  \n● Explicit workﬂow and execution state models (statuses, transitions, events)  \n● Event -driven orchestration with retries, idempotency, and recovery  \n● Backend systems that power AI -driven execution, not just recommendations  \nWe care about correctness, observability, and fast iteration. What You’ll Do ● Design and build stateless backend services using Python + FastAPI  \n● Deﬁne durable workﬂow state models driven by real customer workﬂows  \n● Integrate AI agents into reliable execution pipelines  \n● Build event -driven async systems (queues, schedulers, background jobs)  \n● Own prompt engineering and production LLM integration  \n● Design clean APIs consumed by frontend systems and agents  \n● Work directly with customers to:  \n○ Understand how workﬂows fail in practice  \n○ Debug real production issues  \n○ Iterate quickly based on feedback  \n● Ensure systems are observable, debuggable, and resilient  \n● Operate backend and AI infrastructure end-to -end",
    "metadata": {
      "job_title": "AI Backend Engineer",
      "company": "Questhiring",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 143,
    "job_id": "RS-1",
    "chunk_id": 1,
    "source_file": "RS-1.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Niveus Solutions  \nJob role     :  Cloud Leader -Data Analyst  \nLocation  : Mangaluru, Karnataka, India  \n \nAbout the job  \nWe are seeking an experienced Cloud Leader in the role of Data Analyst to join our \ndynamic team. The ideal candidate will be responsible for leveraging cloud \ntechnologies to analyze and interpret complex data sets, leading to informed \nbusiness decisions. T hey will collaborate with cross -functional teams to gather \nrequirements, design data models, and implement solutions that drive operational \nefficiency and enhance performance. Key Responsibilities:  \n- Analyze, model, and interpret large datasets stored in cloud environments. - Work \nclosely with business stakeholders to gather and document requirements for \nreporting and analytics. - Design scalable data architecture and develop ETL \nprocesses for data i ntegration.",
    "metadata": {
      "job_title": "Cloud Leader -Data Analyst",
      "company": "Niveus Solutions",
      "location": "Mangaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 144,
    "job_id": "RS-1",
    "chunk_id": 2,
    "source_file": "RS-1.pdf",
    "folder": "D:/Project_2",
    "text": "- Work \nclosely with business stakeholders to gather and document requirements for \nreporting and analytics. - Design scalable data architecture and develop ETL \nprocesses for data i ntegration. - Utilize cloud -based data analytics tools to \ngenerate actionable insights. - Create and maintain dashboards and reports to \nvisualize data trends and KPIs. - Monitor and ensure data quality and integrity \nacross various platforms. - Provide reco mmendations for data -driven strategies to \nimprove business processes.",
    "metadata": {
      "job_title": "Cloud Leader -Data Analyst",
      "company": "Niveus Solutions",
      "location": "Mangaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 145,
    "job_id": "RS-1",
    "chunk_id": 3,
    "source_file": "RS-1.pdf",
    "folder": "D:/Project_2",
    "text": "- Monitor and ensure data quality and integrity \nacross various platforms. - Provide reco mmendations for data -driven strategies to \nimprove business processes. - Stay updated on industry trends in cloud computing \nand data analytics. Skills Required:  \n- Proficiency in data analysis and visualization tools such as Tableau, Power BI, or \nsimilar. - Strong knowledge of SQL and experience with cloud databases like Amazon \nRedshift, Google BigQuery, or Azure SQL Database. - Familiarity with cloud platforms (AWS, Google Cloud, Azure) and their data \nservices.",
    "metadata": {
      "job_title": "Cloud Leader -Data Analyst",
      "company": "Niveus Solutions",
      "location": "Mangaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 146,
    "job_id": "RS-1",
    "chunk_id": 4,
    "source_file": "RS-1.pdf",
    "folder": "D:/Project_2",
    "text": "- Strong knowledge of SQL and experience with cloud databases like Amazon \nRedshift, Google BigQuery, or Azure SQL Database. - Familiarity with cloud platforms (AWS, Google Cloud, Azure) and their data \nservices. - Understanding of data warehousing concepts and architecture. - Experience in data migration and ETL tools (e.g., Talend, Informatica, Apache \nNiFi). - Excellent communication and presentati on skills for conveying complex data \ninsights to stakeholders. - Strong analytical and problem -solving skills.",
    "metadata": {
      "job_title": "Cloud Leader -Data Analyst",
      "company": "Niveus Solutions",
      "location": "Mangaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 147,
    "job_id": "RS-1",
    "chunk_id": 5,
    "source_file": "RS-1.pdf",
    "folder": "D:/Project_2",
    "text": "- Excellent communication and presentati on skills for conveying complex data \ninsights to stakeholders. - Strong analytical and problem -solving skills. - Ability to work collaboratively in a team -oriented environment. Tools Required:  \n- Data visualization tools (Tableau, Power BI, Looker). - SQL for data querying and manipulation. - Cloud services (AWS, Google Cloud Platform, Azure).",
    "metadata": {
      "job_title": "Cloud Leader -Data Analyst",
      "company": "Niveus Solutions",
      "location": "Mangaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 148,
    "job_id": "RS-1",
    "chunk_id": 6,
    "source_file": "RS-1.pdf",
    "folder": "D:/Project_2",
    "text": "- SQL for data querying and manipulation. - Cloud services (AWS, Google Cloud Platform, Azure). - ETL tools (Talend, Informatica, Apache Airflow). - Programming knowledge in Python or R for data analysis and scripting. - Familiarity with Agile methodologies and project management tools (Jira, Trello, \nor similar).",
    "metadata": {
      "job_title": "Cloud Leader -Data Analyst",
      "company": "Niveus Solutions",
      "location": "Mangaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 149,
    "job_id": "RS-1",
    "chunk_id": 7,
    "source_file": "RS-1.pdf",
    "folder": "D:/Project_2",
    "text": "- Familiarity with Agile methodologies and project management tools (Jira, Trello, \nor similar).",
    "metadata": {
      "job_title": "Cloud Leader -Data Analyst",
      "company": "Niveus Solutions",
      "location": "Mangaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 150,
    "job_id": "RS-10",
    "chunk_id": 1,
    "source_file": "RS-10.pdf",
    "folder": "D:/Project_2",
    "text": "Company : KPMG India \nJob role     : Data Analyst \nLocation  :  Bengaluru, Karnataka, India \nAbout the job \nAbout KPMG in Indi a : \nKPMG entities in India are profession al services firm(s). Thes e Indian member firms are \naffiliated wit h KPMG I nternationa l Limited. KPMG was establis hed in India in August \n1993. Our professionals leverage the global network of firms, a nd are conversan t with \nlocal laws, regulations , markets a nd competition. KPMG has offices across India in \nAhmedaba d, Bengaluru, Chandigar h, Chennai, Gurugram , Jaipur, Hyderabad, Jaipur, \nKochi, Kolkata, Mumbai, Noida, Pune , Vadodara and Vijayawada. KPMG entities in India offer services to national and international clients in India across \nsectors.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "KPMG India",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 151,
    "job_id": "RS-10",
    "chunk_id": 2,
    "source_file": "RS-10.pdf",
    "folder": "D:/Project_2",
    "text": "KPMG has offices across India in \nAhmedaba d, Bengaluru, Chandigar h, Chennai, Gurugram , Jaipur, Hyderabad, Jaipur, \nKochi, Kolkata, Mumbai, Noida, Pune , Vadodara and Vijayawada. KPMG entities in India offer services to national and international clients in India across \nsectors. W e strive to provide rapid, performance-bas ed, industry-focus ed, and \ntechnology-enabl ed services, which reflect a shared knowledge of global and local \nindustries and our experience of the Indian business environment. About the Job : \nExperience - 6+ Years \nFunctional Skills \n•Determining, creating, and implementing internal process improvements, such\nas redesigning infrastructure for increased scalability, improving data delivery,\nand automating manual procedures. •Building analytical tools that make use of the data flow and offer a practical\nunderstanding of crucial company performance indicators like operational\neffectiveness and customer acquisition. •Helping stakeholders, including the data, design, product, and executive teams,\nwith technical data difficulties.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "KPMG India",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 152,
    "job_id": "RS-10",
    "chunk_id": 3,
    "source_file": "RS-10.pdf",
    "folder": "D:/Project_2",
    "text": "•Building analytical tools that make use of the data flow and offer a practical\nunderstanding of crucial company performance indicators like operational\neffectiveness and customer acquisition. •Helping stakeholders, including the data, design, product, and executive teams,\nwith technical data difficulties. •Working on data -related technical challenges while collaborating with\nstakeholders, including the Executive, Product, Data, and Design teams, to\nsupport their data infrastructure needs. •Remaining up to date with developments in technology and industry norms can\nhelp you to produce higher -quality results. Technical Skills:  \n•Analyze large datasets to derive actionable insights and support decision -\nmaking processes. •Develop and maintain data pipelines using PySpark and other data processing\ntools.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "KPMG India",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 153,
    "job_id": "RS-10",
    "chunk_id": 4,
    "source_file": "RS-10.pdf",
    "folder": "D:/Project_2",
    "text": "Technical Skills:  \n•Analyze large datasets to derive actionable insights and support decision -\nmaking processes. •Develop and maintain data pipelines using PySpark and other data processing\ntools. •Write efficient SQL queries to extract, transform, and load data from various\nsources. •Implement data models and schemas to organize and optimize data storage and\nretrieval. •Perform data normalization and denormalization to ensure data integrity and\naccessibility. •Collaborate with data engineers to centralize and manage data assets.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "KPMG India",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 154,
    "job_id": "RS-10",
    "chunk_id": 5,
    "source_file": "RS-10.pdf",
    "folder": "D:/Project_2",
    "text": "•Perform data normalization and denormalization to ensure data integrity and\naccessibility. •Collaborate with data engineers to centralize and manage data assets. •Ensure data quality through validation and cleansing processes. •Utilize CI/CD pipelines to streamline data deployment and maintain continuous\nintegration. Qualifications:  \n•6 years or more Proven experience in data analytics and working with large\ndatasets. •Proficiency in Python, including libraries such as Pandas and Numpy for data\nmanipulation.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "KPMG India",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 155,
    "job_id": "RS-10",
    "chunk_id": 6,
    "source_file": "RS-10.pdf",
    "folder": "D:/Project_2",
    "text": "Qualifications:  \n•6 years or more Proven experience in data analytics and working with large\ndatasets. •Proficiency in Python, including libraries such as Pandas and Numpy for data\nmanipulation. •Strong SQL skills for querying and managing databases. • Experience with PySpark for large -scale data processing. • Basic understanding of Hadoop and its ecosystem. • Familiarity with data engineering concepts and best practices.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "KPMG India",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 156,
    "job_id": "RS-10",
    "chunk_id": 7,
    "source_file": "RS-10.pdf",
    "folder": "D:/Project_2",
    "text": "• Basic understanding of Hadoop and its ecosystem. • Familiarity with data engineering concepts and best practices. • Knowledge of data modeling, including schemas, normalization, and \ndenormalization techniques. • Understanding of data centralization, cardinality, and data quality principles. • Good to have experience in CI/CD pipelines and tools  \nBanking  \n• Deep understanding of banking operations, financial products, and regulatory \nframeworks  \n• Experience with data modeling, ETL processes, and statistical analysis  \n• Prior experience in retail or corporate banking analytics  \n• Analyze banking data including customer transactions, loan performance, and \nfinancial statements  \n• Support credit risk analysis and fraud detection initiatives  \n• Maintain and optimize banking databases and data pipelines  \n \n \nEqual employment opportunity information  \n \n \nKPMG India has a policy of providing equal opportunity for all applicants and employees \nregardless of their color, caste, religion, age, sex/gender, national origin, citizenship, \nsexual orientation, gender identity or expression, disability or other legall y protected \nstatus. KPMG India values diversity and we request you to submit the details below to \nsupport us in our endeavor for diversity.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "KPMG India",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 157,
    "job_id": "RS-10",
    "chunk_id": 8,
    "source_file": "RS-10.pdf",
    "folder": "D:/Project_2",
    "text": "• Good to have experience in CI/CD pipelines and tools  \nBanking  \n• Deep understanding of banking operations, financial products, and regulatory \nframeworks  \n• Experience with data modeling, ETL processes, and statistical analysis  \n• Prior experience in retail or corporate banking analytics  \n• Analyze banking data including customer transactions, loan performance, and \nfinancial statements  \n• Support credit risk analysis and fraud detection initiatives  \n• Maintain and optimize banking databases and data pipelines  \n \n \nEqual employment opportunity information  \n \n \nKPMG India has a policy of providing equal opportunity for all applicants and employees \nregardless of their color, caste, religion, age, sex/gender, national origin, citizenship, \nsexual orientation, gender identity or expression, disability or other legall y protected \nstatus. KPMG India values diversity and we request you to submit the details below to \nsupport us in our endeavor for diversity. Providing the below information is voluntary \nand refusal to submit such information will not be prejudicial to you.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "KPMG India",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 158,
    "job_id": "RS-2",
    "chunk_id": 1,
    "source_file": "RS-2.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Dexian  \nJob role     : Data Analyst  \nLocation   : Bengaluru, Karnataka, India  \n \nAbout the job  \nWe are seeking a motivated and detail -oriented Data Analyst to join our team. The role \ninvolves analyzing drone and aircraft -based imagery, assessing the quality and \nperformance of solar PV modules, and preparing accurate reports for client \ndeliverables. T his position is ideal for fresh graduates looking to start their career in the \nrenewable energy and solar analytics domain. Key Responsibilities  \n• Analyze and interpret data from drone and aircraft -based images  \n• Assess the performance, quality, and condition of solar PV modules  \n• Identify defects, anomalies, and performance issues in solar assets  \n• Prepare comprehensive reports and client deliverables  \n• Ensure data accuracy and compliance with quality standards  \n• Learn and adapt to new software tools and technologies  \n• Support additional tasks and responsibilities as assigned  \n \n \nQualifications  \n• 0 – 6 months of experience in a relevant field (Freshers welcome)  \n• Undergraduate or Postgraduate degree in:  \n• Geography  \n• Physics  \n• Engineering  \n• Environmental Science  \n• Renewable Energy  \n• Or related disciplines  \n• Strong analytical and problem -solving skills  \n• Good interpersonal and communication skills  \n• High attention to detail  \n \n \nPreferred / Good -to-Have Skills  \n• Basic electrical knowledge  \n• Understanding of solar PV systems and solar plant design  \n• Ability to quickly learn and adapt to new software and tools  \n• Familiarity with data analysis, image analysis, or GIS concepts (added \nadvantage)  \n \n \nWork Requirements  \n• Ability to sit and stand for extended periods as required  \n• Comfortable working on computers for long durations",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Dexian",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 159,
    "job_id": "RS-3",
    "chunk_id": 1,
    "source_file": "RS-3.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Talentorix  \nJob role     : Data Analyst  \nLocation   :  India  \n \nAbout the job  \nJob Title:  Data Analyst  \nCompany Name:  Hexa Solution  \nEmployment Type:  Full-Time  \nWork Mode:  Work From Home  \nWorking Days:  5 Days per Week  \nWork Schedule:  Flexible Hours  \n \n \nAbout the Opportunity  \nTalentorix is hiring a Data Analyst for its client organization, Hexa Solution. This role is \nsuitable for candidates who are interested in working with data, building analytical \ninsights, and supporting business decision -making through structured analysis. Role Overview  \nThe Data Analyst will support data collection, analysis, and reporting activities. The role \ninvolves working closely with senior analysts and cross -functional teams to turn raw \ndata into meaningful insights that support business goals. Key Responsibilities  \n• Assist in collecting, cleaning, and processing data from multiple sources  \n• Perform exploratory data analysis to identify trends, patterns, and anomalies  \n• Create dashboards and visual reports to present insights clearly  \n• Support senior analysts in statistical analysis and basic predictive modeling  \n• Translate business requirements into analytical tasks in collaboration with team \nmembers  \n• Document data analysis processes and methodologies  \n• Learn and apply new data analysis tools and techniques as required  \n• Participate in team meetings and share progress updates or findings  \n• Support data quality checks and validation of analytical outputs  \n• Assist with ad -hoc data analysis tasks and projects  \n \n \nSkills & Eligibility  \n• Basic understanding of data analysis concepts and analytical thinking  \n• Strong problem -solving mindset and attention to detail  \n• Willingness to learn new tools, techniques, and processes  \n• Good communication and collaboration skills  \n• Candidates with a learning -oriented attitude and interest in data analytics are \nencouraged to apply  \n \n \nAbout Talentorix  \nTalentorix is a staffing and recruitment firm that supports organizations by managing \ntheir hiring requirements. We work with client companies to identify suitable candidates \nand facilitate a structured and transparent recruitment process.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Talentorix",
      "location": "India"
    }
  },
  {
    "vector_id": 160,
    "job_id": "RS-3",
    "chunk_id": 2,
    "source_file": "RS-3.pdf",
    "folder": "D:/Project_2",
    "text": "Key Responsibilities  \n• Assist in collecting, cleaning, and processing data from multiple sources  \n• Perform exploratory data analysis to identify trends, patterns, and anomalies  \n• Create dashboards and visual reports to present insights clearly  \n• Support senior analysts in statistical analysis and basic predictive modeling  \n• Translate business requirements into analytical tasks in collaboration with team \nmembers  \n• Document data analysis processes and methodologies  \n• Learn and apply new data analysis tools and techniques as required  \n• Participate in team meetings and share progress updates or findings  \n• Support data quality checks and validation of analytical outputs  \n• Assist with ad -hoc data analysis tasks and projects  \n \n \nSkills & Eligibility  \n• Basic understanding of data analysis concepts and analytical thinking  \n• Strong problem -solving mindset and attention to detail  \n• Willingness to learn new tools, techniques, and processes  \n• Good communication and collaboration skills  \n• Candidates with a learning -oriented attitude and interest in data analytics are \nencouraged to apply  \n \n \nAbout Talentorix  \nTalentorix is a staffing and recruitment firm that supports organizations by managing \ntheir hiring requirements. We work with client companies to identify suitable candidates \nand facilitate a structured and transparent recruitment process.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Talentorix",
      "location": "India"
    }
  },
  {
    "vector_id": 161,
    "job_id": "RS-4",
    "chunk_id": 1,
    "source_file": "RS-4.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Tesco Bengaluru  \nJob role     : Data Analyst  \nLocation   :  Bengaluru, Karnataka, India  \n \nAbout the job  \nAbout the role  \nPlease Refer to You are Responsible For: - \nYou will be responsible for  \nIdentifying operational improvements and finding solutions by applying CI tools and \ntechniques - Responsible for completing tasks and transactions within agreed KPI's - \nKnows and applies fundamental work theories/concepts/processes in own areas of \nwork-Engage with market partners to understand problems to be solved, translate the \nbusiness problems to analytical problems, taking ownership of specified analysis and \ntranslate the answers back to decision makers in business - Manipulating, analyzing and \nsynthesizi ng large complex data sets using different sources and ensuring data quality \nand integrity - Responsible for high quality and timely completion of specified work \ndeliverables - Support automation of repeatable tasks, report generation or dashboard \nrefresh- Think beyond the ask and develop analysis and reports that will contribute \nbeyond basic asks - Write codes that are well detailed, structured, and compute \nefficient- Contribute to development of knowledge assets and reusable modules on \nGitHub/Wiki - Ability to generate practical insights that drive decisions in our business \noperations - Understands business needs and in depth understanding of Tesco \nprocesses - Responsible for completing tasks and transactions within agreed important \nmetrics  \nY \nou will need  \nBasic understanding of Business Decisions, Basic Skills to develop visualizations, self -\nservice dashboards and reports using Tableau & Basic Statistical Concepts (Correlation \nAnalysis and Hyp. Testing), Basic skills to analyze data using Adv Excel, SQL, Hi ve, Basic \nDW concepts on Hadoop and Teradata, Automation using alteryx/ python is good to \nhave  \n \nWhats in it for you? At Tesco, we are committed to providing the best for you. As a result, our colleagues enjoy a unique, differentiated, market - competitive reward \npackage, based on the current industry practices, for all the work they put into serving \nour customers, communities and planet a little better every day. Our Tesco Rewards framework consists of pillars - Fixed Pay, Incentives, and Benefits. Total Rewards offered at Tesco is determined by four principles - simple, fair, \ncompetitive, and sustainable.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Tesco Bengaluru",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 162,
    "job_id": "RS-4",
    "chunk_id": 2,
    "source_file": "RS-4.pdf",
    "folder": "D:/Project_2",
    "text": "Our Tesco Rewards framework consists of pillars - Fixed Pay, Incentives, and Benefits. Total Rewards offered at Tesco is determined by four principles - simple, fair, \ncompetitive, and sustainable. Salary - Your fixed pay is the guaranteed pay as per your contract of employment. Performance Bonus  - Opportunity to earn additional compensation bonus based on \nperformance, paid annually   \n  \nLeave & Time -off - Colleagues are entitled to 30 days of leave (18 days of Earned Leave, \n12 days of Casual/Sick Leave) and 10 national and festival holidays, as per the \ncompany’s policy. Making Retirement Tension -FreeSalary  - In addition to Statutory retirement beneets, \nTesco enables colleagues to participate in voluntary programmes like NPS and VPF. Health is Wealth  - Tesco promotes programmes that support a culture of health and \nwellness including insurance for colleagues and their family.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Tesco Bengaluru",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 163,
    "job_id": "RS-4",
    "chunk_id": 3,
    "source_file": "RS-4.pdf",
    "folder": "D:/Project_2",
    "text": "Making Retirement Tension -FreeSalary  - In addition to Statutory retirement beneets, \nTesco enables colleagues to participate in voluntary programmes like NPS and VPF. Health is Wealth  - Tesco promotes programmes that support a culture of health and \nwellness including insurance for colleagues and their family. Our medical insurance \nprovides coverage for dependents including parents or in -laws. Mental Wellbeing  - We offer mental health support through self -help tools, community \ngroups, ally networks, face -to-face counselling, and more for both colleagues and \ndependents. Financial Wellbeing  - Through our financial literacy partner, we offer one -to-one \nfinancial coaching at discounted rates, as well as salary advances on earned wages \nupon request. Save As You Earn (SAYE)  - Our SAYE programme allows colleagues to transition from \nbeing employees to Tesco shareholders through a structured 3 -year savings plan.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Tesco Bengaluru",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 164,
    "job_id": "RS-4",
    "chunk_id": 4,
    "source_file": "RS-4.pdf",
    "folder": "D:/Project_2",
    "text": "Financial Wellbeing  - Through our financial literacy partner, we offer one -to-one \nfinancial coaching at discounted rates, as well as salary advances on earned wages \nupon request. Save As You Earn (SAYE)  - Our SAYE programme allows colleagues to transition from \nbeing employees to Tesco shareholders through a structured 3 -year savings plan. Physical Wellbeing  - Our green campus promotes physical wellbeing with facilities that \ninclude a cricket pitch, football field, badminton and volleyball courts, along with indoor \ngames, encouraging a healthier lifestyle. About Us  \nAt Tesco, inclusion is at the heart of everything we do. We believe in treating everyone \nfairly and with respect, valuing individuality and uniqueness to create a true sense of \nbelonging. Diversity and inclusion are deeply embedded in our values —we treat p eople \nhow they want to be treated.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Tesco Bengaluru",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 165,
    "job_id": "RS-4",
    "chunk_id": 5,
    "source_file": "RS-4.pdf",
    "folder": "D:/Project_2",
    "text": "We believe in treating everyone \nfairly and with respect, valuing individuality and uniqueness to create a true sense of \nbelonging. Diversity and inclusion are deeply embedded in our values —we treat p eople \nhow they want to be treated. Our goal is for all colleagues to feel they can be \nthemselves at work, and we are committed to helping them thrive. Across the Tesco \ngroup, we are building an inclusive workplace that actively celebrates the cultures, \npersonali ties, and preferences of our colleagues, who in turn contribute to the success \nof our business and reflect the diversity of the communities we serve. At Tesco Bengaluru, we are proud to be a Disability Confident Committed Employer, \nhighlighting our com mitment to creating a supportive environment for individuals with \ndisabilities. We are dedicated to offering equal opportunities for all candidates and \nencourage applicants with disabilities to apply.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Tesco Bengaluru",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 166,
    "job_id": "RS-4",
    "chunk_id": 6,
    "source_file": "RS-4.pdf",
    "folder": "D:/Project_2",
    "text": "At Tesco Bengaluru, we are proud to be a Disability Confident Committed Employer, \nhighlighting our com mitment to creating a supportive environment for individuals with \ndisabilities. We are dedicated to offering equal opportunities for all candidates and \nencourage applicants with disabilities to apply. Our recruitment process is fully \naccessible, and we are  happy to provide reasonable adjustments during interviews. If \nyou need any accommodations to participate in the recruitment process, please let us \nknow. We are here to ensure that everyone has the chance to succeed. We also believe in fostering a work  environment where you can excel both \nprofessionally and personally.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Tesco Bengaluru",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 167,
    "job_id": "RS-4",
    "chunk_id": 7,
    "source_file": "RS-4.pdf",
    "folder": "D:/Project_2",
    "text": "We are here to ensure that everyone has the chance to succeed. We also believe in fostering a work  environment where you can excel both \nprofessionally and personally. Our hybrid model allows you to work flexibly —spend 60% \nof your week collaborating in person with colleagues at our office locations or local \nsites, and the rest of the time working remote ly. We understand that everyone’s life \njourney is unique, whether you are starting your career, pursuing passions, or navigating \nlife changes, and we are here to support you. Flexibility is a core part of our culture, and \nwe encourage open conversations ab out how we can best accommodate your needs, \nso talk to us throughout your application process on the support required.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Tesco Bengaluru",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 168,
    "job_id": "RS-4",
    "chunk_id": 8,
    "source_file": "RS-4.pdf",
    "folder": "D:/Project_2",
    "text": "Flexibility is a core part of our culture, and \nwe encourage open conversations ab out how we can best accommodate your needs, \nso talk to us throughout your application process on the support required.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Tesco Bengaluru",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 169,
    "job_id": "RS-5",
    "chunk_id": 1,
    "source_file": "RS-5.pdf",
    "folder": "D:/Project_2",
    "text": " \n \nCompany : Stier Solutions Inc  \nJob role     : Junior Data Analyst  \nLocation   :  Hyderabad, Telangana, India  · \n \n \n \nAbout the job  \nJob Title:  Junior Data Analyst  \nLocation:  Hyderabad, Telangana  \nEmployment Type:  Full-time | On -site / Hybrid  \nAbout the Role  \nWe are looking for a detail -oriented and analytical  Junior Data Analyst  to support our \ndata and business teams. In this role, you will work with data to generate insights, \ncreate reports, and help drive informed decision -making. This position is ideal for fresh \ngraduates or early -career professionals eager to build a strong fo undation in data \nanalytics. Key Responsibilities  \n• Collect, clean, and analyze data from multiple sources. • Prepare reports, dashboards, and visualizations for business stakeholders. • Identify trends, patterns, and anomalies to support decision -making.",
    "metadata": {
      "job_title": "Junior Data Analyst",
      "company": "Stier Solutions Inc",
      "location": "Hyderabad, Telangana, India  ·"
    }
  },
  {
    "vector_id": 170,
    "job_id": "RS-5",
    "chunk_id": 2,
    "source_file": "RS-5.pdf",
    "folder": "D:/Project_2",
    "text": "• Prepare reports, dashboards, and visualizations for business stakeholders. • Identify trends, patterns, and anomalies to support decision -making. • Work with cross -functional teams to understand data requirements. • Maintain data accuracy, consistency, and documentation. • Support ad -hoc analysis and ongoing reporting needs. Required Skills & Qualifications  \n• Bachelor’s degree in Data Science, Statistics, Computer Science, Economics, or \na related field.",
    "metadata": {
      "job_title": "Junior Data Analyst",
      "company": "Stier Solutions Inc",
      "location": "Hyderabad, Telangana, India  ·"
    }
  },
  {
    "vector_id": 171,
    "job_id": "RS-5",
    "chunk_id": 3,
    "source_file": "RS-5.pdf",
    "folder": "D:/Project_2",
    "text": "• Support ad -hoc analysis and ongoing reporting needs. Required Skills & Qualifications  \n• Bachelor’s degree in Data Science, Statistics, Computer Science, Economics, or \na related field. • 0–2 years of experience in data analysis (internships or academic projects \naccepted). • Strong proficiency in Excel or Google Sheets. • Basic to intermediate knowledge of SQL. • Familiarity with data visualization tools such as Power BI, Tableau, or Looker.",
    "metadata": {
      "job_title": "Junior Data Analyst",
      "company": "Stier Solutions Inc",
      "location": "Hyderabad, Telangana, India  ·"
    }
  },
  {
    "vector_id": 172,
    "job_id": "RS-5",
    "chunk_id": 4,
    "source_file": "RS-5.pdf",
    "folder": "D:/Project_2",
    "text": "• Basic to intermediate knowledge of SQL. • Familiarity with data visualization tools such as Power BI, Tableau, or Looker. • Strong analytical thinking and attention to detail. • Good communication and problem -solving skills. Preferred / Good -to-Have  \n• Basic knowledge of Python or R for data analysis. • Understanding of basic statistical concepts.",
    "metadata": {
      "job_title": "Junior Data Analyst",
      "company": "Stier Solutions Inc",
      "location": "Hyderabad, Telangana, India  ·"
    }
  },
  {
    "vector_id": 173,
    "job_id": "RS-5",
    "chunk_id": 5,
    "source_file": "RS-5.pdf",
    "folder": "D:/Project_2",
    "text": "Preferred / Good -to-Have  \n• Basic knowledge of Python or R for data analysis. • Understanding of basic statistical concepts. • Exposure to dashboards, KPIs, and business metrics. • Experience working with large datasets. Why Join Us  \n• Hands-on exposure to real -world data and business use cases. • Learning and mentorship from experienced analytics professionals.",
    "metadata": {
      "job_title": "Junior Data Analyst",
      "company": "Stier Solutions Inc",
      "location": "Hyderabad, Telangana, India  ·"
    }
  },
  {
    "vector_id": 174,
    "job_id": "RS-5",
    "chunk_id": 6,
    "source_file": "RS-5.pdf",
    "folder": "D:/Project_2",
    "text": "Why Join Us  \n• Hands-on exposure to real -world data and business use cases. • Learning and mentorship from experienced analytics professionals. • Collaborative and growth -focused work culture. • Competitive salary with clear career growth opportunities.",
    "metadata": {
      "job_title": "Junior Data Analyst",
      "company": "Stier Solutions Inc",
      "location": "Hyderabad, Telangana, India  ·"
    }
  },
  {
    "vector_id": 175,
    "job_id": "RS-6",
    "chunk_id": 1,
    "source_file": "RS-6.pdf",
    "folder": "D:/Project_2",
    "text": " \nCompany : Infosys  \nJob role     : Data Analyst  \nLocation   :  Trivandrum, Kerala, India  \n \n \nAbout the job  \n• Primary skills:Technology ->Analytics - Packages ->Python - Big Data,Technology -\n>Cloud Platform ->Google Big Data,Technology ->Oracle Cloud ->Service Cloud -\n>Agent Scripting,Technology ->Reporting, Analytics & Visualization ->Pentaho \nReporting  \n•  Desirables:Technology ->Machine Learning ->Python  \n \n \nA day in the life of an Infoscion  \n \n \n•  As part of the Infosys consulting team, your primary role would be to lead the \nengagement effort of providing high -quality and value -adding consulting \nsolutions to customers at different stages - from problem definition to diagnosis \nto solution design, deve lopment and deployment. •  You will review the proposals prepared by consultants, provide guidance, and \nanalyze the solutions defined for the client business problems to identify any \npotential risks and issues. •  You will identify change Management requirements and propose a structured \napproach to client for managing the change using multiple communication \nmechanisms. •  You will also coach and create a vision for the team, provide subject matter \ntraining for your focus areas, motivate and inspire team members through \neffective and timely feedback and recognition for high performance. •  You would be a key contributor in unit -level and organizational initiatives with an \nobjective of providing high -quality, value -adding consulting solutions to \ncustomers adhering to the guidelines and processes of the organization. If you \nthink you fit right in to help our clients navigate their next in their digital \ntransformation journey, this is the place for you!",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Infosys",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 176,
    "job_id": "RS-6",
    "chunk_id": 2,
    "source_file": "RS-6.pdf",
    "folder": "D:/Project_2",
    "text": "•  You would be a key contributor in unit -level and organizational initiatives with an \nobjective of providing high -quality, value -adding consulting solutions to \ncustomers adhering to the guidelines and processes of the organization. If you \nthink you fit right in to help our clients navigate their next in their digital \ntransformation journey, this is the place for you! •  Good knowledge on software configuration management systems  \n•  Strong business acumen, strategy and cross -industry thought leadership  \n•  Awareness of latest technologies and Industry trends  \n•  Logical thinking and problem solving skills along with an ability to collaborate  \n•  Two or three industry domain knowledge  \n•  Understanding of the financial processes for various types of projects and the \nvarious pricing models available  \n•  Client Interfacing skills  \n•  Knowledge of SDLC and agile methodologies  \n•  Project and Team management",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Infosys",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 177,
    "job_id": "RS-7",
    "chunk_id": 1,
    "source_file": "RS-7.pdf",
    "folder": "D:/Project_2",
    "text": " \nGroww  \nJob role     : Data Analyst  \nLocation   :  Greater Bengaluru Area  \n \n \nAbout the job  \nAbout Groww:  \nWe are a passionate group of people focused on making financial services accessible to \nevery Indian through a multi -product platform. Each day, we help millions of customers \ntake charge of their financial journey. Customer obsession is in our DNA. Every pr oduct, \nevery design, every algorithm down to the tiniest detail is executed keeping the \ncustomers’ needs and convenience in mind. Our people are our greatest strength. Everyone at Groww is driven by ownership, customer -centricity, integrity and the \npassion to constantly challenge the status quo.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Unknown",
      "location": "Greater Bengaluru Area"
    }
  },
  {
    "vector_id": 178,
    "job_id": "RS-7",
    "chunk_id": 2,
    "source_file": "RS-7.pdf",
    "folder": "D:/Project_2",
    "text": "Our people are our greatest strength. Everyone at Groww is driven by ownership, customer -centricity, integrity and the \npassion to constantly challenge the status quo. Are you as passionate about defying conventions and creating something extraordinary \nas we are? Let’s chat. Our Vision  \nEvery individual deserves the knowledge, tools, and confidence to make informed \nfinancial decisions. At Groww, we are making sure every Indian feels empowered to do \nso through a cutting -edge multi -product platform offering a variety of financial services.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Unknown",
      "location": "Greater Bengaluru Area"
    }
  },
  {
    "vector_id": 179,
    "job_id": "RS-7",
    "chunk_id": 3,
    "source_file": "RS-7.pdf",
    "folder": "D:/Project_2",
    "text": "Our Vision  \nEvery individual deserves the knowledge, tools, and confidence to make informed \nfinancial decisions. At Groww, we are making sure every Indian feels empowered to do \nso through a cutting -edge multi -product platform offering a variety of financial services. Our long-term vision is to become the trusted financial partner for millions of Indians. Our Values  \nOur culture enables us to be what we are — India’s fastest -growing financial services \ncompany. It fosters an environment where collaboration, transparency, and open \ncommunication take center -stage and hierarchies fade away. There is space for every \nindividual to be themselves and feel motivated to bring their best to the table, as well as \ncraft a promising career for themselves.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Unknown",
      "location": "Greater Bengaluru Area"
    }
  },
  {
    "vector_id": 180,
    "job_id": "RS-7",
    "chunk_id": 4,
    "source_file": "RS-7.pdf",
    "folder": "D:/Project_2",
    "text": "It fosters an environment where collaboration, transparency, and open \ncommunication take center -stage and hierarchies fade away. There is space for every \nindividual to be themselves and feel motivated to bring their best to the table, as well as \ncraft a promising career for themselves. The values that form our foundation are:  \n• Radical customer centricity  \n• Ownership -driven culture  \n• Keeping everything simple  \n• Long-term thinking  \n• Complete transparency  \n \n \nKey Role & Responsibilities:   \n- Preparing reports for the management stating trends & patterns using relevant data   \n- Handle Day to day ad hoc data requests from stakeholders   \n- Dashboarding and Automation of key metrics   \n- Supporting initiatives for data integrity and normalization   \n- Supporting the data warehouse in identifying and revising reporting requirements   \n  \nKey Skills & Experience:   \n- 1-3 years of relevant Analytics experience as a data analyst or in a related field   \n- Proficiency with SQL   \n- Familiar with Data Visualization",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Unknown",
      "location": "Greater Bengaluru Area"
    }
  },
  {
    "vector_id": 181,
    "job_id": "RS-8",
    "chunk_id": 1,
    "source_file": "RS-8.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Scoutit  \nJob role     : Data Analyst  \nLocation   :  Bengaluru, Karnataka, India  · \n \n \n \nAbout the job  \nWe're looking for  Data Analysts ! Salary: INR 18,00,000 - 20,00,000 / year  \n \nResponsibilities  \n \n \n• Clean, organize, and validate data to ensure accuracy and completeness. • Utilize Microsoft Excel, VBA, and SQL for data manipulation, analysis, and \nreporting. • Collaborate with cross -functional teams to understand data requirements and \ndeliver actionable insights. • Generate and publish excel reports for further uses  \n• Apply knowledge to enhance data analysis and reporting. Eligibility  \n \n \n• Bachelor's degree in Computer Application, Science, or relevant education.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Scoutit",
      "location": "Bengaluru, Karnataka, India  ·"
    }
  },
  {
    "vector_id": 182,
    "job_id": "RS-8",
    "chunk_id": 2,
    "source_file": "RS-8.pdf",
    "folder": "D:/Project_2",
    "text": "• Generate and publish excel reports for further uses  \n• Apply knowledge to enhance data analysis and reporting. Eligibility  \n \n \n• Bachelor's degree in Computer Application, Science, or relevant education. • 1 year of experience in data acquisition & analysis or a related field. • Proficiency in Microsoft Excel, Microsoft Office, VBA, SQL  \n• Strong analytical skills and attention to detail. • Excellent communication and teamwork abilities. • Ability to manage multiple tasks and meet deadlines.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Scoutit",
      "location": "Bengaluru, Karnataka, India  ·"
    }
  },
  {
    "vector_id": 183,
    "job_id": "RS-8",
    "chunk_id": 3,
    "source_file": "RS-8.pdf",
    "folder": "D:/Project_2",
    "text": "• Excellent communication and teamwork abilities. • Ability to manage multiple tasks and meet deadlines.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Scoutit",
      "location": "Bengaluru, Karnataka, India  ·"
    }
  },
  {
    "vector_id": 184,
    "job_id": "RS-9",
    "chunk_id": 1,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Barclays  \n \nJob role     : Data Analyst  \nLocation   :  Bengaluru, Karnataka, India  \n \n \nAbout the job  \nJoin us as a Data Analyst at Barclays where you'll spearhead the evolution of our \nwarehouse landscape for all Analytics work, driving innovation and excellence. You'll \nharness cutting -edge technology to revolutionize our data engineering, ensuring \nunappare lled customer experiences. You may be assessed on the key critical skills \nrelevant for success in role. To be successful as Data Analyst you should have experience with:  \n \n \n \n• Banking Domain Knowledge preferably collection and recovery lending. • Writing Complex SQL Scripting, and strong Data Profiling. • Create source to target mapping and support Data Engineers in developing code.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 185,
    "job_id": "RS-9",
    "chunk_id": 2,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "• Writing Complex SQL Scripting, and strong Data Profiling. • Create source to target mapping and support Data Engineers in developing code. • Working knowledge on Warehousing projects. • Teradata / Oracle / Bigdata / Cloud Concepts. • Working knowledge on Data Modelling Tool. Below Given Additional Relevant Skills Are Highly Valued  \n \n \n \n• Knowledge on AWS, Python/PySpark.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 186,
    "job_id": "RS-9",
    "chunk_id": 3,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "• Working knowledge on Data Modelling Tool. Below Given Additional Relevant Skills Are Highly Valued  \n \n \n \n• Knowledge on AWS, Python/PySpark. • JIRA and Agile way of working. • Knowledge on Snowflake and Databricks. You may be assessed on key critical skills relevant for success in role, such as risk and \ncontrols, change and transformation, business acumen, strategic thinking and digital \nand technology, as well as job -specific technical skills. This role is based out of Bengaluru.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 187,
    "job_id": "RS-9",
    "chunk_id": 4,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "You may be assessed on key critical skills relevant for success in role, such as risk and \ncontrols, change and transformation, business acumen, strategic thinking and digital \nand technology, as well as job -specific technical skills. This role is based out of Bengaluru. Purpose of the role  \n \nTo enable data -driven strategic and operational decision making through extracting \nactionable insights from large datasets, performing statistical and advanced analytics \nto uncover trends and patterns, and presenting findings through clear visualisations a nd \nreports. Accountabilities  \n \n \n \n• Investigation and analysis of data issues related to quality, lineage, controls, and \nauthoritative source identification, documenting data sources, methodologies, \nand quality findings with recommendations for improvement. • Designing and building data pipelines to automate data movement and \nprocessing. • Apply advanced analytical techniques to large datasets to uncover trends and \ncorrelations, develop validated logical data models, and translate insights into \nactionable business recommendations that drive operational and process \nimprovements, leveraging ma chine learning/AI.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 188,
    "job_id": "RS-9",
    "chunk_id": 5,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "• Designing and building data pipelines to automate data movement and \nprocessing. • Apply advanced analytical techniques to large datasets to uncover trends and \ncorrelations, develop validated logical data models, and translate insights into \nactionable business recommendations that drive operational and process \nimprovements, leveraging ma chine learning/AI. • Through data -driven analysis, translate analytical findings into actionable \nbusiness recommendations, identifying opportunities for operational and \nprocess improvements. • Design and create interactive dashboards and visual reports using applicable \ntools and automate reporting processes for regular and ad -hoc stakeholder \nneeds. Analyst Expectations  \n \n \n \n• To perform prescribed activities in a timely manner and to a high standard \nconsistently driving continuous improvement. • Requires in -depth technical knowledge and experience in their assigned area of \nexpertise  \n• Thorough understanding of the underlying principles and concepts within the \narea of expertise  \n• They lead and supervise a team, guiding and supporting professional \ndevelopment, allocating work requirements and coordinating team resources.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 189,
    "job_id": "RS-9",
    "chunk_id": 6,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "Analyst Expectations  \n \n \n \n• To perform prescribed activities in a timely manner and to a high standard \nconsistently driving continuous improvement. • Requires in -depth technical knowledge and experience in their assigned area of \nexpertise  \n• Thorough understanding of the underlying principles and concepts within the \narea of expertise  \n• They lead and supervise a team, guiding and supporting professional \ndevelopment, allocating work requirements and coordinating team resources. • If the position has leadership responsibilities, People Leaders are expected to \ndemonstrate a clear set of leadership behaviours to create an environment for \ncolleagues to thrive and deliver to a consistently excellent standard. The four \nLEAD behaviours ar e: L – Listen and be authentic, E – Energise and inspire, A – \nAlign across the enterprise, D – Develop others. • OR for an individual contributor, they develop technical expertise in work area, \nacting as an advisor where appropriate. • Will have an impact on the work of related teams within the area.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 190,
    "job_id": "RS-9",
    "chunk_id": 7,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "• OR for an individual contributor, they develop technical expertise in work area, \nacting as an advisor where appropriate. • Will have an impact on the work of related teams within the area. • Partner with other functions and business areas. • Takes responsibility for end results of a team’s operational processing and \nactivities. • Escalate breaches of policies / procedure appropriately. • Take responsibility for embedding new policies/ procedures adopted due to risk \nmitigation.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 191,
    "job_id": "RS-9",
    "chunk_id": 8,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "• Escalate breaches of policies / procedure appropriately. • Take responsibility for embedding new policies/ procedures adopted due to risk \nmitigation. • Advise and influence decision making within own area of expertise. • Take ownership for managing risk and strengthening controls in relation to the \nwork you own or contribute to. Deliver your work and areas of responsibility in \nline with relevant rules, regulation and codes of conduct. • Maintain and continually build an understanding of how own sub -function \nintegrates with function, alongside knowledge of the organisations products, \nservices and processes within the function.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 192,
    "job_id": "RS-9",
    "chunk_id": 9,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "Deliver your work and areas of responsibility in \nline with relevant rules, regulation and codes of conduct. • Maintain and continually build an understanding of how own sub -function \nintegrates with function, alongside knowledge of the organisations products, \nservices and processes within the function. • Demonstrate understanding of how areas coordinate and contribute to the \nachievement of the objectives of the organisation sub -function. • Make evaluative judgements based on the analysis of factual information, paying \nattention to detail. • Resolve problems by identifying and selecting solutions through the application \nof acquired technical experience and will be guided by precedents. • Guide and persuade team members and communicate complex / sensitive \ninformation.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 193,
    "job_id": "RS-9",
    "chunk_id": 10,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "• Resolve problems by identifying and selecting solutions through the application \nof acquired technical experience and will be guided by precedents. • Guide and persuade team members and communicate complex / sensitive \ninformation. • Act as contact point for stakeholders outside of the immediate function, while \nbuilding a network of contacts outside team and external to the organisation. All colleagues will be expected to demonstrate the Barclays Values of Respect, Integrity, \nService, Excellence and Stewardship – our moral compass, helping us do what we \nbelieve is right. They will also be expected to demonstrate the Barclays Mindset – to \nEmpower, Challenge and Drive – the operating manual for how we behave.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 194,
    "job_id": "RS-9",
    "chunk_id": 11,
    "source_file": "RS-9.pdf",
    "folder": "D:/Project_2",
    "text": "They will also be expected to demonstrate the Barclays Mindset – to \nEmpower, Challenge and Drive – the operating manual for how we behave.",
    "metadata": {
      "job_title": "Data Analyst",
      "company": "Barclays",
      "location": "Bengaluru, Karnataka, India"
    }
  },
  {
    "vector_id": 195,
    "job_id": "Safran",
    "chunk_id": 1,
    "source_file": "Safran.pdf",
    "folder": "D:/Project_2",
    "text": "Company : S afran  \nJob role     :  Engineer  \nLocation  : Trivandrum, Kerala, India  \nAbout the job \n \nEducational Qualiﬁcation  \n• BE / BTech in Electronics & Communication Engineering (ECE), Applied \nElectronics (AE), Electrical & Electronics Engineering (EEE), or Electronics & \nInstrumentation (EI)  \n \n \nJob Location : Trivandrum, Kerala  \nExperience  \n• 1 to 2 years of relevant experience  \n \n \nJob Summary  \nWill be responsible for working on electronics and instrumentation systems, \nfocusing on data acquisition, embedded/Linux -based development, and system \nintegration. Roles & Responsibilities \n• Design, develop, and test electronics and instrumentation solutions  \n• Work on data acquisition systems and related hardware interfaces  \n• Develop and debug applications using  C \n• Operate in  Linux and Linux RT  environments  \n• Use  Visual Studio Code for development and troubleshooting  \n• Support system integration, validation, and testing activities  \n• Prepare technical documentation and reports \n \n \nMandatory Skills  \n• Strong knowledge of electronics and instrumentation  \n• Proﬁciency in  C programming  \n• Experience with  Visual Studio Code  \n• Working knowledge of  Linux  and  Linux RT  \n• Hands -on experience with  Data Acquisition systems  \nDesired Skills \n• Knowledge of  C++  \n• Exposure to  MIL -STD -1553  protocols  \n• Experience with  LabVIEW",
    "metadata": {
      "job_title": "Engineer",
      "company": "S afran",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 196,
    "job_id": "skyroot aerospace",
    "chunk_id": 1,
    "source_file": "skyroot aerospace.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Skyroot Aerospace  \nJob role     :  Agentic  AI Engineer  \nLocation  : Hyderabad, Telangana, India  \nAbout the job \nAbout the Role  \nWe are seeking a passionate  Agentic / Retrieval -Augmented Generation (RAG) AI \nEngineer to design, build, and optimize intelligent automation systems that \nintegrate  large language models (LLMs)  with  software development life cycle \n(SDLC)  workﬂows used in  avionics and safety -critical software projects . You will develop autonomous AI agents, RAG pipelines, and reasoning systems that \nstreamline documentation, veriﬁcation, and compliance processes in line with aerospace standards. Key Responsibilities  \n• Design and implement RAG pipelines integrating LLMs with vector \ndatabases and retrieval systems to support traceability, requirements validation, and code- document alignment. • Develop autonomous AI agents capable of multi -step reasoning, task \nexecution, and contextual decision-making across software lifecycle phases (requirements, design, code, test, veriﬁcation). • Fine -tune and evaluate LLMs  and embeddings for domain -speciﬁc avionics \nuse cases and engineering documentation. • Integrate APIs and frameworks  such as OpenAI, Anthropic, LangChain, and \nLlamaIndex into AI -driven SDLC automation workﬂows.",
    "metadata": {
      "job_title": "Agentic  AI Engineer",
      "company": "Skyroot Aerospace",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 197,
    "job_id": "skyroot aerospace",
    "chunk_id": 2,
    "source_file": "skyroot aerospace.pdf",
    "folder": "D:/Project_2",
    "text": "• Fine -tune and evaluate LLMs  and embeddings for domain -speciﬁc avionics \nuse cases and engineering documentation. • Integrate APIs and frameworks  such as OpenAI, Anthropic, LangChain, and \nLlamaIndex into AI -driven SDLC automation workﬂows. • Work with vector databases  (e.g., Pinecone, Chroma, Weaviate, Milvus) for \nefficient retrieval and knowledge management. • Implement context and memory management systems  enabling agents to \nmaintain state and learn from interactions. • Collaborate with avionics domain experts and cross -functional teams (ML, \nbackend, and veriﬁcation engineers) to deploy scalable and compliant AI solutions. • Monitor, evaluate, and optimize agent performance  for accuracy, latency, \ncost, and reliability.",
    "metadata": {
      "job_title": "Agentic  AI Engineer",
      "company": "Skyroot Aerospace",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 198,
    "job_id": "skyroot aerospace",
    "chunk_id": 3,
    "source_file": "skyroot aerospace.pdf",
    "folder": "D:/Project_2",
    "text": "• Collaborate with avionics domain experts and cross -functional teams (ML, \nbackend, and veriﬁcation engineers) to deploy scalable and compliant AI solutions. • Monitor, evaluate, and optimize agent performance  for accuracy, latency, \ncost, and reliability. • Stay current with advancements  in LLMs, RAG architectures, and AI agents, \napplying best practices to regulated software domains. Desirable Skills & Domain Knowledge  \n• Familiarity with  avionics software development processes , including  DO-\n178C , ARP4754A , and  MISRA C  guidelines. • Understanding of  model -based design , requirements traceability , and  \nautomated veriﬁcation  workﬂows. • Knowledge of  conﬁguration management , version control , and  continuous \nintegration  in safety -critical systems.",
    "metadata": {
      "job_title": "Agentic  AI Engineer",
      "company": "Skyroot Aerospace",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 199,
    "job_id": "skyroot aerospace",
    "chunk_id": 4,
    "source_file": "skyroot aerospace.pdf",
    "folder": "D:/Project_2",
    "text": "• Understanding of  model -based design , requirements traceability , and  \nautomated veriﬁcation  workﬂows. • Knowledge of  conﬁguration management , version control , and  continuous \nintegration  in safety -critical systems. • Awareness of  software assurance , review automation , and  document \ngeneration  practices for aerospace projects. • Strong analytical and problem -solving skills with the ability to bridge AI \ntechnologies  and  engineering domain expertise . Preferred Technical Stack   \n• Languages:  Python, C/C++ is a plus  \n• Frameworks:  LangChain, LlamaIndex, OpenAI API, FastAPI   \n• Databases:  Chroma, Weaviate, Pinecone, Milvus   \n• ML Tools:  Hugging Face, TensorFlow, PyTorch   \n• Deployment:  Docker, Kubernetes, Azure/OpenShift, CI/CD pipelines  \n \n \nQualiﬁcations   \n• Bachelor’s or Master’s in Computer Science, Artiﬁcial Intelligence, or \nrelated ﬁeld (Aerospace/Embedded domain exposure preferred). • 1–2 years of experience in AI/ML engineering, with hands -on work in LLM or \nRAG systems.",
    "metadata": {
      "job_title": "Agentic  AI Engineer",
      "company": "Skyroot Aerospace",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 200,
    "job_id": "skyroot aerospace",
    "chunk_id": 5,
    "source_file": "skyroot aerospace.pdf",
    "folder": "D:/Project_2",
    "text": "Preferred Technical Stack   \n• Languages:  Python, C/C++ is a plus  \n• Frameworks:  LangChain, LlamaIndex, OpenAI API, FastAPI   \n• Databases:  Chroma, Weaviate, Pinecone, Milvus   \n• ML Tools:  Hugging Face, TensorFlow, PyTorch   \n• Deployment:  Docker, Kubernetes, Azure/OpenShift, CI/CD pipelines  \n \n \nQualiﬁcations   \n• Bachelor’s or Master’s in Computer Science, Artiﬁcial Intelligence, or \nrelated ﬁeld (Aerospace/Embedded domain exposure preferred). • 1–2 years of experience in AI/ML engineering, with hands -on work in LLM or \nRAG systems. • Exposure to aerospace or defence software development is an added advantage.",
    "metadata": {
      "job_title": "Agentic  AI Engineer",
      "company": "Skyroot Aerospace",
      "location": "Hyderabad, Telangana, India"
    }
  },
  {
    "vector_id": 201,
    "job_id": "Uplers",
    "chunk_id": 1,
    "source_file": "Uplers.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Uplers  \nJob role     :  AI Engineer \nLocation  : Kochi , Kerala, India  \nAbout the job \n \nExperience : 3.00 + years  \n \nSalary: Conﬁdential (based on experience)  \n Expected Notice Period : 30 Days  \n Shift: (GMT+05:30) Asia/Kolkata (IST)  \n \nOpportunity Type: Remote  \n \nPlacement Type: Full Time Contract for 12 Months(40 hrs a week/160 hrs a month) \n (*Note: This is a requirement for one of Uplers' client - Oddsmate)  \n \nWhat do you need for this opportunity? Must have skills required:  \n \nFront -end Experience, LSTMs, RNNs, Transformers, AI Agents, LangChain, \nLangGraph, RAG pipelines, AWS, Python  \n \nOddsmate is Look ing for:   \n \nKey Responsibilities:  \n  \n• AI Agent Development: Architect, build, and deploy production -ready AI \nagents capable of complex reasoning and decision -making within the sports \nbetting domain. • LLM Integration & Orchestration: Implement and manage integrations with \nLarge Language Models (LLMs) using modern orchestration frameworks like LangChain, LangGraph, or similar tools. • Data Pipeline Engineering: Design and implement robust RAG (Retrieval -\nAugmented Generation) pipelines to ensure LLMs have real -time, accurate \naccess to live odds, historical data, and complex data feeds for informed \ndecision -making. • Predictive Modeling: Integrate, test, and optimize machine learning models \nto enhance betting predictions and value assessment. • Code Ownership: Take full ownership and agency over engineering projects, \nensuring code quality, scalability, and adherence to best practices in a fast -\npaced environment.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Uplers",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 202,
    "job_id": "Uplers",
    "chunk_id": 2,
    "source_file": "Uplers.pdf",
    "folder": "D:/Project_2",
    "text": "• Predictive Modeling: Integrate, test, and optimize machine learning models \nto enhance betting predictions and value assessment. • Code Ownership: Take full ownership and agency over engineering projects, \nensuring code quality, scalability, and adherence to best practices in a fast -\npaced environment. • Collaboration: Work closely with the founder/CTO and design team, contributing technical expertise to product strategy and execution. Required Skills & Experience (The Must -Haves)  \n  \n• Proven experience building and deploying sophisticated AI Agents for real -\nworld applications. • Expertise with major LLMs and deep proﬁciency in agentic and orchestration frameworks (LangChain, LangGraph, etc.). • Demonstrable experience designing and implementing highly effective RAG pipelines utilizing Vector Databases and embedding models.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Uplers",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 203,
    "job_id": "Uplers",
    "chunk_id": 3,
    "source_file": "Uplers.pdf",
    "folder": "D:/Project_2",
    "text": "• Expertise with major LLMs and deep proﬁciency in agentic and orchestration frameworks (LangChain, LangGraph, etc.). • Demonstrable experience designing and implementing highly effective RAG pipelines utilizing Vector Databases and embedding models. • Comfortable working in a small team, high -paced startup environment, and \ndemonstrating a strong sense of ownership and agency over all projects. • Proﬁciency in Python and relevant data/ML libraries (e.g., Pandas, NumPy). Highly Preferred (The Plus)  \n  \n• Experience developing and implementing classic machine learning or deep learning algorithms (RNNs, LSTMs, Transformers) for time -series data or \nprediction. • Experience with cloud platforms (AWS/Azure/GCP) for model deployment \nand MLOps principles.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Uplers",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 204,
    "job_id": "Uplers",
    "chunk_id": 4,
    "source_file": "Uplers.pdf",
    "folder": "D:/Project_2",
    "text": "Highly Preferred (The Plus)  \n  \n• Experience developing and implementing classic machine learning or deep learning algorithms (RNNs, LSTMs, Transformers) for time -series data or \nprediction. • Experience with cloud platforms (AWS/Azure/GCP) for model deployment \nand MLOps principles. Nice to Have (The Full -Stack Element)  \n \n \n• Any front -end development experience (e.g., React, Next.js, or similar \nframeworks) to contribute to the full -stack element of the platform. What We Offer  \n  \n• An opportunity to be a foundational, Lead Engineer with a long -term view, \npotentially leading the engineering team as we scale. • A chance to work at the intersection of AI and a massive, real -time data \nindustry. • High technical impact and direct inﬂuence on product decisions.",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Uplers",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 205,
    "job_id": "Uplers",
    "chunk_id": 5,
    "source_file": "Uplers.pdf",
    "folder": "D:/Project_2",
    "text": "• A chance to work at the intersection of AI and a massive, real -time data \nindustry. • High technical impact and direct inﬂuence on product decisions. How to apply for this opportunity? • Step 1: Click On Apply! And Register or Login on our portal. • Step 2: Complete the Screening Form & Upload updated Resume  \n• Step 3: Increase your chances to get shortlisted & meet the client for the \nInterview!",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Uplers",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 206,
    "job_id": "Uplers",
    "chunk_id": 6,
    "source_file": "Uplers.pdf",
    "folder": "D:/Project_2",
    "text": "And Register or Login on our portal. • Step 2: Complete the Screening Form & Upload updated Resume  \n• Step 3: Increase your chances to get shortlisted & meet the client for the \nInterview!",
    "metadata": {
      "job_title": "AI Engineer",
      "company": "Uplers",
      "location": "Kochi , Kerala, India"
    }
  },
  {
    "vector_id": 207,
    "job_id": "UPS",
    "chunk_id": 1,
    "source_file": "UPS.pdf",
    "folder": "D:/Project_2",
    "text": "Company : UPS  \nJob role     :  Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP , \nVertex AI, IBM Watsonx  \nLocation  : Chennai, Tamil Nadu, India  \nAbout the job \n \nJob Summary  \n \n \nWe are seeking a highly skilled AI Engineer with 3+ years of overall experience in \nsoftware development, Data Science, or Machine Learning to design, develop, and \ndeploy cutting -edge AI systems leveraging Large Language Models (LLMs), \nChatbots, Retrieval -Augmented Generation (RAG), and agentic AI architectures. This role involves hands- on development with LLMs, embeddings, RAG pipelines, \nand multi -agent systems using modern frameworks like LangChain, LangGraph, \nand LlamaIndex. The ideal candidate has experience with Vertex AI on GCP and IBM WatsonX, ﬁne -tuning, and Agent Development Kits (ADKs), and is excited about \nbuilding scalable, production -grade AI platforms. Responsibilities  \n \n \n• Agentic AI Development:   \n  \nDesign, build, and deploy  agentic AI systems  using frameworks such as LangChain, \nLangGraph, and related libraries. Develop and deploy  multi -agent systems capable of autonomous decision -making, \nreasoning, planning, and collaboration. • RAG Pipelines:  \n  \nImplement and optimize retrieval -augmented generation (RAG)  systems, ensuring \nagents can access and incorporate external knowledge sources for  grounded, \naccurate responses .",
    "metadata": {
      "job_title": "Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP ,",
      "company": "UPS",
      "location": "Chennai, Tamil Nadu, India"
    }
  },
  {
    "vector_id": 208,
    "job_id": "UPS",
    "chunk_id": 2,
    "source_file": "UPS.pdf",
    "folder": "D:/Project_2",
    "text": "Develop and deploy  multi -agent systems capable of autonomous decision -making, \nreasoning, planning, and collaboration. • RAG Pipelines:  \n  \nImplement and optimize retrieval -augmented generation (RAG)  systems, ensuring \nagents can access and incorporate external knowledge sources for  grounded, \naccurate responses . • LLM Engineering:  \n \n \nFine -tune and prompt -engineer LLMs for  task -speciﬁc reasoning, planning, and \ndynamic adaptation . Work with  LLM/SLM APIs, embeddings, and advanced generative AI techniques . • Enterprise AI Platform:  \n \n \nLead the development of enterprise-grade AI platforms integrating  LLMs, RAG, \nembeddings, and agentic AI protocols . Implement and standardize Model Context Protocol (MCP) for consistent context \nmanagement across models and agents.",
    "metadata": {
      "job_title": "Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP ,",
      "company": "UPS",
      "location": "Chennai, Tamil Nadu, India"
    }
  },
  {
    "vector_id": 209,
    "job_id": "UPS",
    "chunk_id": 3,
    "source_file": "UPS.pdf",
    "folder": "D:/Project_2",
    "text": "• Enterprise AI Platform:  \n \n \nLead the development of enterprise-grade AI platforms integrating  LLMs, RAG, \nembeddings, and agentic AI protocols . Implement and standardize Model Context Protocol (MCP) for consistent context \nmanagement across models and agents. • MLOps & Observability:  \n  \nEstablish and enforce best practices for  MLOps, monitoring, and observability , \nensuring scalable and maintainable AI solutions. • Applied AI Prototyping:  \n \n \nRapidly  prototype, experiment, and iterate to improve AI agent capabilities. • Collaboration & Research:  \n \n \nParticipate in the  full research cycle : literature review, data exploration, \nexperimentation, and presentation of ﬁndings. Collaborate effectively with other engineers, researchers, and data scientists.",
    "metadata": {
      "job_title": "Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP ,",
      "company": "UPS",
      "location": "Chennai, Tamil Nadu, India"
    }
  },
  {
    "vector_id": 210,
    "job_id": "UPS",
    "chunk_id": 4,
    "source_file": "UPS.pdf",
    "folder": "D:/Project_2",
    "text": "• Collaboration & Research:  \n \n \nParticipate in the  full research cycle : literature review, data exploration, \nexperimentation, and presentation of ﬁndings. Collaborate effectively with other engineers, researchers, and data scientists. Contribute to the  documentation and standardization of technical code and \npractices. Required Education  \n \nBachelor’s degree in Computer Science, Engineering, or a related quantitative \nﬁeld. Master’s or Ph.D.  is a strong plus. Required Experience  \n \n \n• 3+ years overall experience in software development, data science, or \nmachine learning.",
    "metadata": {
      "job_title": "Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP ,",
      "company": "UPS",
      "location": "Chennai, Tamil Nadu, India"
    }
  },
  {
    "vector_id": 211,
    "job_id": "UPS",
    "chunk_id": 5,
    "source_file": "UPS.pdf",
    "folder": "D:/Project_2",
    "text": "Master’s or Ph.D.  is a strong plus. Required Experience  \n \n \n• 3+ years overall experience in software development, data science, or \nmachine learning. • 1+ year of hands -on experience developing AI applications with LLMs and \nsystems such as retrieval -based methods, ﬁne -tuning, or agent -based \narchitectures. • 1+ year of experience with frameworks like LangChain, LlamaIndex, OpenAI, \nor similar tools. Required Technical Skills  \n  \n• Strong programming skills in Python and basics in SQL. • Expertise with LLM/SLM APIs, embeddings, and RAG systems.",
    "metadata": {
      "job_title": "Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP ,",
      "company": "UPS",
      "location": "Chennai, Tamil Nadu, India"
    }
  },
  {
    "vector_id": 212,
    "job_id": "UPS",
    "chunk_id": 6,
    "source_file": "UPS.pdf",
    "folder": "D:/Project_2",
    "text": "Required Technical Skills  \n  \n• Strong programming skills in Python and basics in SQL. • Expertise with LLM/SLM APIs, embeddings, and RAG systems. • Experience deploying on Google Cloud Platform (GCP) with Vertex AI, and \nIBM WatsonX. • Familiarity with agentic AI protocols and exposure to Agent Development \nKits (ADKs). • Preferred Qualiﬁcations  \n• Experience implementing Model Context Protocol (MCP) for agent \ncoordination. • Prior exposure to LangGraph, AutoGen, or related orchestration frameworks.",
    "metadata": {
      "job_title": "Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP ,",
      "company": "UPS",
      "location": "Chennai, Tamil Nadu, India"
    }
  },
  {
    "vector_id": 213,
    "job_id": "UPS",
    "chunk_id": 7,
    "source_file": "UPS.pdf",
    "folder": "D:/Project_2",
    "text": "• Preferred Qualiﬁcations  \n• Experience implementing Model Context Protocol (MCP) for agent \ncoordination. • Prior exposure to LangGraph, AutoGen, or related orchestration frameworks. • Knowledge of MLOps best practices (CI/CD for ML, observability, monitoring, scaling). • Familiarity with responsible AI principles (safety, fairness, interpretability). • Experience in enterprise -scale deployments of AI -driven platforms. • Contributions to open -source AI/ML projects are a plus.",
    "metadata": {
      "job_title": "Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP ,",
      "company": "UPS",
      "location": "Chennai, Tamil Nadu, India"
    }
  },
  {
    "vector_id": 214,
    "job_id": "UPS",
    "chunk_id": 8,
    "source_file": "UPS.pdf",
    "folder": "D:/Project_2",
    "text": "• Experience in enterprise -scale deployments of AI -driven platforms. • Contributions to open -source AI/ML projects are a plus.",
    "metadata": {
      "job_title": "Intermediate AI Engineer – Python, RAG, Agentic AI, ADK, MCP , GCP ,",
      "company": "UPS",
      "location": "Chennai, Tamil Nadu, India"
    }
  },
  {
    "vector_id": 215,
    "job_id": "UST",
    "chunk_id": 1,
    "source_file": "UST.pdf",
    "folder": "D:/Project_2",
    "text": "Company : UST  \nJob role    :  ML Engineer I  \nLocation : Kochi, Kerala, India  \n \nAbout the job Role Description  \n \nWe are seeking a  visionary AI professional  to lead the AIOps team within our \nIntelligent Automation division. The role combines technical leadership, R&D, and team management to deliver cutting -edge AI -driven solutions that optimize IT \noperations through intelligent automation. Key Responsibilities  \n  \n• AIOps Research & Innovation: Drive research and development of AI solutions for predictive maintenance, anomaly detection, incident \ncorrelation, and root cause analysis. Explore and implement advanced \nGenerative AI, Large Language Models (LLMs), and agentic AI for IT \nopera tions automation. • Project & Delivery Leadership: Oversee end- to-end delivery of AIOps \nprojects, ensuring alignment with organizational goals, client requirements, \nand quality standards. • Technical Expertise: Provide expert guidance in ML, DL, NLP , and Generative \nAI technologies to build scalable, robust solutions.",
    "metadata": {
      "job_title": "ML Engineer I",
      "company": "UST",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 216,
    "job_id": "UST",
    "chunk_id": 2,
    "source_file": "UST.pdf",
    "folder": "D:/Project_2",
    "text": "• Project & Delivery Leadership: Oversee end- to-end delivery of AIOps \nprojects, ensuring alignment with organizational goals, client requirements, \nand quality standards. • Technical Expertise: Provide expert guidance in ML, DL, NLP , and Generative \nAI technologies to build scalable, robust solutions. • Team Leadership & Mentorship: Manage, mentor, and inspire AI researchers, \ndata scientists, and ML engineers, fostering collaboration, innovation, and \nprofessional growth. • Strategic Vision: Deﬁne AIOps strategy, roadmap, and innovation milestones \nthat drive business value. • Collaboration: Partner with cross -functional teams, including product \nmanagement, engineering, and business stakeholders, to design and deliver impactful AI solutions. Qualiﬁcations & Experience  \n \n \n• Education: Bachelor’s degree in Computer Science, Engineering, \nMathematics, or related ﬁeld; advanced degree (Master’s or Ph.D.) \npreferred.",
    "metadata": {
      "job_title": "ML Engineer I",
      "company": "UST",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 217,
    "job_id": "UST",
    "chunk_id": 3,
    "source_file": "UST.pdf",
    "folder": "D:/Project_2",
    "text": "• Collaboration: Partner with cross -functional teams, including product \nmanagement, engineering, and business stakeholders, to design and deliver impactful AI solutions. Qualiﬁcations & Experience  \n \n \n• Education: Bachelor’s degree in Computer Science, Engineering, \nMathematics, or related ﬁeld; advanced degree (Master’s or Ph.D.) \npreferred. • Experience: 10+ years in AI with deep expertise in ML, DL, NLP , and \nGenerative AI applications. • AIOps Expertise: Proven experience with use cases such as predictive \nmaintenance, anomaly detection, and incident management. • Technical Skills: Proﬁciency in ML frameworks (TensorFlow, PyTorch, Scikit -\nlearn), Generative AI/LLMs (GPT, BERT, transformer models), and MLOps \ntools. Familiarity with Databricks and cloud AI services (AWS, Azure, GCP).",
    "metadata": {
      "job_title": "ML Engineer I",
      "company": "UST",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 218,
    "job_id": "UST",
    "chunk_id": 4,
    "source_file": "UST.pdf",
    "folder": "D:/Project_2",
    "text": "• Technical Skills: Proﬁciency in ML frameworks (TensorFlow, PyTorch, Scikit -\nlearn), Generative AI/LLMs (GPT, BERT, transformer models), and MLOps \ntools. Familiarity with Databricks and cloud AI services (AWS, Azure, GCP). • Leadership & Communication: Demonstrated experience managing technical teams, mentoring staff, and collaborating with stakeholders. • Other Skills: Strong analytical, problem -solving, and decision -making \nabilities. Able to thrive in a fast -paced, dynamic environment while \nmaintaining focus on innovation and quality. Preferred Attributes \n  \n• Passion for continuous learning and experimentation with emerging AI \ntechnologies.",
    "metadata": {
      "job_title": "ML Engineer I",
      "company": "UST",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 219,
    "job_id": "UST",
    "chunk_id": 5,
    "source_file": "UST.pdf",
    "folder": "D:/Project_2",
    "text": "Able to thrive in a fast -paced, dynamic environment while \nmaintaining focus on innovation and quality. Preferred Attributes \n  \n• Passion for continuous learning and experimentation with emerging AI \ntechnologies. • Ability to translate AI research into scalable production solutions. • Strong business acumen with the ability to link technical innovation to \noperational impact. Skills  \n Artiﬁcial Intelligence,Machine Learning,Python \n \n \nDesired Skills and Experience  \nArtiﬁcial Intelligence,Machine Learning,Python",
    "metadata": {
      "job_title": "ML Engineer I",
      "company": "UST",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 220,
    "job_id": "UST",
    "chunk_id": 6,
    "source_file": "UST.pdf",
    "folder": "D:/Project_2",
    "text": "Skills  \n Artiﬁcial Intelligence,Machine Learning,Python \n \n \nDesired Skills and Experience  \nArtiﬁcial Intelligence,Machine Learning,Python",
    "metadata": {
      "job_title": "ML Engineer I",
      "company": "UST",
      "location": "Kochi, Kerala, India"
    }
  },
  {
    "vector_id": 221,
    "job_id": "UST2",
    "chunk_id": 1,
    "source_file": "UST2.pdf",
    "folder": "D:/Project_2",
    "text": "Company : UST  \nJob role     :  Developer III - Senior AI Engineer (Python, Docker, AI Frameworks)   \nLocation  : Trivandrum, Kerala, India  \nAbout the job \nRole Description  \n \nJob Title:  Senior AI Engineer  \n \nDepartment/BU:  Engineering  \n Overview  \n \nWe are seeking a motivated Senior AI Engineer to contribute to the design and \ndevelopment of our  agentic framework  and  centralized AI platform . This role will \nfocus on implementing and integrating AI agents, experimenting with open-source \nAI tools, and supporting the delivery of both customer -facing and internal AI -\npowered applications. You will collaborate closely with senior AI engineers, backend developers, and \nproduct engineers to bring agentic solutions to life, gaining hands- on experience \nwith cutting -edge AI frameworks and infrastructure. Resp onsibilities  \n  \n• Implement and maintain components of the agentic AI framework under the \nguidance of senior engineers. • Leverage open -source AI frameworks (e.g., LangChain, CrewAI, AutoGen) to \nbuild and experiment with agents for diverse use cases. • Evaluate and incorporate selected open -source AI solutions into the \nplatform’s agentic framework.",
    "metadata": {
      "job_title": "Developer III - Senior AI Engineer (Python, Docker, AI Frameworks)",
      "company": "UST",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 222,
    "job_id": "UST2",
    "chunk_id": 2,
    "source_file": "UST2.pdf",
    "folder": "D:/Project_2",
    "text": "• Leverage open -source AI frameworks (e.g., LangChain, CrewAI, AutoGen) to \nbuild and experiment with agents for diverse use cases. • Evaluate and incorporate selected open -source AI solutions into the \nplatform’s agentic framework. • Collaborate with product engineers to integrate AI agents into customer -\nfacing applications and internal tools. • Write clean, maintainable Python code for AI workﬂows, APIs, and data integration tasks. • Assist in testing, debugging, and performance optimization of AI -powered \nworkloads. • Contribute to documentation and knowledge sharing within the team.",
    "metadata": {
      "job_title": "Developer III - Senior AI Engineer (Python, Docker, AI Frameworks)",
      "company": "UST",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 223,
    "job_id": "UST2",
    "chunk_id": 3,
    "source_file": "UST2.pdf",
    "folder": "D:/Project_2",
    "text": "• Assist in testing, debugging, and performance optimization of AI -powered \nworkloads. • Contribute to documentation and knowledge sharing within the team. Relevant Experience & Educational Requirements  \n  \n• Bachelor’s degree in Computer Science, Engineering, or a related ﬁeld (or \nequivalent practical experience). • 2–4 years of software engineering experience, with exposure to AI/ML \nconcepts or platforms. • Strong programming skills in Python; familiarity with frameworks like FastAPI or Flask is a plus. • Hands -on experience with at least one agentic AI framework (e.g., \nLangChain, LangGraph, CrewAI, AutoGen) through projects, internships, or \nprofessional work.",
    "metadata": {
      "job_title": "Developer III - Senior AI Engineer (Python, Docker, AI Frameworks)",
      "company": "UST",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 224,
    "job_id": "UST2",
    "chunk_id": 4,
    "source_file": "UST2.pdf",
    "folder": "D:/Project_2",
    "text": "• Strong programming skills in Python; familiarity with frameworks like FastAPI or Flask is a plus. • Hands -on experience with at least one agentic AI framework (e.g., \nLangChain, LangGraph, CrewAI, AutoGen) through projects, internships, or \nprofessional work. • Familiarity with containerization (Docker) and cloud environments (AWS, \nGCP , Azure). • Exposure to orchestration frameworks (Kubernetes). • Familiarity with modern LLM APIs (OpenAI, Anthropic, etc.). Skills  \n  \n• Artiﬁcial Intelligence   \n• Python   \n• Docker   \n• AI Frameworks   \n  \nSkills  \n \nArtiﬁcial Intelligence,Python,Docker,Ai framework  \n \n \nDesired Skills and Experience  \nArtiﬁcial Intelligence,Python,Docker,Ai framework",
    "metadata": {
      "job_title": "Developer III - Senior AI Engineer (Python, Docker, AI Frameworks)",
      "company": "UST",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 225,
    "job_id": "UST2",
    "chunk_id": 5,
    "source_file": "UST2.pdf",
    "folder": "D:/Project_2",
    "text": "• Familiarity with modern LLM APIs (OpenAI, Anthropic, etc.). Skills  \n  \n• Artiﬁcial Intelligence   \n• Python   \n• Docker   \n• AI Frameworks   \n  \nSkills  \n \nArtiﬁcial Intelligence,Python,Docker,Ai framework  \n \n \nDesired Skills and Experience  \nArtiﬁcial Intelligence,Python,Docker,Ai framework",
    "metadata": {
      "job_title": "Developer III - Senior AI Engineer (Python, Docker, AI Frameworks)",
      "company": "UST",
      "location": "Trivandrum, Kerala, India"
    }
  },
  {
    "vector_id": 226,
    "job_id": "Visteon",
    "chunk_id": 1,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "Company : Visteon Corporation  \nJob role     :  Generative AI Developer   \nLocation  : Bengaluru , Karnataka, India  \nAbout the job \nAt Visteon, the work we do is both relevant and recognized—not just by our \norganization, but by our peers, by industry -leading brands, and by millions of \ndrivers around the world. That’s YOUR work. And, as a truly global technology \nleader in the mobility space, focused on building cross -functional AND cross -\ncultural teams, we connect you with people who help you grow. So here, whatever we do is not a job. It’s a mission. As a multi -billion -dollar leader of disruptive \nchange in the industry, we are shaping t he future, while enabling a cleaner \nenvironment.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 227,
    "job_id": "Visteon",
    "chunk_id": 2,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "It’s a mission. As a multi -billion -dollar leader of disruptive \nchange in the industry, we are shaping t he future, while enabling a cleaner \nenvironment. No other industry offers more fast -paced change and opportunity. We \nare in the midst of a mobility revolution that will completely change the way we \ninteract with our vehicles, reduce the number of car accid ents and fatalities, and \nmake the world a cleaner place. Visteon is at the epicenter of this mobility \nrevolution. Two major trends in the automotive industry – the shift to electric \nvehicles and vehicles with autonomous safety technologies – have created u nique \nopportunities for Visteon.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 228,
    "job_id": "Visteon",
    "chunk_id": 3,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "Visteon is at the epicenter of this mobility \nrevolution. Two major trends in the automotive industry – the shift to electric \nvehicles and vehicles with autonomous safety technologies – have created u nique \nopportunities for Visteon. We are the only automotive provider focused exclusively on cockpit electronics – the fastest -growing segment in the industry. Mission of the \nRole: Facilitate Enterprise machine learning and artiﬁcial intelligence solutions  \nusing the latest technologies Visteon is adopting globally. Key Objectives of this \nRole: The primary goal of the Global ML/AI Developer is to leverage advanced machine learning and artiﬁcial intelligence techniques to develop innovative \nsolutions that dr ive Visteon’s strategic initiatives. By collaborating with cross -\nfunctional teams and stakeholders, this role identiﬁes opportunities for AI -driven \nimprovements, designs and implements scalable ML models, and integrates these \nmodels into existing systems to enhance operational efficiency.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 229,
    "job_id": "Visteon",
    "chunk_id": 4,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "Key Objectives of this \nRole: The primary goal of the Global ML/AI Developer is to leverage advanced machine learning and artiﬁcial intelligence techniques to develop innovative \nsolutions that dr ive Visteon’s strategic initiatives. By collaborating with cross -\nfunctional teams and stakeholders, this role identiﬁes opportunities for AI -driven \nimprovements, designs and implements scalable ML models, and integrates these \nmodels into existing systems to enhance operational efficiency. Following development best practices, fostering a culture of continuous learning, and staying \nabreast of AI advancements, the Global ML/AI Developer ensures that all AI \nsolutions align with organizational goals, support data -driven decision -making, \nand continuously improve Visteon’s technological capabilities. Key Performance Indicators:   \n  \n•  Model Accuracy and Performance: Track deployed ML models' accuracy, \nprecision, recall, and F1 scores to ensure they meet performance benchmarks and deliver reliable predictions. •  Deployment Efficiency: Measure the time taken to deploy ML models from \ndevelopment to production, ensuring a streamlined and efficient \ndeployment process. •  Scalability and Integration: Evaluate the scalability of ML models by \nmonitoring their performance under varying loads and their integration with existing systems.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 230,
    "job_id": "Visteon",
    "chunk_id": 5,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Deployment Efficiency: Measure the time taken to deploy ML models from \ndevelopment to production, ensuring a streamlined and efficient \ndeployment process. •  Scalability and Integration: Evaluate the scalability of ML models by \nmonitoring their performance under varying loads and their integration with existing systems. KPIs could include the number of integrated data sources \nand the efficiency of data pipeline s. \n•  Innovation and Research: Track the adoption of new ML/AI techniques and \ntechnologies, participation in industry conferences, and contributions to research publications or internal knowledge -sharing platforms. •  Model Maintenance and Updates: Monitor the frequency and effectiveness \nof model updates and maintenance activities to ensure that models remain \naccurate and relevant. •  Training and Knowledge Transfer: Assess the effectiveness of training \nprograms and knowledge transfer by tracking team members’ proﬁciency in ML/AI development and the adoption of best practices. •  Business Impact: Measure the impact of ML/AI solutions on business \noutcomes, such as increased revenue, cost savings, or improved operational \nefficiency.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 231,
    "job_id": "Visteon",
    "chunk_id": 6,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Training and Knowledge Transfer: Assess the effectiveness of training \nprograms and knowledge transfer by tracking team members’ proﬁciency in ML/AI development and the adoption of best practices. •  Business Impact: Measure the impact of ML/AI solutions on business \noutcomes, such as increased revenue, cost savings, or improved operational \nefficiency. Use metrics like ROI (Return on Investment) or speciﬁc business \nKPIs to evaluate success. •  Compliance and Ethics: Ensure compliance with data privacy regulations \nand ethical standards by monitoring adherence to data governance policies, bias mitigation strategies, and transparency in model decision -making \nprocesses. •  Customer Satisfaction: Collect feedback from internal stakeholders or \nclients to evaluate their satisfaction with ML/AI solutions. Use metrics like \nNet Promoter Score (NPS) or customer satisfaction surveys to identify areas for improvement.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 232,
    "job_id": "Visteon",
    "chunk_id": 7,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Customer Satisfaction: Collect feedback from internal stakeholders or \nclients to evaluate their satisfaction with ML/AI solutions. Use metrics like \nNet Promoter Score (NPS) or customer satisfaction surveys to identify areas for improvement. Key Year One Deliverables:   \n  \n•  Current State Assessment and Documentation: Conduct a thorough \nevaluation of the existing AI/ML infrastructure, including data sources, models, platforms, and governance practices. Document ﬁndings and identify areas for improvement. •  Stakeholder Needs Analysis: Collaborate with key stakeholders to \nunderstand their requirements, challenges, and priorities for AI/ML \nsolutions. Gain a comprehensive understanding of business objectives and \nuser needs.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 233,
    "job_id": "Visteon",
    "chunk_id": 8,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Stakeholder Needs Analysis: Collaborate with key stakeholders to \nunderstand their requirements, challenges, and priorities for AI/ML \nsolutions. Gain a comprehensive understanding of business objectives and \nuser needs. •  Roadmap and Strategy Development: Develop a strategic roadmap for AI/ML \nimplementation that aligns with organizational goals. Prioritize initiatives based on business value, feasibility, data availability, technical constraints, and resource needs. •  Prototyping and Proof of Concept: Create prototypes or proof of concept \nsolutions to demonstrate the potential of AI/ML in addressing speciﬁc business challenges or opportunities. Validate technical feasibility and \ngather stakeholder feedback.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 234,
    "job_id": "Visteon",
    "chunk_id": 9,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Prototyping and Proof of Concept: Create prototypes or proof of concept \nsolutions to demonstrate the potential of AI/ML in addressing speciﬁc business challenges or opportunities. Validate technical feasibility and \ngather stakeholder feedback. •  Governance Framework Establishment: Establish and implement a \ngovernance framework for AI/ML development and usage, including data security policies, access controls, data quality standards, and change \nmanagement processes. •  Training and Enablement Programs: Design and deliver training programs to \nenhance the skills and capabilities of team members and end users in AI/ML \ndevelopment, best practices, and data analysis techniques. •  Model Development and Deployment: Develop and deploy high -quality \nAI/ML models to meet critical business requirements. Ensure models are accurate, scalable, and aligned with user needs.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 235,
    "job_id": "Visteon",
    "chunk_id": 10,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Model Development and Deployment: Develop and deploy high -quality \nAI/ML models to meet critical business requirements. Ensure models are accurate, scalable, and aligned with user needs. •  Integration with Existing Systems: Integrate AI/ML solutions with existing \ndata sources, applications, and systems to create a uniﬁed analytics environment. Ensure seamless data ﬂow and interoperability between AI/ML \nmodels and other platforms. •  Documentation and Knowledge Sharing: Document AI/ML solutions, best \npractices, and lessons learned to facilitate knowledge sharing and promote \nreusability across the organization. •  Performance Measurement and Reporting: Establish performance metrics \nand reporting mechanisms to track progress against key objectives and KPIs.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 236,
    "job_id": "Visteon",
    "chunk_id": 11,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Documentation and Knowledge Sharing: Document AI/ML solutions, best \npractices, and lessons learned to facilitate knowledge sharing and promote \nreusability across the organization. •  Performance Measurement and Reporting: Establish performance metrics \nand reporting mechanisms to track progress against key objectives and KPIs. Provide regular updates to stakeholders on the status of AI/ML \ninitiatives and their impact on business outcome s. \n \n \nQualiﬁcation, Experience and Skills:   \n \nTechnical Skills:  \n \n \n•  Extensive expertise in machine learning frameworks (e.g., TensorFlow, \nPyTorch), programming languages (e.g., Python, R, SQL), and data processing tools (e.g., Apache Spark, Hadoop). •  Proﬁcient in backend development for Python using FastAPI and Django \nRest. •  Skilled in developing, training, and deploying machine learning models, \nincluding supervised and unsupervised learning, deep learning, and \nreinforcement learning (ﬁne -tuning). •  Strong understanding of data engineering concepts, including data \npreprocessing, feature engineering, and data pipeline development.",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 237,
    "job_id": "Visteon",
    "chunk_id": 12,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Skilled in developing, training, and deploying machine learning models, \nincluding supervised and unsupervised learning, deep learning, and \nreinforcement learning (ﬁne -tuning). •  Strong understanding of data engineering concepts, including data \npreprocessing, feature engineering, and data pipeline development. •  Experienced with cloud platforms (preferably Microsoft Azure) for deploying \nand scaling machine learning solutions. •  Hands -on experience with core machine learning algorithms, concepts, and \nvirtual environment managers (Poetry, Conda, Venv). •  Expertise in natural language processing (NLP) using Langchain and OpenAI, \nas well as computer vision tasks such as classiﬁcation, object detection, and segmentation. Business Acumen: Strong business analysis and ability to \ntranslate comp\"",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  },
  {
    "vector_id": 238,
    "job_id": "Visteon",
    "chunk_id": 13,
    "source_file": "Visteon.pdf",
    "folder": "D:/Project_2",
    "text": "•  Expertise in natural language processing (NLP) using Langchain and OpenAI, \nas well as computer vision tasks such as classiﬁcation, object detection, and segmentation. Business Acumen: Strong business analysis and ability to \ntranslate comp\"",
    "metadata": {
      "job_title": "Generative AI Developer",
      "company": "Visteon Corporation",
      "location": "Bengaluru , Karnataka, India"
    }
  }
]